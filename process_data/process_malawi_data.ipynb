{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "702a6377-b4ff-4e43-b615-4347ca0c33ca",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d3cef64-a803-41e1-a35b-52aabb66c9b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "from collections import defaultdict\n",
    "import sklearn.linear_model as sklearn_linear_model\n",
    "import sklearn.metrics as sklearn_metrics\n",
    "import sklearn.model_selection as sklearn_model_selection\n",
    "import sklearn.preprocessing as sklearn_preprocessing\n",
    "import sklearn.feature_selection as sklearn_feature_selection\n",
    "import sklearn.ensemble as sklearn_ensemble\n",
    "import sklearn.decomposition as sklearn_decomposition\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import dask.dataframe as ddf\n",
    "\n",
    "import geopandas as gpd\n",
    "import dask_geopandas as dgpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pyreadstat\n",
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0077cdb-e09e-43d7-b773-6304b9551e67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = Path('/home/selker/eop/data')\n",
    "\n",
    "malawi_directory = data_path / 'malawi'\n",
    "malawi_survey_directory_dta = malawi_directory / 'MWI_2016_IHS-IV_v04_M_STATA14'\n",
    "\n",
    "mosaiks_directory = data_path / 'mosaiks'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cc9ad4-cdc0-4a06-9809-77f78ff4d25c",
   "metadata": {},
   "source": [
    "Out: \n",
    "* A data file, one-hot encoded and imputed as in roshni's replication code, with all columns included\n",
    "* A summary like I construct: with \"dropped\" indicating either dropped for missingness, or omitted because we don't want it (say, consumption qs)\n",
    "* summary should include a one-hot map, i.e. a column containing one-hat categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e7ea2d-8d31-47ee-b986-93326c36d21f",
   "metadata": {},
   "source": [
    "## Geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea8a433f-1342-4165-95fd-971b2eb56b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_vars, _ = pyreadstat.read_dta(\n",
    "    malawi_survey_directory_dta / 'household_geovariables/householdgeovariablesihs4.dta'\n",
    ")\n",
    "filt, _ = pyreadstat.read_dta(\n",
    "    malawi_survey_directory_dta / 'household/hh_mod_a_filt.dta',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4ebbf5e-63bf-4aa5-9d0f-5dc1c8d5fdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>lat_modified</th>\n",
       "      <th>lon_modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301025230225</td>\n",
       "      <td>-14.683761</td>\n",
       "      <td>34.915074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210374850204</td>\n",
       "      <td>-14.005029</td>\n",
       "      <td>33.794591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>311057710075</td>\n",
       "      <td>-16.826165</td>\n",
       "      <td>35.269503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>312048040073</td>\n",
       "      <td>-15.004730</td>\n",
       "      <td>35.163219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>311097790117</td>\n",
       "      <td>-17.016698</td>\n",
       "      <td>35.079629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12442</th>\n",
       "      <td>312048040036</td>\n",
       "      <td>-15.004730</td>\n",
       "      <td>35.163219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12443</th>\n",
       "      <td>305016150137</td>\n",
       "      <td>-15.558742</td>\n",
       "      <td>35.010733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12444</th>\n",
       "      <td>104031830093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445</th>\n",
       "      <td>314408470035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12446</th>\n",
       "      <td>314358370219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12447 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            case_id  lat_modified  lon_modified\n",
       "0      301025230225    -14.683761     34.915074\n",
       "1      210374850204    -14.005029     33.794591\n",
       "2      311057710075    -16.826165     35.269503\n",
       "3      312048040073    -15.004730     35.163219\n",
       "4      311097790117    -17.016698     35.079629\n",
       "...             ...           ...           ...\n",
       "12442  312048040036    -15.004730     35.163219\n",
       "12443  305016150137    -15.558742     35.010733\n",
       "12444  104031830093           NaN           NaN\n",
       "12445  314408470035           NaN           NaN\n",
       "12446  314358370219           NaN           NaN\n",
       "\n",
       "[12447 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_vars[['case_id', 'lat_modified', 'lon_modified']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c8fe268-4428-4e33-b001-6c54103079e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_ea_and_lat_lon = filt[['case_id', 'ea_id']].merge(\n",
    "    geo_vars[['case_id', 'lat_modified', 'lon_modified']],\n",
    "    on='case_id', \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a49e5c0-7631-4ace-9323-4dcb3062f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few EAs have two locations. Not sure why.\n",
    "ea_with_lat_lon = with_ea_and_lat_lon.groupby('ea_id')[['lat_modified', 'lon_modified']].agg(pd.Series.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65529b42-e637-422c-98b0-06684861aef2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "The 'read_file' function requires the 'pyogrio' or 'fiona' package, but neither is installed or imports correctly.\nImporting fiona resulted in: /home/selker/.conda/envs/leo_base/lib/python3.9/site-packages/fiona/../../../libgdal.so.34: undefined symbol: sqlite3_total_changes64\nImporting pyogrio resulted in: No module named 'pyogrio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m malawi_admin_3 \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmalawi_directory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmwi_adm_nso_hotosm_20230405_shp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmwi_admbnda_adm3_nso_hotosm_20230405.shp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/leo_base/lib/python3.9/site-packages/geopandas/io/file.py:271\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_file\u001b[39m(filename, bbox\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m    Returns a GeoDataFrame from a file or URL.\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m \n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m     engine \u001b[38;5;241m=\u001b[39m \u001b[43m_check_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mread_file\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m function\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m     filename \u001b[38;5;241m=\u001b[39m _expand_user(filename)\n\u001b[1;32m    275\u001b[0m     from_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/leo_base/lib/python3.9/site-packages/geopandas/io/file.py:120\u001b[0m, in \u001b[0;36m_check_engine\u001b[0;34m(engine, func)\u001b[0m\n\u001b[1;32m    118\u001b[0m     _check_pyogrio(func)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m package, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut neither is installed or imports correctly.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mImporting fiona resulted in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfiona_import_error\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mImporting pyogrio resulted in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpyogrio_import_error\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m     )\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m engine\n",
      "\u001b[0;31mImportError\u001b[0m: The 'read_file' function requires the 'pyogrio' or 'fiona' package, but neither is installed or imports correctly.\nImporting fiona resulted in: /home/selker/.conda/envs/leo_base/lib/python3.9/site-packages/fiona/../../../libgdal.so.34: undefined symbol: sqlite3_total_changes64\nImporting pyogrio resulted in: No module named 'pyogrio'"
     ]
    }
   ],
   "source": [
    "malawi_admin_3 = gpd.read_file(\n",
    "    malawi_directory / 'mwi_adm_nso_hotosm_20230405_shp' / 'mwi_admbnda_adm3_nso_hotosm_20230405.shp'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96090eb6-0939-4cde-9e30-a5dc27704e7c",
   "metadata": {},
   "source": [
    "#### Mosaiks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a199ffd-5597-49a0-9178-1454034adba7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def clean_mosaiks_column_name(column_name):\n",
    "    column_name_stripped = column_name.strip(' .')\n",
    "    try:\n",
    "        number = int(column_name_stripped)\n",
    "    except ValueError:\n",
    "        if column_name_stripped == '':\n",
    "            return 'mosaiks_0'\n",
    "        else:\n",
    "            return column_name\n",
    "    else:\n",
    "        return f'mosaiks_{number}'\n",
    "\n",
    "mosaiks = ddf.read_csv(str(mosaiks_directory / 'malawi_fine' / '*.csv'))\n",
    "malawi_outline = gpd.read_file(\n",
    "    malawi_directory / 'mwi_adm_nso_hotosm_20230405_shp' / 'mwi_admbnda_adm0_nso_hotosm_20230405.shp'\n",
    ")\n",
    "\n",
    "mosaiks = dgpd.from_dask_dataframe(\n",
    "    mosaiks, dgpd.points_from_xy(mosaiks, 'Lon', 'Lat')\n",
    ")\n",
    "\n",
    "# this data covers a box containing Malawi; filter down to the points actually within the country.\n",
    "mosaiks = mosaiks[mosaiks.geometry.within(malawi_outline.iloc[0].geometry)]\n",
    "\n",
    "mosaiks.columns = mosaiks.columns.map(clean_mosaiks_column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61f9659-048f-4f7a-866d-5fb03b66918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaiks.drop(columns='geometry').to_parquet('mosaiks_within_malawi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1648eb1-e204-4994-9809-0c76a24fbbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaiks = ddf.read_parquet('mosaiks_within_malawi/*.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a730ea4a-4537-4241-a4de-2cec205d609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_vars.groupby(['lat_modified', 'lon_modified']).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564074c7-e4c0-479d-bbf9-cf5850bab1b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DOESN'T WORK - finish about; this geo_vars df doesn't have ea_id (it's in HH_MOD_A_FILT)\n",
    "\n",
    "\n",
    "# associate a moasiks tile with each enumeration area\n",
    "ea_geo = geo_vars.groupby('ea_id').first()[['lat_modified', 'lon_modified']]\n",
    "ea_geo = gpd.GeoDataFrame(ea_geo, geometry = gpd.points_from_xy(x=ea_geo.lon_modified, y=ea_geo.lat_modified))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06379574-1bd2-44e5-a304-04a550f1fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaiks_grid_size = 1\n",
    "max_distance = math.sqrt(2 * (mosaiks_grid_size / 2)**2)\n",
    "\n",
    "mosaiks_computed = mosaiks.compute()\n",
    "\n",
    "ea_geo_with_mosaiks = gpd.sjoin_nearest(\n",
    "    left_df=ea_geo, right_df=mosaiks_computed, how='left', max_distance=mosaiks_grid_size\n",
    ")\n",
    "\n",
    "ea_geo_with_mosaiks.rename(\n",
    "    columns={'Lat': 'lat_mosaiks', 'Lon': 'lon_mosaiks', 'index_right': 'index_mosaiks'},\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "ea_geo_with_mosaiks.reset_index(inplace=True)\n",
    "ea_geo_with_mosaiks.ea_id = ea_geo_with_mosaiks.ea_id.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4adbbc7-c3f2-4d3e-ac38-a84cd71635c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ea_geo_with_mosaiks.drop(columns=['geometry', 'BoxLabel']).to_parquet('2016_ea_geo_with_mosaiks.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "936f8fbc-dc0f-4281-80bd-5e9c26b35aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ea_geo_with_mosaiks = pd.read_parquet('2016_ea_geo_with_mosaiks.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2595254c-1909-4dea-884f-c17c8a182b96",
   "metadata": {},
   "source": [
    "## 2016 LSMS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48bf690f-65eb-4257-a71b-43e66f784298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_equal(df, col1, col2):\n",
    "    c1 = df[col1]\n",
    "    c2 = df[col2]\n",
    "\n",
    "    if pd.api.types.is_numeric_dtype(c1) and pd.api.types.is_numeric_dtype(c2):\n",
    "        return np.isclose(c1, c2, rtol=1e-4, equal_nan=True).all()\n",
    "    else:\n",
    "        try:\n",
    "            eq = (c1 == c2).all()\n",
    "        except TypeError:\n",
    "            # mismatched categories -> this comparison raises a type error\n",
    "            eq = False\n",
    "        return eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7f356e25-5162-4c69-a3bd-e6d419650313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error merging agriculture/ag_mod_r2, mismatch in hhid\n",
      "error merging agriculture/ag_mod_e3, mismatch in hhid\n",
      "error merging consumption_aggregate/ihs4 consumption aggregate, mismatch in region\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/tmp/ipykernel_3468256/1219469157.py:93: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  malawi_to_process[c] = pd.to_numeric(malawi_to_process[c], errors='ignore')\n",
      "/data/tmp/ipykernel_3468256/1219469157.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  malawi_to_process[c] = pd.to_numeric(malawi_to_process[c], errors='ignore')\n",
      "/data/tmp/ipykernel_3468256/1219469157.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  malawi_to_process[c] = malawi_to_process[c].astype(str)\n",
      "/data/tmp/ipykernel_3468256/1219469157.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  malawi_to_process[c] = malawi_to_process[c].astype(str)\n",
      "/data/tmp/ipykernel_3468256/1219469157.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  malawi_to_process[c] = malawi_to_process[c].astype(str)\n",
      "/data/tmp/ipykernel_3468256/1219469157.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  malawi_to_process[c] = malawi_to_process[c].astype(str)\n",
      "/data/tmp/ipykernel_3468256/1219469157.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  malawi_to_process[c] = malawi_to_process[c].astype(str)\n",
      "/data/tmp/ipykernel_3468256/1219469157.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  malawi_to_process[c] = malawi_to_process[c].astype(str)\n"
     ]
    }
   ],
   "source": [
    "malawi = None\n",
    "column_names_to_labels = dict()\n",
    "\n",
    "for file in (\n",
    "    'household/hh_mod_a_filt',\n",
    "    'household/hh_mod_f', # housing\n",
    "    'household/hh_mod_h', # food security\n",
    "    'household/hh_mod_n1', # household enterprises\n",
    "    'household/hh_mod_s2', # household credit\n",
    "    'household/hh_mod_t', # subj assessment of well-being\n",
    "    'household/hh_mod_x', # ag and fisheries filter,\n",
    "    'agriculture/ag_mod_a', # ownership of land\n",
    "    'agriculture/ag_mod_r2', # livestock\n",
    "    'agriculture/ag_mod_e3', # coupon use - rainy season\n",
    "    'household_geovariables/householdgeovariablesihs4', # geo\n",
    "    'consumption_aggregate/ihs4 consumption aggregate' # consumption\n",
    "):\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore') # TODO: Investigate. Warning thrown from w/in pyreadstat.\n",
    "\n",
    "        dataframe, metadata =  pyreadstat.read_dta(\n",
    "                malawi_survey_directory_dta / f'{file}.dta', apply_value_formats=True\n",
    "        )\n",
    "\n",
    "    column_names_to_labels.update(metadata.column_names_to_labels)\n",
    "\n",
    "    if malawi is None:\n",
    "        malawi = dataframe\n",
    "    else:\n",
    "        malawi = malawi.merge(dataframe, on='case_id', how='outer', suffixes=('_left', '_right'))\n",
    "\n",
    "        for c in malawi.columns:\n",
    "            if c.endswith('_left'):\n",
    "                c_left = c\n",
    "                base = c_left[:-5]\n",
    "                c_right = f'{base}_right'\n",
    "\n",
    "                match = columns_equal(malawi, c_left, c_right)\n",
    "                \n",
    "                if match:\n",
    "                    malawi.drop(columns=c_right, inplace=True)\n",
    "                    malawi.rename(columns={c_left: base}, inplace=True)\n",
    "                # geographies are sometimes named and sometimes encoded as integers. If we've got one of each,  \n",
    "                # keep the string name: that way it won't accidentally be treated as numeric later.\n",
    "                elif (\n",
    "                    (base in ['region', 'district'])\n",
    "                    & (\n",
    "                        pd.api.types.is_numeric_dtype(malawi[c_left]) \n",
    "                        + pd.api.types.is_numeric_dtype(malawi[c_right]) \n",
    "                        == 1\n",
    "                      )\n",
    "                ):\n",
    "                    if pd.api.types.is_numeric_dtype(malawi[c_left]):\n",
    "                        malawi.drop(columns=c_left, inplace=True)\n",
    "                        malawi.rename(columns={c_right: base}, inplace=True)\n",
    "                    else:\n",
    "                        malawi.drop(columns=c_right, inplace=True)\n",
    "                        malawi.rename(columns={c_left: base}, inplace=True)\n",
    "                else:\n",
    "                    print(f'error merging {file}, mismatch in {base}')\n",
    "                    malawi.drop(columns=c_right, inplace=True)\n",
    "                    malawi.rename(columns={c_left: base}, inplace=True)\n",
    "\n",
    "# Add Mosaiks columns. \n",
    "if False:\n",
    "    malawi.ea_id = malawi.ea_id.astype(int)\n",
    "    malawi = malawi.merge(\n",
    "        ea_geo_with_mosaiks, on='ea_id', how='outer'\n",
    "    )\n",
    "    \n",
    "    for c in ('lat_modified', 'lon_modified'):\n",
    "        malawi.drop(columns=f'{c}_x', inplace=True)\n",
    "        malawi.rename(columns={f'{c}_y' : c}, inplace=True)\n",
    "\n",
    "malawi_raw = malawi\n",
    "# Drop rows that are missing critical fields which we don't want to impute.\n",
    "malawi.dropna(subset=['rexpagg'], inplace=True)\n",
    "\n",
    "# TODO: Figure out how to detect datetime-like columns automatically\n",
    "malawi['interviewDate'] = pd.to_datetime(malawi['interviewDate'])\n",
    "\n",
    "# columns not to be imputed, coerced to numeric, or one-hot encoded.\n",
    "# summary table won't include these either - for now, this seems fine. \n",
    "columns_to_reserve = [\n",
    "    'hhid', 'case_id', 'hh_wgt', 'interviewDate'\n",
    "]\n",
    "malawi_reserved = malawi[columns_to_reserve]\n",
    "malawi_to_process = malawi[malawi.columns.difference(columns_to_reserve)]\n",
    "\n",
    "# coerce columns to numeric that can be coerced\n",
    "for c in malawi_to_process.columns:\n",
    "    malawi_to_process[c] = pd.to_numeric(malawi_to_process[c], errors='ignore')\n",
    "\n",
    "# coerce known categorical columns to string\n",
    "known_categorical = [\n",
    "    'region', 'district', 'hh_t01', 'hh_t02', 'hh_t03', 'hh_t04'\n",
    "]\n",
    "for c in known_categorical:\n",
    "    malawi_to_process[c] = malawi_to_process[c].astype(str)\n",
    "\n",
    "# summarize columns\n",
    "missing_counts = malawi_to_process.isnull().sum()+ (malawi_to_process == \"\").sum()  \n",
    "means = malawi_to_process.mean(skipna=True, numeric_only=True)\n",
    "medians = malawi_to_process.median(skipna=True, numeric_only=True)\n",
    "stds = malawi_to_process.std(skipna=True, numeric_only=True)\n",
    "\n",
    "summary = pd.concat((missing_counts, means, medians, stds), axis=1)\n",
    "summary.columns = ['missing_count', 'mean', 'median', 'std']\n",
    "summary['missing_fraction'] = summary.missing_count / len(malawi_to_process)\n",
    "\n",
    "summary.reset_index(names='covariate', inplace=True)\n",
    "\n",
    "# Split into numeric and non-numeric columns\n",
    "malawi_numeric = malawi_to_process.select_dtypes(include=[np.number])\n",
    "malawi_non_numeric = malawi_to_process.select_dtypes(exclude=[np.number, np.datetime64])\n",
    "\n",
    "def get_covariate_type(cov):\n",
    "    \n",
    "    if cov in malawi_numeric.columns:\n",
    "        return 'numeric'\n",
    "    elif cov in malawi_non_numeric.columns:\n",
    "        return 'categorical'\n",
    "\n",
    "summary['type'] = summary['covariate'].apply(get_covariate_type)\n",
    "covariate_to_columns_map = {\n",
    "    covariate: [covariate] for covariate in summary.covariate\n",
    "}\n",
    "\n",
    "# impute missing values with the mean.\n",
    "MISSINGNESS_CUTOFF = 0.15\n",
    "covariates_over_cutoff = summary[summary.missing_fraction > MISSINGNESS_CUTOFF].covariate.values\n",
    "for covariate in malawi_numeric.columns:\n",
    "    if covariate in covariates_over_cutoff:\n",
    "        dummy_column = f'{covariate}_nan'\n",
    "        malawi_numeric[dummy_column] = malawi_numeric[covariate].isna()\n",
    "        covariate_to_columns_map[covariate].append(dummy_column)\n",
    "\n",
    "# This is different from what roshni does: She uses 0 to impute\n",
    "# if missingness is >15%. \n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(malawi_numeric)\n",
    "\n",
    "columns = malawi_numeric.columns\n",
    "malawi_numeric = pd.DataFrame(imputer.transform(malawi_numeric))\n",
    "malawi_numeric.columns = columns\n",
    "\n",
    "# one-hot encode categoricals.\n",
    "# This is different from what roshni does. I'm encoding missing values\n",
    "# with a category regardless of missing fraction.\n",
    "one_hot_encoder = sklearn_preprocessing.OneHotEncoder(\n",
    "    drop='if_binary', sparse_output=False\n",
    ").fit(malawi_non_numeric)\n",
    "encoded_data = one_hot_encoder.transform(malawi_non_numeric)\n",
    "malawi_non_numeric_encoded = pd.DataFrame(encoded_data)\n",
    "malawi_non_numeric_encoded.columns = one_hot_encoder.get_feature_names_out()\n",
    "\n",
    "# populate the map from original column names to the list of one-hot columns. \n",
    "for i in range(len(one_hot_encoder.feature_names_in_)):\n",
    "\n",
    "    covariate = one_hot_encoder.feature_names_in_[i]\n",
    "    categories = one_hot_encoder.categories_[i]\n",
    "\n",
    "    if one_hot_encoder.drop_idx_[i] is not None:\n",
    "        categories = np.delete(categories, one_hot_encoder.drop_idx_[i])\n",
    "\n",
    "    covariate_to_columns_map[covariate] = [\n",
    "        f'{covariate}_{category}' for category in categories\n",
    "    ]\n",
    "\n",
    "malawi = malawi_reserved.join(malawi_numeric).join(malawi_non_numeric_encoded)\n",
    "\n",
    "# create map from one-hot columns to original columns + values\n",
    "inverse_one_hot_map = dict()\n",
    "for feature, categories in one_hot_map.items():\n",
    "    for category in categories:\n",
    "        inverse_one_hot_map[f'{feature}_{category}'] = (feature, category)\n",
    "\n",
    "# TODO: replace with a dict get() with default\n",
    "def interpret_column_name(column_name):\n",
    "\n",
    "    if column_name in column_names_to_labels:\n",
    "        return column_names_to_labels[column_name]\n",
    "\n",
    "    return column_name\n",
    "\n",
    "summary['description'] = summary.covariate.apply(interpret_column_name)\n",
    "\n",
    "summary.missing_fraction = summary.missing_fraction.round(2)\n",
    "summary['median'] = summary['median'].round(2)\n",
    "summary['mean'] = summary['mean'].round(2)\n",
    "summary['std'] = summary['std'].round(2)\n",
    "\n",
    "ADULT_MIN_AGE = 18\n",
    "\n",
    "roster, _ =  pyreadstat.read_dta(\n",
    "    malawi_survey_directory_dta / 'household/hh_mod_b.dta', apply_value_formats=True\n",
    ")\n",
    "\n",
    "roster['adult'] = roster.hh_b05a >= ADULT_MIN_AGE\n",
    "hh_adult_counts = (\n",
    "    roster[roster.adult].groupby('case_id')[['hhid']].count().rename(columns={'hhid': 'num_adults'})\n",
    ")\n",
    "hh_child_counts = (\n",
    "    roster[~roster.adult].groupby('case_id')[['hhid']].count().rename(columns={'hhid': 'num_children'})\n",
    ")\n",
    "\n",
    "malawi = (\n",
    "    malawi\n",
    "    .merge(hh_adult_counts, how='left', on='case_id')\n",
    "    .merge(hh_child_counts, how='left', on='case_id')\n",
    ")\n",
    "\n",
    "malawi[['num_adults', 'num_childrens']] = (\n",
    "    malawi[['num_adults', 'num_children']].fillna(value=0)\n",
    ")\n",
    "\n",
    "malawi = malawi[malawi.num_adults + malawi.num_children > 0]\n",
    "summary['columns'] = summary.covariate.map(covariate_to_columns_map)\n",
    "\n",
    "# https://docs.google.com/spreadsheets/d/11I0U413LgiVYuvgPhVL1M-5bfJabCFql75tQWG551U0/edit#gid=0\n",
    "MALAWI_CONSUMPTION_CONVERSION_FACTOR = 0.00461055475\n",
    "\n",
    "# Convert outcome to consumption per capita per day in terms of 2017 USD\n",
    "#    1. Use conversion factor to convert to 2017 USD\n",
    "#    2. Divide by household size\n",
    "#    2. Convert consumption to consumption per day\n",
    "malawi[\"outcome\"] = malawi[\"rexpagg\"].copy()\n",
    "malawi[\"outcome\"] /= (malawi.num_adults + malawi.num_children)\n",
    "malawi[\"outcome\"] *= MALAWI_CONSUMPTION_CONVERSION_FACTOR\n",
    "malawi[\"outcome\"] /= 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "414638ce-ac07-44ac-b9c0-68d14ecc34c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    out_path = Path('/home/selker/eop/data/malawi')\n",
    "    malawi.to_parquet(out_path / 'malawi_cleaned_2016.parquet', index=False)\n",
    "    summary.set_index('covariate', drop=True).to_parquet(out_path / 'malawi_summary_2016.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66edb10-5cdd-4afe-a4d1-0f80315dfa93",
   "metadata": {},
   "source": [
    "### Calculate baseline poverty rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0308c791-b323-41c1-b0a6-697a1405ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path('/home/selker/eop/data/malawi')\n",
    "malawi = pd.read_parquet(out_path / 'malawi_cleaned_2016.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6817a47c-852b-4476-93fe-c95731ab705a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6417307692307692"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poverty_line = 2.15\n",
    "below = len(malawi[malawi.outcome < poverty_line])\n",
    "total = len(malawi)\n",
    "\n",
    "rate = below / total\n",
    "display(rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61fff03-9ba9-467c-8ce5-f098429d8dcc",
   "metadata": {},
   "source": [
    "## 2018 Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f27208f1-a490-4162-8711-caaf3d247ae4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/selker/eop/data/malawi/census_2018_pop_tables.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m census \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmalawi_directory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcensus_2018_pop_tables.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/leo_base/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/leo_base/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.conda/envs/leo_base/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/leo_base/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.conda/envs/leo_base/lib/python3.9/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/selker/eop/data/malawi/census_2018_pop_tables.csv'"
     ]
    }
   ],
   "source": [
    "census = pd.read_csv(malawi_directory / 'census_2018_pop_tables.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fb0662-8fed-4009-8b4b-37b266796c8e",
   "metadata": {},
   "source": [
    "# Cleaning section from select_predictors, for 2019 Malawi LSMS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48c71c0a-2fdc-4e1c-b734-19d35c2cb7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_equal(df, col1, col2):\n",
    "    c1 = df[col1]\n",
    "    c2 = df[col2]\n",
    "    \n",
    "    if pd.api.types.is_numeric_dtype(c1) and pd.api.types.is_numeric_dtype(c2):\n",
    "        return np.isclose(c1, c2, rtol=1e-4).all()\n",
    "    else:\n",
    "        return (c1 == c2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "123edb4d-f788-40d0-a76c-681f5f3e8dcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = Path('/home/selker/eop/data')\n",
    "\n",
    "malawi_directory = data_path / 'malawi'\n",
    "malawi_survey_directory_csv = malawi_directory / 'MWI_2019_IHS-V_v06_M_CSV'\n",
    "malawi_survey_directory_dta = malawi_directory / 'MWI_2019_IHS-V_v06_M_Stata'\n",
    "\n",
    "mosaiks_directory = data_path / 'mosaiks'\n",
    "\n",
    "RANDOM_STATE=11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ea1761-d62d-4c68-89dc-676070e7c823",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Load + process Mosaiks data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad478934-1130-47c6-a440-6a6b852c27ce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /home/selker/.conda/envs/leo_base_new/share/proj failed\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'within'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/leo_base_new/lib/python3.9/site-packages/dask_expr/_core.py:457\u001b[0m, in \u001b[0;36mExpr.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Projection' object has no attribute 'within'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/leo_base_new/lib/python3.9/site-packages/dask_expr/_collection.py:517\u001b[0m, in \u001b[0;36mFrameBase.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;66;03m# Fall back to `expr` API\u001b[39;00m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;66;03m# (Making sure to convert to/from Expr)\u001b[39;00m\n\u001b[0;32m--> 517\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(val):\n",
      "File \u001b[0;32m~/.conda/envs/leo_base_new/lib/python3.9/site-packages/dask_expr/_core.py:478\u001b[0m, in \u001b[0;36mExpr.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    477\u001b[0m link \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/dask-contrib/dask-expr/blob/main/README.md#api-coverage\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 478\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis often means that you are attempting to use an unsupported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI function. Current API coverage is documented here: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlink\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Projection' object has no attribute 'within'\n\nThis often means that you are attempting to use an unsupported API function. Current API coverage is documented here: https://github.com/dask-contrib/dask-expr/blob/main/README.md#api-coverage.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:23\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/leo_base_new/lib/python3.9/site-packages/dask_expr/_collection.py:523\u001b[0m, in \u001b[0;36mFrameBase.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;66;03m# Raise original error\u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[0;32m~/.conda/envs/leo_base_new/lib/python3.9/site-packages/dask_expr/_collection.py:512\u001b[0m, in \u001b[0;36mFrameBase.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;66;03m# Prioritize `FrameBase` attributes\u001b[39;00m\n\u001b[0;32m--> 512\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    515\u001b[0m             \u001b[38;5;66;03m# Fall back to `expr` API\u001b[39;00m\n\u001b[1;32m    516\u001b[0m             \u001b[38;5;66;03m# (Making sure to convert to/from Expr)\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'within'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def clean_mosaiks_column_name(column_name):\n",
    "    column_name_stripped = column_name.strip(' .')\n",
    "    try:\n",
    "        number = int(column_name_stripped)\n",
    "    except ValueError:\n",
    "        if column_name_stripped == '':\n",
    "            return 'mosaiks_0'\n",
    "        else:\n",
    "            return column_name\n",
    "    else:\n",
    "        return f'mosaiks_{number}'\n",
    "\n",
    "mosaiks = ddf.read_csv(str(mosaiks_directory / 'malawi_fine' / '*.csv'))\n",
    "malawi_outline = gpd.read_file(\n",
    "    malawi_directory / 'mwi_adm_nso_hotosm_20230405_shp' / 'mwi_admbnda_adm0_nso_hotosm_20230405.shp'\n",
    ")\n",
    "\n",
    "mosaiks = dgpd.from_dask_dataframe(\n",
    "    mosaiks, dgpd.points_from_xy(mosaiks, 'Lon', 'Lat')\n",
    ")\n",
    "\n",
    "# this data covers a box containing Malawi; filter down to the points actually within the country.\n",
    "mosaiks = mosaiks[mosaiks.geometry.within(malawi_outline.iloc[0].geometry)]\n",
    "\n",
    "mosaiks.columns = mosaiks.columns.map(clean_mosaiks_column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c60d6091-0fed-451c-bf19-14f0408ec5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_vars, _ = pyreadstat.read_dta(\n",
    "    malawi_survey_directory_dta / 'householdgeovariables_ihs5.dta'\n",
    ")\n",
    "\n",
    "# associate a moasiks tile with each enumeration area\n",
    "ea_geo = geo_vars.groupby('ea_id').first()[['ea_lat_mod', 'ea_lon_mod']]\n",
    "ea_geo = gpd.GeoDataFrame(ea_geo, geometry = gpd.points_from_xy(x=ea_geo.ea_lon_mod, y=ea_geo.ea_lat_mod))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b73032-5df2-47af-a848-35dff10b93b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaiks_grid_size = 1\n",
    "max_distance = math.sqrt(2 * (mosaiks_grid_size / 2)**2)\n",
    "\n",
    "mosaiks_computed = mosaiks.compute()\n",
    "\n",
    "ea_geo_with_mosaiks = gpd.sjoin_nearest(\n",
    "    left_df=ea_geo, right_df=mosaiks_computed, how='left', max_distance=mosaiks_grid_size\n",
    ")\n",
    "\n",
    "ea_geo_with_mosaiks.rename(\n",
    "    columns={'Lat': 'lat_mosaiks', 'Lon': 'lon_mosaiks', 'index_right': 'index_mosaiks'},\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "ea_geo_with_mosaiks.reset_index(inplace=True)\n",
    "ea_geo_with_mosaiks.ea_id = ea_geo_with_mosaiks.ea_id.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d9cc6a-14b1-4c63-84c6-40b9ed1e4f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ea_geo_with_mosaiks.drop(columns=['geometry', 'BoxLabel']).to_parquet('ea_geo_with_mosaiks.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "250c61df-23d1-475f-9681-f2565542fa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "ea_geo_with_mosaiks = pd.read_parquet('ea_geo_with_mosaiks.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5213fe6c-9ba5-42ae-a1c8-a53806041f07",
   "metadata": {},
   "source": [
    "### Load survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e0f8fac-002c-4194-ac96-9cf4c52b0ab2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error merging ag_mod_e3, mismatch in HHID\n",
      "error merging hh_mod_a_filt, mismatch in HHID\n",
      "error merging ihs5_consumption_aggregate, mismatch in region\n",
      "error merging ihs5_consumption_aggregate, mismatch in district\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/tmp/ipykernel_1712032/2262660627.py:107: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  malawi_to_process[c] = pd.to_numeric(malawi_to_process[c], errors='ignore')\n",
      "/data/tmp/ipykernel_1712032/2262660627.py:107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  malawi_to_process[c] = pd.to_numeric(malawi_to_process[c], errors='ignore')\n",
      "/data/tmp/ipykernel_1712032/2262660627.py:114: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  malawi_to_process[c] = malawi_to_process[c].astype(str)\n",
      "/data/tmp/ipykernel_1712032/2262660627.py:114: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  malawi_to_process[c] = malawi_to_process[c].astype(str)\n",
      "/data/tmp/ipykernel_1712032/2262660627.py:114: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  malawi_to_process[c] = malawi_to_process[c].astype(str)\n",
      "/data/tmp/ipykernel_1712032/2262660627.py:114: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  malawi_to_process[c] = malawi_to_process[c].astype(str)\n",
      "/data/tmp/ipykernel_1712032/2262660627.py:114: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  malawi_to_process[c] = malawi_to_process[c].astype(str)\n",
      "/data/tmp/ipykernel_1712032/2262660627.py:114: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  malawi_to_process[c] = malawi_to_process[c].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-dropping: num columns 4357\n",
      "dropping 144 columns\n",
      "post-dropping: num columns 4213\n"
     ]
    }
   ],
   "source": [
    "# https://docs.google.com/spreadsheets/d/1lHoEWEIhl7DR2SwFdHiBnBBuC75SzW39pDIVyNBh3JQ/edit#gid=1019974521\n",
    "malawi_consumption_conversion_factor = 0.003361742723912196\n",
    "\n",
    "malawi = None\n",
    "column_names_to_labels = dict()\n",
    "\n",
    "# malawi_directory.iterdir():\n",
    "for file in (\n",
    "    'HH_MOD_F',\n",
    "    'HH_MOD_H',\n",
    "    'HH_MOD_N1',\n",
    "    'HH_MOD_S2',\n",
    "    'HH_MOD_T',\n",
    "    'HH_MOD_X',\n",
    "    'ag_mod_a',\n",
    "    'ag_mod_e3',\n",
    "    'hh_mod_a_filt',\n",
    "    'ihs5_consumption_aggregate',\n",
    "    'householdgeovariables_ihs5'\n",
    "): \n",
    "    \n",
    "    # dataframe = pd.read_csv(malawi_survey_directory / file, low_memory=False)\n",
    "    # \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore') # TODO: Investigate. Warning thrown from w/in pyreadstat.\n",
    "\n",
    "        dataframe, metadata =  pyreadstat.read_dta(\n",
    "                malawi_survey_directory_dta / f'{file}.dta', apply_value_formats=True\n",
    "        )\n",
    "\n",
    "    column_names_to_labels.update(metadata.column_names_to_labels)\n",
    "    \n",
    "    # print(f'file: {file}, {dataframe.case_id.value_counts().head(10)}')\n",
    "    if malawi is None:\n",
    "        malawi = dataframe\n",
    "    else:\n",
    "        malawi = malawi.merge(dataframe, on='case_id', how='outer', suffixes=('_left', '_right'))    \n",
    "\n",
    "        for c in malawi.columns:\n",
    "            if c.endswith('_left'):\n",
    "                c_left = c\n",
    "                base = c_left[:-5]\n",
    "                c_right = f'{base}_right'\n",
    "\n",
    "                # sometimes categorical types mess up this check; fail conservatively\n",
    "                try:\n",
    "                    match = columns_equal(malawi, c_left, c_right)\n",
    "                except:\n",
    "                    match = False\n",
    "                \n",
    "                if match:\n",
    "                    malawi.drop(columns=c_left, inplace=True)\n",
    "                    malawi.rename(columns={c_right: base}, inplace=True)\n",
    "                # geographies are sometimes named and sometimes encoded as integers. If we've got one of each,  \n",
    "                # keep the string name: that way it won't accidentally be treated as numeric later.\n",
    "                elif (\n",
    "                    (base in ['region', 'district'])\n",
    "                    & (\n",
    "                        pd.api.types.is_numeric_dtype(malawi[c_left]) \n",
    "                        + pd.api.types.is_numeric_dtype(malawi[c_right]) \n",
    "                        == 1\n",
    "                      )\n",
    "                ):\n",
    "                    if pd.api.types.is_numeric_dtype(malawi[c_left]):\n",
    "                        malawi.drop(columns=c_left, inplace=True)\n",
    "                        malawi.rename(columns={c_right: base}, inplace=True)\n",
    "                    else:\n",
    "                        malawi.drop(columns=c_right, inplace=True)\n",
    "                        malawi.rename(columns={c_left: base}, inplace=True)\n",
    "                else:\n",
    "                    # print(pd.api.types.is_numeric_dtype(c_left) + pd.api.types.is_numeric_dtype(c_right))\n",
    "                    print(f'error merging {file}, mismatch in {base}')\n",
    "                    # TODO: Examine these cases\n",
    "                    malawi.drop(columns=c_left, inplace=True)\n",
    "                    malawi.rename(columns={c_right: base}, inplace=True)\n",
    "\n",
    "# Add Mosaiks columns. \n",
    "malawi.ea_id = malawi.ea_id.astype(int)\n",
    "malawi = malawi.merge(\n",
    "    ea_geo_with_mosaiks, on='ea_id', how='outer'\n",
    ")\n",
    "\n",
    "for c in ('ea_lat_mod', 'ea_lon_mod'):\n",
    "    malawi.drop(columns=f'{c}_x', inplace=True)\n",
    "    malawi.rename(columns={f'{c}_y' : c}, inplace=True)\n",
    "\n",
    "# save to allow exporting parts of this data later\n",
    "malawi_raw = malawi\n",
    "\n",
    "# Drop rows that are missing critical fields which we don't want to impute.\n",
    "malawi.dropna(subset=['HHID', 'rexpaggpc'], inplace=True)\n",
    "\n",
    "# TODO: Figure out how to detect datetime-like columns automatically\n",
    "malawi['interviewDate'] = pd.to_datetime(malawi['interviewDate'])\n",
    "\n",
    "# columns not to be imputed, coerced to numeric, or one-hot encoded.\n",
    "# summary table won't include these either - for now, this seems fine. \n",
    "columns_to_reserve = [\n",
    "    'HHID', 'case_id', 'hh_wgt', 'interviewDate'\n",
    "]\n",
    "malawi_reserved = malawi[columns_to_reserve]\n",
    "malawi_to_process = malawi[malawi.columns.difference(columns_to_reserve)]\n",
    "\n",
    "# coerce columns to numeric that can be coerced\n",
    "for c in malawi_to_process.columns:\n",
    "    malawi_to_process[c] = pd.to_numeric(malawi_to_process[c], errors='ignore')\n",
    "\n",
    "# coerce known categorical columns to string\n",
    "known_categorical = [\n",
    "    'region', 'district', 'hh_t01', 'hh_t02', 'hh_t03', 'hh_t04'\n",
    "]\n",
    "for c in known_categorical:\n",
    "    malawi_to_process[c] = malawi_to_process[c].astype(str)\n",
    "\n",
    "# Before imputing or dropping highly-missing columns, summarize columns\n",
    "missing_counts = malawi_to_process.isnull().sum()+ (malawi_to_process == \"\").sum()  \n",
    "means = malawi_to_process.mean(skipna=True, numeric_only=True)\n",
    "medians = malawi_to_process.median(skipna=True, numeric_only=True)\n",
    "stds = malawi_to_process.std(skipna=True, numeric_only=True)\n",
    "summary = pd.concat((missing_counts, means, medians, stds), axis=1)\n",
    "summary.columns = ['missing_count', 'mean', 'median', 'std']\n",
    "summary.reset_index(names='covariate', inplace=True)\n",
    "\n",
    "# Drop highly missing columns.\n",
    "print(f'pre-dropping: num columns {len(malawi_to_process.columns)}')\n",
    "threshold = 0.15\n",
    "\n",
    "missing_percent = missing_counts  / len(malawi_to_process)\n",
    "dropped_for_missingness = malawi_to_process[missing_percent[missing_percent >= threshold].index].columns\n",
    "malawi_to_process = malawi_to_process[missing_percent[missing_percent < threshold].index] \n",
    "not_dropped_for_missingness = [c for c in malawi_to_process.columns if c not in dropped_for_missingness]\n",
    "\n",
    "print(f'dropping {len(dropped_for_missingness)} columns')\n",
    "print(f'post-dropping: num columns {len(malawi_to_process.columns)}')\n",
    "\n",
    "# Split into numeric and non-numeric columns\n",
    "malawi_numeric = malawi_to_process.select_dtypes(include=[np.number])\n",
    "malawi_non_numeric = malawi_to_process.select_dtypes(exclude=[np.number, np.datetime64])\n",
    "\n",
    "def get_covariate_type(cov):\n",
    "    \n",
    "    if cov in malawi_numeric.columns:\n",
    "        return 'numeric'\n",
    "    elif cov in malawi_non_numeric.columns:\n",
    "        return 'categorical'\n",
    "    else:\n",
    "        return 'dropped'\n",
    "\n",
    "summary['type'] = summary['covariate'].apply(get_covariate_type)\n",
    "\n",
    "# impute missing values\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(malawi_numeric)\n",
    "\n",
    "columns = malawi_numeric.columns\n",
    "malawi_numeric = pd.DataFrame(imputer.transform(malawi_numeric))\n",
    "malawi_numeric.columns = columns\n",
    "\n",
    "# one-hot encode categoricals: First, fill missing values.\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value='MISSING')\n",
    "imputer.fit(malawi_non_numeric)\n",
    "imputer.transform(malawi_non_numeric)\n",
    "\n",
    "# next, one-hot encode\n",
    "one_hot_encoder = sklearn_preprocessing.OneHotEncoder(\n",
    "    drop='if_binary', sparse_output=False\n",
    ").fit(malawi_non_numeric)\n",
    "encoded_data = one_hot_encoder.transform(malawi_non_numeric)\n",
    "malawi_non_numeric_encoded = pd.DataFrame(encoded_data)\n",
    "malawi_non_numeric_encoded.columns = one_hot_encoder.get_feature_names_out()\n",
    "\n",
    "# Set up a map from original column names to the list of one-hot columns. We'll use it later.\n",
    "one_hot_map = dict()\n",
    "for i in range(len(one_hot_encoder.feature_names_in_)):\n",
    "    \n",
    "    categories = one_hot_encoder.categories_[i]\n",
    "    if one_hot_encoder.drop_idx_[i] is not None:\n",
    "        categories = np.delete(categories, one_hot_encoder.drop_idx_[i])\n",
    "\n",
    "    one_hot_map[one_hot_encoder.feature_names_in_[i]] = categories\n",
    "\n",
    "malawi = malawi_reserved.join(malawi_numeric).join(malawi_non_numeric_encoded)\n",
    "\n",
    "malawi['consumption_ppp_2017'] = malawi.rexpaggpc * malawi_consumption_conversion_factor\n",
    "\n",
    "# create map from one-hot columns to original columns + values\n",
    "inverse_one_hot_map = dict()\n",
    "for feature, categories in one_hot_map.items():\n",
    "    for category in categories:\n",
    "        inverse_one_hot_map[f'{feature}_{category}'] = (feature, category)\n",
    "\n",
    "def interpret_column_name(column_name):\n",
    "\n",
    "    if column_name in inverse_one_hot_map:\n",
    "        original_column_name, value = inverse_one_hot_map[column_name]\n",
    "        return f'Covariate: {column_names_to_labels[original_column_name]}, value: {value}'\n",
    "\n",
    "    elif column_name in column_names_to_labels:\n",
    "        return column_names_to_labels[column_name]\n",
    "\n",
    "    return column_name\n",
    "\n",
    "summary['description'] = summary.covariate.apply(interpret_column_name)\n",
    "summary['missing_fraction'] = summary['missing_count'] / len(malawi)\n",
    "\n",
    "summary.missing_fraction = summary.missing_fraction.round(2)\n",
    "summary['median'] = summary['median'].round(2)\n",
    "summary['mean'] = summary['mean'].round(2)\n",
    "summary['std'] = summary['std'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "60184b7d-678b-4156-a8a3-6c2c3eb9a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    \n",
    "    malawi_raw.to_parquet('/home/selker/eop/data/malawi/malawi_merged.parquet', index=False)\n",
    "\n",
    "    pd.DataFrame.from_dict(\n",
    "        column_names_to_labels, orient='index', columns=['description']\n",
    "    ).reset_index(names='covariate').to_csv('column_description_map.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dc26ad-a6e3-4add-8e99-496186626152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leo_base",
   "language": "python",
   "name": "leo_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
