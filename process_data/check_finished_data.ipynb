{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import itertools\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "\n",
    "from opt_targeted_transfers import standardize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from opt_targeted_transfers import Dataset, split\n",
    "def get_row_from_metadata(metadata, covariate_name):\n",
    "    \"\"\"\n",
    "    Extracts a specific row from the metadata DataFrame based on the covariate name.\n",
    "\n",
    "    :param metadata: DataFrame containing metadata.\n",
    "    :param covariate_name: Name of the covariate to extract.\n",
    "    :return: Row corresponding to the specified covariate name.\n",
    "    \"\"\"\n",
    "    return metadata.loc[metadata['variable_name'] == covariate_name].squeeze()\n",
    "\n",
    "def all_rows_from_metadata_containing(metadata, substring):\n",
    "    \"\"\"\n",
    "    Extracts all rows from the metadata DataFrame that contain a specific substring in the variable name.\n",
    "\n",
    "    :param metadata: DataFrame containing metadata.\n",
    "    :param substring: Substring to search for in the variable names.\n",
    "    :return: DataFrame containing all rows with variable names that contain the substring.\n",
    "    \"\"\"\n",
    "    return metadata[metadata['variable_name'].str.contains(substring, na=False)].reset_index(drop=True)\n",
    "\n",
    "def all_column_names_containing(df, substring):\n",
    "    \"\"\"\n",
    "    Extracts all column names from the DataFrame that contain a specific substring.\n",
    "\n",
    "    :param df: DataFrame to search for column names.\n",
    "    :param substring: Substring to search for in the column names.\n",
    "    :return: List of column names containing the specified substring.\n",
    "    \"\"\"\n",
    "    return [col for col in df.columns if substring in col]\n",
    "\n",
    "\n",
    "def find_equivalent_columns(data, summary, numeric_tolerance=1e-6, categorical_threshold=0.99):\n",
    "    \"\"\"\n",
    "    Find pairs of columns in a DataFrame that are informationally equivalent.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas DataFrame\n",
    "        The DataFrame to analyze\n",
    "    numeric_tolerance : float, default 1e-6\n",
    "        Tolerance for considering numeric columns equal or proportional\n",
    "    categorical_threshold : float, default 0.99\n",
    "        Threshold for considering categorical columns equivalent (percentage match)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list of tuples\n",
    "        Each tuple contains (col1, col2, relationship_type)\n",
    "        where relationship_type is one of: 'identical', 'proportional', 'categorical_equivalent'\n",
    "    \"\"\"\n",
    "    equivalent_pairs = []\n",
    "    columns = data.columns\n",
    "    \n",
    "    # Get column types\n",
    "    \n",
    "    numeric_cols = summary[summary.data_type == 'numeric'].variable_name.tolist()\n",
    "    categorical_cols = summary[summary.data_type == 'categorical'].variable_name.tolist()\n",
    "\n",
    "    # Identify constant columns\n",
    "    constant_cols = []\n",
    "    for col in columns:\n",
    "        unique_values = data[col].dropna().unique()\n",
    "        if len(unique_values) <= 1:\n",
    "            constant_cols.append(col)\n",
    "\n",
    "    # Print constant columns if verbose\n",
    "    if len(constant_cols) > 0:\n",
    "        print(\"Constant columns:\")\n",
    "        for col in constant_cols:\n",
    "            print(col)\n",
    "        print()\n",
    "    \n",
    "\n",
    "    # Remove constant columns from numeric and categorical lists\n",
    "    numeric_cols = [col for col in numeric_cols if col not in constant_cols]\n",
    "    categorical_cols = [col for col in categorical_cols if col not in constant_cols]\n",
    "\n",
    "    # remove missingness-indicator columns\n",
    "    missingness_cols = list(\n",
    "        set(all_column_names_containing(data, '_missing') + \n",
    "        all_column_names_containing(data, '_m'))\n",
    "    )\n",
    "    numeric_cols = [col for col in numeric_cols if col not in missingness_cols]\n",
    "    categorical_cols = [col for col in categorical_cols if col not in missingness_cols]\n",
    "    \n",
    "    # Check numeric columns for equality or proportionality\n",
    "    for col1, col2 in itertools.combinations(numeric_cols, 2):\n",
    "\n",
    "        # Check for identical values first\n",
    "        if data[col1].equals(data[col2]):\n",
    "            equivalent_pairs.append((col1, col2, 'identical'))\n",
    "            continue\n",
    "            \n",
    "        # Check for identical values where neither is zero\n",
    "        valid_mask = ~data[col1].isna() & ~data[col2].isna()\n",
    "        if np.allclose(data.loc[valid_mask, col1], data.loc[valid_mask, col2], \n",
    "                      rtol=numeric_tolerance, atol=numeric_tolerance):\n",
    "            equivalent_pairs.append((col1, col2, 'nearly_identical'))\n",
    "            continue\n",
    "        \n",
    "        # For rows with zeros, check if the columns are exactly equal\n",
    "        zero_mask = (data[col1] == 0) | (data[col2] == 0)\n",
    "        non_zero_mask = ~zero_mask & valid_mask\n",
    "        \n",
    "        # Check if the columns have the same values where zeros are present\n",
    "        if zero_mask.any():\n",
    "            zero_equality = (data.loc[zero_mask & valid_mask, col1] == \n",
    "                             data.loc[zero_mask & valid_mask, col2]).all()\n",
    "        else:\n",
    "            zero_equality = True\n",
    "            \n",
    "        # Check for proportional relationship in non-zero values\n",
    "        if non_zero_mask.sum() > 10:  # Require at least some non-zero values\n",
    "            ratios = data.loc[non_zero_mask, col2] / data.loc[non_zero_mask, col1]\n",
    "            ratio_std = ratios.std()\n",
    "            \n",
    "            # If standard deviation of ratios is very small, columns are proportional\n",
    "            if ratio_std < numeric_tolerance and zero_equality:\n",
    "                ratio = ratios.mean()\n",
    "                equivalent_pairs.append((col1, col2, f'proportional (factor: {ratio:.4f})'))\n",
    "    \n",
    "    # Create a list of all columns to check for categorical equivalence\n",
    "    # This includes both explicit categorical columns and numeric columns\n",
    "    all_potential_categorical_cols = categorical_cols + numeric_cols\n",
    "    \n",
    "    # Check all columns for equivalent categorical mappings\n",
    "    for col1, col2 in itertools.combinations(all_potential_categorical_cols, 2):\n",
    "        # Skip if identical columns or already identified as identical or proportional\n",
    "        if col1 == col2 or any((col1, col2, rel) in equivalent_pairs for rel in \n",
    "                               ['identical', 'nearly_identical', 'proportional']):\n",
    "            continue\n",
    "            \n",
    "        # Get unique values for both columns\n",
    "        unique_vals1 = data[col1].dropna().unique()\n",
    "        unique_vals2 = data[col2].dropna().unique()\n",
    "        \n",
    "        # Skip if columns have different number of unique values\n",
    "        if len(unique_vals1) != len(unique_vals2):\n",
    "            continue\n",
    "            \n",
    "        # Skip if too many unique values (likely not categorical)\n",
    "        if len(unique_vals1) > 100:  # Arbitrary threshold, adjust as needed\n",
    "            continue\n",
    "            \n",
    "        # Create a mapping table between values in both columns\n",
    "        mapping_df = data[[col1, col2]].dropna().drop_duplicates()\n",
    "        \n",
    "        # Check if mapping is one-to-one (each value in col1 maps to exactly one value in col2)\n",
    "        is_one_to_one = True\n",
    "        \n",
    "        # Check col1 -> col2 mapping\n",
    "        for val in unique_vals1:\n",
    "            corresponding_vals = data.loc[data[col1] == val, col2].dropna().unique()\n",
    "            if len(corresponding_vals) != 1:\n",
    "                is_one_to_one = False\n",
    "                break\n",
    "                \n",
    "        # Check col2 -> col1 mapping\n",
    "        if is_one_to_one:\n",
    "            for val in unique_vals2:\n",
    "                corresponding_vals = data.loc[data[col2] == val, col1].dropna().unique()\n",
    "                if len(corresponding_vals) != 1:\n",
    "                    is_one_to_one = False\n",
    "                    break\n",
    "        \n",
    "        if is_one_to_one:\n",
    "            # If we create a new column using the mapping, it should match the original\n",
    "            val_mapping = dict(zip(mapping_df[col1], mapping_df[col2]))\n",
    "            \n",
    "            # Apply mapping and handle NaN values\n",
    "            mapped_values = data[col1].map(val_mapping)\n",
    "            \n",
    "            # Count matches (ignoring NaN values)\n",
    "            valid_mask = ~data[col1].isna() & ~data[col2].isna()\n",
    "            if valid_mask.sum() > 0:\n",
    "                match_percentage = (mapped_values == data[col2])[valid_mask].mean()\n",
    "                \n",
    "                if match_percentage >= categorical_threshold:\n",
    "                    # Determine if both are numeric or mixed types\n",
    "                    if col1 in numeric_cols and col2 in numeric_cols:\n",
    "                        relationship = 'numeric_categorical_equivalent'\n",
    "                    else:\n",
    "                        relationship = 'categorical_equivalent'\n",
    "                    equivalent_pairs.append((col1, col2, relationship))\n",
    "    \n",
    "    return equivalent_pairs\n",
    "\n",
    "\n",
    "\n",
    "def get_data_for_geo_extrapolation(data, summary, geo_extrapolation):\n",
    "    \"\"\"\n",
    "    Preprocess the testing data for geo-extrapolation.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The input data.\n",
    "        summary (pd.DataFrame): The summary data.\n",
    "    Returns:\n",
    "        pd.DataFrame: The preprocessed data without geographic identifiers\n",
    "    \"\"\"\n",
    "\n",
    "    geo_cols = summary[summary[\"geographic_indicator\"] == True][\n",
    "        \"variable_name\"\n",
    "    ].tolist()\n",
    "\n",
    "    coarse_geo_cols = summary[summary[\"geographic_indicator_coarser\"] == True][\n",
    "        \"variable_name\"\n",
    "    ].tolist()\n",
    "\n",
    "    remove_for_coarse = set(geo_cols) - set(coarse_geo_cols)\n",
    "    remove_for_coarse = list(remove_for_coarse)\n",
    "\n",
    "    if geo_extrapolation:\n",
    "        data = data.drop(columns=remove_for_coarse)\n",
    "    else:\n",
    "        1/0\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_datasets(\n",
    "    trainpath, testpath, summarypath, geo_extrapolation, outcome='consumption_per_day_per_capita', weight='headcount_adjusted_hh_wgt'\n",
    "):\n",
    "    \"\"\"\n",
    "    Load datasets.\n",
    "\n",
    "    Args:\n",
    "        trainpath (str): Path to the training data file.\n",
    "        testpath (str): Path to the test data file.\n",
    "        outcome (str): Outcome variable.\n",
    "        weight (str): Weight variable.\n",
    "\n",
    "    Returns:\n",
    "        train_dataset (Dataset): Training dataset.\n",
    "        test_dataset (Dataset): Test dataset.\n",
    "    \"\"\"\n",
    "    data1 = _load_data(trainpath)\n",
    "    data2 = _load_data(testpath)\n",
    "    summary = pd.read_parquet(summarypath)\n",
    "\n",
    "    data1 = get_data_for_geo_extrapolation(data1, summary, geo_extrapolation)\n",
    "    data2 = get_data_for_geo_extrapolation(data2, summary, geo_extrapolation)\n",
    "\n",
    "    all_data = pd.concat([data1, data2], ignore_index=True)\n",
    "    all_data = convert_to_onehot(all_data, summary)\n",
    "\n",
    "    train_data = _load_data(trainpath)\n",
    "    test_data = _load_data(testpath)\n",
    "    train_data = get_data_for_geo_extrapolation(train_data, summary, geo_extrapolation)\n",
    "    test_data = get_data_for_geo_extrapolation(test_data, summary, geo_extrapolation)\n",
    "    covs = list(train_data.columns)\n",
    "    covs.remove(outcome)\n",
    "    covs.remove(weight)\n",
    "\n",
    "    train_data = convert_to_onehot(train_data, summary)\n",
    "    test_data = convert_to_onehot(test_data, summary)\n",
    "\n",
    "    train_missing_columns = set(all_data.columns) - set(train_data.columns)\n",
    "    res = [train_data]\n",
    "    for col in train_missing_columns:\n",
    "        res.append(pd.DataFrame({col: np.zeros(len(train_data))}))\n",
    "    final_train_data = pd.concat(res, axis=1)\n",
    "\n",
    "    test_missing_columns = set(all_data.columns) - set(test_data.columns)\n",
    "    res = [test_data]\n",
    "    for col in test_missing_columns:\n",
    "        res.append(pd.DataFrame({col: np.zeros(len(test_data))}))\n",
    "    final_test_data = pd.concat(res, axis=1)\n",
    "\n",
    "    train_dataset = Dataset(\n",
    "        final_train_data.astype(\"float32\"), outcome=outcome, covs=covs, weight=weight\n",
    "    )\n",
    "    test_dataset = Dataset(\n",
    "        final_test_data.astype(\"float32\"), outcome=outcome, covs=covs, weight=weight\n",
    "    )\n",
    "    test_covariate_dataset = Dataset(\n",
    "        final_test_data.astype(\"float32\"), outcome=None, covs=covs, weight=weight\n",
    "    )\n",
    "\n",
    "    train_dataset, validation_dataset = split(train_dataset)\n",
    "    return train_dataset, validation_dataset, test_covariate_dataset, test_dataset\n",
    "\n",
    "\n",
    "def convert_to_onehot(df, summary):\n",
    "    \"\"\"\n",
    "    Convert categorical columns to one-hot encoding.\n",
    "\n",
    "    :param df: The input data.\n",
    "    :type df: pandas.DataFrame\n",
    "    :return new_df: The input data with one-hot encoding.\n",
    "    :rtype: pandas.DataFrame\n",
    "    \"\"\"\n",
    "    if \"type\" in summary.columns:\n",
    "        data_type = \"type\"\n",
    "    elif \"data_type\" in summary.columns:\n",
    "        data_type = \"data_type\"\n",
    "    if \"covariate\" in summary.columns:\n",
    "        covariate = \"covariate\"\n",
    "    elif \"variable_name\" in summary.columns:\n",
    "        covariate = \"variable_name\"\n",
    "\n",
    "    categorical_columns = summary[summary[data_type] == \"categorical\"][\n",
    "        covariate\n",
    "    ].tolist()\n",
    "\n",
    "    categorical_columns = [col for col in categorical_columns if col in df.columns]\n",
    "\n",
    "    one_hot = pd.get_dummies(df[categorical_columns]).astype(np.float32)\n",
    "    df.drop(columns=categorical_columns, inplace=True)\n",
    "    new_df = pd.concat([df, one_hot], axis=1)\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def _load_data(path):\n",
    "    \"\"\"\n",
    "    Load data.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the data file.\n",
    "\n",
    "    Returns:\n",
    "        data_for_wgan (pd.DataFrame): Data for WGAN training.\n",
    "        data_wrapper (wgan.DataWrapper): DataWrapper object for WGAN training.\n",
    "    \"\"\"\n",
    "    data = pd.read_parquet(path)\n",
    "\n",
    "    if \"hhid\" in data.columns:\n",
    "        data = data.drop(columns=[\"hhid\"])\n",
    "    if \"case_id\" in data.columns:\n",
    "        data = data.drop(columns=[\"case_id\"])\n",
    "    if \"hh_id\" in data.columns:\n",
    "        data = data.drop(columns=[\"hh_id\"])\n",
    "    if \"hh_wgt\" in data.columns:\n",
    "        data = data.drop(columns=[\"hh_wgt\"])\n",
    "\n",
    "    return data.reset_index(drop=True)\n",
    "\n",
    "\"\"\"\n",
    "Done in this notebook\n",
    "- Ensure that missingness-indicator columns exist.\n",
    "    - You probably can't conclusively check that all are included, because the data you get will not necessarily reveal which columns had missingness, but check that there are some missingness columns, and none for categorical data.\n",
    "- Ensure there are no NaNs in the data.\n",
    "- Ensure column names:\n",
    "    - In data: \"hhid\" (if household ID is included), \"consumption_per_capita_per_day\", \"hh_wgt\".\n",
    "    - Consumption: Check mean and std for sanity. In a poor country, the mean should be low-mid single digits: e.g., in Uganda, the mean is $3.80/day.\n",
    "- Check for columns that indicate units:\n",
    "    - If they are present, the corresponding numeric field should be standardized, e.g., all area units adjusted to square meters.\n",
    "- Check that metadata and the dataset itself match:\n",
    "    - Every column in data is described in metadata and vice versa. It's also OK if `hhid` is not in the data at all.\n",
    "- In metadata:\n",
    "    - \"variable_name\".\n",
    "    - \"data_type\", with permitted values \"numeric\" and \"categorical\".\n",
    "    - \"geographic_indicator\".\n",
    "- Scan datatypes:\n",
    "    - In particular, make sure nothing is numeric which should be categorical.\n",
    "    - Ensure categorical-type columns have the appropriate type even if the categories are encoded as integers (if a column is binary, with no missing values, it can be numeric or categorical).\n",
    "    - IDs of all kinds are strings even if they appear numeric.\n",
    "- Check for duplication\n",
    "- Check feasibility of stratification\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in: Ethiopia\n"
     ]
    }
   ],
   "source": [
    "data_path = Path('/data/eop/country_data')\n",
    "\n",
    "data, summary, proposed_stratifier = None, None, None\n",
    "\n",
    "country = 'Ethiopia'  # Change this to the desired country\n",
    "\n",
    "if country == 'Burkina Faso':\n",
    "    country_data_path = data_path / 'burkina_faso' / 'cleaned'\n",
    "    data = pd.read_parquet(\n",
    "        data_path / 'burkina_faso' / 'cleaned' / 'burkinafaso_final_data.parquet'\n",
    "    )\n",
    "    summary = pd.read_parquet(\n",
    "        data_path / 'burkina_faso' / 'cleaned' / 'summary.parquet'\n",
    "    )\n",
    "    proposed_stratifier = 'region'\n",
    "elif country == 'Benin':\n",
    "    country_data_path = data_path / 'benin' / 'cleaned'\n",
    "    data = pd.read_parquet(country_data_path / 'benin_data.parquet')\n",
    "    summary = pd.read_parquet(country_data_path / 'summary.parquet')\n",
    "    proposed_stratifier = 'region'\n",
    "elif country == 'Cote dIvoire':\n",
    "    country_data_path = data_path / 'cote_divoire' / 'cleaned'\n",
    "\n",
    "    data = pd.read_parquet(\n",
    "        data_path / 'cote_divoire' / 'cleaned' / 'cotedivoire_cleaned_data.parquet'\n",
    "    )\n",
    "\n",
    "    summary = pd.read_parquet(\n",
    "        data_path / 'cote_divoire' / 'cleaned' / 'summary.parquet'\n",
    "    )\n",
    "    proposed_stratifier = 'region'\n",
    "elif country == 'Guinea-Bissau':\n",
    "    country_data_path = data_path / 'guinea-bissau' / 'cleaned'\n",
    "\n",
    "    data = pd.read_parquet(\n",
    "        data_path / 'guinea-bissau' / 'cleaned' / 'final_gb_dataset.parquet'\n",
    "    )\n",
    "    summary = pd.read_parquet(\n",
    "        data_path / 'guinea-bissau' / 'cleaned' / 'summary.parquet'\n",
    "    )\n",
    "    proposed_stratifier = 'region'\n",
    "elif country == 'Mali':\n",
    "    country_data_path = data_path / 'mali' / 'cleaned'\n",
    "    data = pd.read_parquet(\n",
    "        data_path / 'mali' / 'cleaned' / 'final_mali_dataset.parquet'\n",
    "    )\n",
    "    summary = pd.read_parquet(\n",
    "        data_path / 'mali' / 'cleaned' / 'summary.parquet'\n",
    "    )\n",
    "    proposed_stratifier = 'region'\n",
    "elif country == 'Somalia':\n",
    "    country_data_path = data_path / 'somalia' / 'cleaned'\n",
    "    data = pd.read_parquet(\n",
    "        data_path / 'somalia' / 'cleaned' / 'somalia_lsms_final.parquet'\n",
    "    )\n",
    "    summary = pd.read_parquet(\n",
    "        data_path / 'somalia' / 'cleaned' / 'summary.parquet'\n",
    "    )\n",
    "    proposed_stratifier = 'region'\n",
    "elif country == 'Albania': \n",
    "    country_data_path = data_path / 'albania' / 'cleaned'\n",
    "    data = pd.read_parquet(\n",
    "        data_path / 'albania' / 'cleaned' / 'albania_all.parquet'\n",
    "    )\n",
    "    summary = pd.read_parquet(\n",
    "        data_path / 'albania' / 'cleaned' / 'summary.parquet'\n",
    "    )\n",
    "elif country == 'Uganda':\n",
    "    country_data_path = data_path / 'uganda' / 'cleaned'\n",
    "    data = pd.read_parquet(\n",
    "        data_path / 'uganda' / 'cleaned' / 'uganda_full.parquet'\n",
    "    )\n",
    "    summary = pd.read_parquet(\n",
    "        data_path / 'uganda' / 'cleaned' / 'summary.parquet'\n",
    "    )\n",
    "    proposed_stratifier='region'\n",
    "elif country == 'Niger':\n",
    "    country_data_path = data_path / 'niger' / 'cleaned'\n",
    "    data = pd.read_parquet(\n",
    "        data_path / 'niger' / 'cleaned' / 'niger_2018.parquet'\n",
    "    )\n",
    "    summary = pd.read_parquet(\n",
    "        data_path / 'niger' / 'cleaned' / 'summary.parquet'\n",
    "    )\n",
    "    proposed_stratifier = 's00q01' # region\n",
    "elif country == 'Malawi':\n",
    "    country_data_path = data_path / 'malawi' / 'cleaned'\n",
    "    data = pd.read_parquet(data_path / 'malawi/cleaned/malawi_2019.parquet')\n",
    "    summary = pd.read_parquet(data_path / 'malawi/cleaned/summary.parquet')\n",
    "    summary.rename(columns={'description': 'variable_description'}, inplace=True)\n",
    "    proposed_stratifier = 'ea_id'\n",
    "elif country == 'Ghana_nolan':\n",
    "    country_data_path = data_path / 'ghana_nolan' / 'cleaned'\n",
    "    data = pd.read_parquet('/data/eop/ghana_nolan/cleaned/ghana_data.parquet')\n",
    "    summary = pd.read_parquet('/data/eop/ghana_nolan/cleaned/summary.parquet')\n",
    "    proposed_stratifier = 'region'\n",
    "elif country == 'Ghana_henry':\n",
    "    country_data_path = data_path / 'ghana_henry' / 'cleaned'\n",
    "    data = pd.read_parquet('/data/eop/ghana_henry/cleaned/ghana_data.parquet')\n",
    "    summary = pd.read_parquet('/data/eop/ghana_henry/cleaned/summary.parquet')\n",
    "    proposed_stratifier = 'region'\n",
    "elif country == 'Togo':\n",
    "    country_data_path = data_path / 'Togo 2018-19' / 'clean'\n",
    "    data = pd.read_parquet('/data/eop/Togo 2018-19/clean/final_togo.parquet')\n",
    "    summary = pd.read_parquet('/data/eop/Togo 2018-19/clean/summary.parquet')\n",
    "    proposed_stratifier = 'cluster_id'\n",
    "elif country == 'Togo_only_cdr':\n",
    "    country_data_path = data_path / 'Togo 2018-19' / 'clean' / 'cdr_features'\n",
    "\n",
    "    data = pd.read_parquet('/data/eop/Togo 2018-19/clean/cdr_features/togo.parquet')\n",
    "    summary = pd.read_parquet('/data/eop/Togo 2018-19/clean/cdr_features/summary.parquet')\n",
    "\n",
    "elif country == 'Togo_survey_and_cdr':    \n",
    "    country_data_path = data_path / 'Togo 2018-19' / 'clean' / 'cdr_features_and_survey_predictors'\n",
    "\n",
    "    data = pd.read_parquet('/data/eop/Togo 2018-19/clean/cdr_features_and_survey_predictors/togo.parquet')\n",
    "    summary = pd.read_parquet('/data/eop/Togo 2018-19/clean/cdr_features_and_survey_predictors/summary.parquet')\n",
    "    proposed_stratifier = 'cluster_id'\n",
    "\n",
    "elif country == 'Ethiopia':\n",
    "    country_data_path = data_path / 'Ethiopia 2018-19' / 'clean'\n",
    "    data = pd.read_parquet('/data/eop/Ethiopia 2018-19/clean/final_ethiopia.parquet')\n",
    "    summary = pd.read_parquet('/data/eop/Ethiopia 2018-19/clean/summary.parquet')\n",
    "    proposed_stratifier = 'region_zone'\n",
    "elif country == 'Nigeria':\n",
    "    country_data_path = data_path / 'Nigeria 2018-19' / 'clean'\n",
    "    data = pd.read_parquet('/data/eop/Nigeria 2018-19/clean/final_nigeria.parquet')\n",
    "    summary = pd.read_parquet('/data/eop/Nigeria 2018-19/clean/summary.parquet')\n",
    "    proposed_stratifier = 'ea_id'\n",
    "\n",
    "elif country == 'Kenya':\n",
    "    country_data_path = data_path / 'kenya' / 'cleaned'\n",
    "    data = pd.read_parquet('/data/eop/kenya/cleaned/kenya.parquet')\n",
    "    summary = pd.read_parquet('/data/eop/kenya/cleaned/summary.parquet')\n",
    "    proposed_stratifier = 'county'\n",
    "elif country == 'Tanzania':\n",
    "    country_data_path = data_path / 'Tanzania_2020-21' / 'cleaned'\n",
    "    data = pd.read_parquet('/data/eop/Tanzania_2020-21/cleaned/tanzania_data.parquet')\n",
    "    summary = pd.read_parquet('/data/eop/Tanzania_2020-21/cleaned/summary.parquet')\n",
    "    proposed_stratifier = 'region'\n",
    "elif country == 'Madagascar':\n",
    "    country_data_path = data_path / 'Madagascar 2010-11' / 'cleaned'\n",
    "    data = pd.read_parquet('/data/eop/Madagascar 2010-11/cleaned/madagascar_data.parquet')\n",
    "    summary = pd.read_parquet('/data/eop/Madagascar 2010-11/cleaned/summary.parquet')\n",
    "    proposed_stratifier = 'REGION'\n",
    "elif country == 'South Sudan':\n",
    "    country_data_path = data_path / 'south_sudan' / 'cleaned'\n",
    "    data = pd.read_parquet('/data/eop/south_sudan/cleaned/south_sudan_data.parquet')\n",
    "    summary = pd.read_parquet('/data/eop/south_sudan/cleaned/summary.parquet')\n",
    "    proposed_stratifier = 'ea'\n",
    "elif country == 'South Africa':\n",
    "    country_data_path = data_path / 'south_africa' / 'cleaned'\n",
    "    data = pd.read_parquet('/data/eop/south_africa/cleaned/south_africa_output.parquet')\n",
    "    summary = pd.read_parquet('/data/eop/south_africa/cleaned/summary.parquet')\n",
    "    proposed_stratifier = 'province'\n",
    "else:\n",
    "    raise ValueError('Invalid country name')\n",
    "\n",
    "\n",
    "if 'variable_description' not in summary.columns:\n",
    "    summary['variable_description'] = summary['variable_name']\n",
    "\n",
    "print(f'Read in: {country}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: Benin\n",
      "nullity: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hhid                        0.0\n",
       "instrument_count_missing    0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty string\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hhid                        0.0\n",
       "instrument_count_missing    0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:\n",
      "8012\n"
     ]
    }
   ],
   "source": [
    "print(f'country: {country}')\n",
    "print('nullity: ')\n",
    "display(data.isna().mean().sort_values(ascending=False).head(2))\n",
    "# Empty string may or may not be a problem.\n",
    "\n",
    "print('empty string')\n",
    "display(data.isin(['']).mean().sort_values(ascending=False).head(2))\n",
    "print('Number of samples:')\n",
    "print(data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missingness columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: Benin\n",
      "Missingness column salon_count_missing not in summary\n",
      "Missingness column dining_count_missing not in summary\n",
      "Missingness column bed_count_missing not in summary\n",
      "Missingness column mattress_count_missing not in summary\n",
      "Missingness column furniture_count_missing not in summary\n",
      "Missingness column carpet_count_missing not in summary\n",
      "Missingness column e_iron_count_missing not in summary\n",
      "Missingness column charcoal_iron_count_missing not in summary\n",
      "Missingness column stove_count_missing not in summary\n",
      "Missingness column gas_cylinder_count_missing not in summary\n",
      "Missingness column hotplate_count_missing not in summary\n",
      "Missingness column microwave_count_missing not in summary\n",
      "Missingness column improved_stove_count_missing not in summary\n",
      "Missingness column food_processor_count_missing not in summary\n",
      "Missingness column manual_juicer_count_missing not in summary\n",
      "Missingness column fridge_count_missing not in summary\n",
      "Missingness column freezer_count_missing not in summary\n",
      "Missingness column fan_count_missing not in summary\n",
      "Missingness column radio_count_missing not in summary\n",
      "Missingness column tv_count_missing not in summary\n",
      "Missingness column vcr_count_missing not in summary\n",
      "Missingness column satellite_dish_count_missing not in summary\n",
      "Missingness column laundry_count_missing not in summary\n",
      "Missingness column vacuum_count_missing not in summary\n",
      "Missingness column ac_count_missing not in summary\n",
      "Missingness column garden_tools_count_missing not in summary\n",
      "Missingness column generator_count_missing not in summary\n",
      "Missingness column personal_car_count_missing not in summary\n",
      "Missingness column moped_count_missing not in summary\n",
      "Missingness column bicycle_count_missing not in summary\n",
      "Missingness column camera_count_missing not in summary\n",
      "Missingness column camcorder_count_missing not in summary\n",
      "Missingness column stereo_count_missing not in summary\n",
      "Missingness column landline_count_missing not in summary\n",
      "Missingness column cellphone_count_missing not in summary\n",
      "Missingness column tablet_count_missing not in summary\n",
      "Missingness column computer_count_missing not in summary\n",
      "Missingness column printer_count_missing not in summary\n",
      "Missingness column video_camera_count_missing not in summary\n",
      "Missingness column rec_boat_count_missing not in summary\n",
      "Missingness column rifle_count_missing not in summary\n",
      "Missingness column guitar_count_missing not in summary\n",
      "Missingness column instrument_count_missing not in summary\n",
      "Missingness column building_count_missing not in summary\n",
      "Missingness column undev_land_count_missing not in summary\n",
      "Missingness column ruminants_lg_missing not in summary\n",
      "Missingness column salon_count_missing not in summary\n",
      "Missingness column dining_count_missing not in summary\n",
      "Missingness column bed_count_missing not in summary\n",
      "Missingness column mattress_count_missing not in summary\n",
      "Missingness column furniture_count_missing not in summary\n",
      "Missingness column carpet_count_missing not in summary\n",
      "Missingness column e_iron_count_missing not in summary\n",
      "Missingness column charcoal_iron_count_missing not in summary\n",
      "Missingness column stove_count_missing not in summary\n",
      "Missingness column gas_cylinder_count_missing not in summary\n",
      "Missingness column hotplate_count_missing not in summary\n",
      "Missingness column microwave_count_missing not in summary\n",
      "Missingness column improved_stove_count_missing not in summary\n",
      "Missingness column food_processor_count_missing not in summary\n",
      "Missingness column manual_juicer_count_missing not in summary\n",
      "Missingness column fridge_count_missing not in summary\n",
      "Missingness column freezer_count_missing not in summary\n",
      "Missingness column fan_count_missing not in summary\n",
      "Missingness column radio_count_missing not in summary\n",
      "Missingness column tv_count_missing not in summary\n",
      "Missingness column vcr_count_missing not in summary\n",
      "Missingness column satellite_dish_count_missing not in summary\n",
      "Missingness column laundry_count_missing not in summary\n",
      "Missingness column vacuum_count_missing not in summary\n",
      "Missingness column ac_count_missing not in summary\n",
      "Missingness column garden_tools_count_missing not in summary\n",
      "Missingness column generator_count_missing not in summary\n",
      "Missingness column personal_car_count_missing not in summary\n",
      "Missingness column moped_count_missing not in summary\n",
      "Missingness column bicycle_count_missing not in summary\n",
      "Missingness column camera_count_missing not in summary\n",
      "Missingness column camcorder_count_missing not in summary\n",
      "Missingness column stereo_count_missing not in summary\n",
      "Missingness column landline_count_missing not in summary\n",
      "Missingness column cellphone_count_missing not in summary\n",
      "Missingness column tablet_count_missing not in summary\n",
      "Missingness column computer_count_missing not in summary\n",
      "Missingness column printer_count_missing not in summary\n",
      "Missingness column video_camera_count_missing not in summary\n",
      "Missingness column rec_boat_count_missing not in summary\n",
      "Missingness column rifle_count_missing not in summary\n",
      "Missingness column guitar_count_missing not in summary\n",
      "Missingness column instrument_count_missing not in summary\n",
      "Missingness column building_count_missing not in summary\n",
      "Missingness column undev_land_count_missing not in summary\n",
      "Missingness column ruminants_lg_missing not in summary\n",
      "categorical columns with missingness indicators:\n",
      "data_type\n",
      "Numeric    74\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>module_name</th>\n",
       "      <th>module_description</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>variable_description</th>\n",
       "      <th>include</th>\n",
       "      <th>data_type</th>\n",
       "      <th>geographic_indicator</th>\n",
       "      <th>create</th>\n",
       "      <th>impute</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [module_name, module_description, variable_name, variable_description, include, data_type, geographic_indicator, create, impute, notes]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical columns with no missingness indicators:\n",
      "Series([], Name: variable_name, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "# Missingness columns (assumes _missing suffix)\n",
    "print(f'country: {country}')\n",
    "\n",
    "missingness_columns_missing = [\n",
    "    c for c in data.columns if ('missing' in c) \n",
    "]\n",
    "missingness_columns_m = [\n",
    "    c for c in data.columns if ('_m' in c) \n",
    "]\n",
    "with_missingness = [\n",
    "    c[:-8] for c in missingness_columns_missing\n",
    "] + [\n",
    "    c[:-2] for c in missingness_columns_m\n",
    "]\n",
    "missingness_columns = missingness_columns_missing + missingness_columns_m\n",
    "for c in missingness_columns:\n",
    "    if not (c in summary.variable_name.values):\n",
    "        print(f\"Missingness column {c} not in summary\")\n",
    "    \n",
    "relevant_summary = summary[summary.variable_name.isin(with_missingness)]\n",
    "print('categorical columns with missingness indicators:')\n",
    "\n",
    "print(relevant_summary.data_type.value_counts())\n",
    "display(relevant_summary[relevant_summary.data_type == 'categorical'])\n",
    "\n",
    "# print numerical columns with no missingness indicators\n",
    "print('numerical columns with no missingness indicators:')\n",
    "print(summary[\n",
    "    (summary.data_type == 'numeric') \n",
    "    & (~summary.variable_name.isin(with_missingness))\n",
    "    & (~summary.variable_name.str.endswith('_missing'))\n",
    "    & (~summary.variable_name.str.endswith('_m'))\n",
    "].variable_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consumption, weights, hh size, poverty rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: Ethiopia\n",
      "mean: 4.681175409246381\n",
      "std: 4.812618484963736\n",
      "rate: 0.4560640131118927\n"
     ]
    }
   ],
   "source": [
    "print(f'country: {country}')\n",
    "assert 'consumption_per_capita_per_day' in data.columns\n",
    "assert 'headcount_adjusted_hh_wgt' in data.columns\n",
    "assert pd.api.types.is_numeric_dtype(data['consumption_per_capita_per_day']), \"'consumption_per_capita_per_day' is not numeric\"\n",
    "assert pd.api.types.is_numeric_dtype(data['headcount_adjusted_hh_wgt']), \"'headcount_adjusted_hh_wgt' is not numeric\"\n",
    "if not 'hh_size' in data.columns:\n",
    "    print('Warning: Missing hh_size')\n",
    "else:\n",
    "    assert np.isclose(data.hh_size * data.hh_wgt, data.headcount_adjusted_hh_wgt).all()\n",
    "    assert pd.api.types.is_numeric_dtype(data['hh_size']), \"'hh_size' is not numeric\"\n",
    "\n",
    "for col in ['headcount_adjusted_hh_wgt_missing', 'consumption_per_capita_per_day_missing', 'hh_wgt_missing']:\n",
    "    if col in data.columns:\n",
    "        assert data[col].sum() == 0, f\"{col} has missing values\"\n",
    "\n",
    "print('mean:', data.consumption_per_capita_per_day.mean())\n",
    "print('std:', data.consumption_per_capita_per_day.std())\n",
    "\n",
    "count_poor = (\n",
    "    data[data.consumption_per_capita_per_day < 2.15].headcount_adjusted_hh_wgt\n",
    ").sum()\n",
    "\n",
    "total = (\n",
    "    data.headcount_adjusted_hh_wgt\n",
    ").sum()\n",
    "rate = count_poor / total\n",
    "\n",
    "print('rate:',rate)\n",
    "# To crosscheck: https://docs.google.com/spreadsheets/d/11wGVZadIZMvR2oXoDtSfjJVvixyv3ievuUOF4k_1HNY/edit?gid=0#gid=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suspiciously named columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: Ghana_nolan\n",
      "containing the word \"unit\":\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>variable_description</th>\n",
       "      <th>module_name</th>\n",
       "      <th>module_description</th>\n",
       "      <th>data_type</th>\n",
       "      <th>geographic_indicator</th>\n",
       "      <th>geographic_indicator_coarser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [variable_name, variable_description, module_name, module_description, data_type, geographic_indicator, geographic_indicator_coarser]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "containing the word \"consumption\":\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>variable_description</th>\n",
       "      <th>module_name</th>\n",
       "      <th>module_description</th>\n",
       "      <th>data_type</th>\n",
       "      <th>geographic_indicator</th>\n",
       "      <th>geographic_indicator_coarser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>consumption_per_capita_per_day</td>\n",
       "      <td>Daily consumption per capita by the household.</td>\n",
       "      <td>percapita_expenditure_df</td>\n",
       "      <td>Expenditure per capita</td>\n",
       "      <td>numeric</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>consumption_per_capita_per_day_missing</td>\n",
       "      <td>Missingness indicator for consumption_per_capi...</td>\n",
       "      <td>Missingness Indicators</td>\n",
       "      <td></td>\n",
       "      <td>categorical</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              variable_name  \\\n",
       "165          consumption_per_capita_per_day   \n",
       "304  consumption_per_capita_per_day_missing   \n",
       "\n",
       "                                  variable_description  \\\n",
       "165     Daily consumption per capita by the household.   \n",
       "304  Missingness indicator for consumption_per_capi...   \n",
       "\n",
       "                  module_name      module_description    data_type  \\\n",
       "165  percapita_expenditure_df  Expenditure per capita      numeric   \n",
       "304    Missingness Indicators                          categorical   \n",
       "\n",
       "     geographic_indicator  geographic_indicator_coarser  \n",
       "165                 False                         False  \n",
       "304                 False                         False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables with \"id\" or \"code\" and listed numeric:\n",
      "Name: sample_hh_id, Description: Unique identifier for the sample household.\n",
      "Name: num_camcorder/video_camera_owned, Description: Number of camcorders/video cameras owned by the household.\n",
      "Name: num_video_player_owned, Description: Number of video players owned by the household.\n"
     ]
    }
   ],
   "source": [
    "print(f'country: {country}')\n",
    "\n",
    "# Suspicious data\n",
    "print('containing the word \"unit\":')\n",
    "display(\n",
    "    summary[\n",
    "        (\n",
    "            summary.variable_name.str.contains('unit')\n",
    "            | summary.variable_description.str.contains('unit')\n",
    "        ) & (\n",
    "            ~summary.variable_name.str.contains('community')\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "print('containing the word \"consumption\":')\n",
    "display(\n",
    "    summary[\n",
    "        summary.variable_name.str.contains('consumption')\n",
    "        | summary.variable_description.str.contains('consumption')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print variables whose name contains \"id\" or \"code\" and are listed as numeric in the summary\n",
    "print('variables with \"id\" or \"code\" and listed numeric:')\n",
    "\n",
    "filtered_variables = summary[\n",
    "    (summary[\"variable_name\"].str.contains(\"id|code\", case=False, na=False)) &\n",
    "    (summary[\"data_type\"] == \"numeric\")\n",
    "]\n",
    "\n",
    "# Print the name and description of the filtered variables\n",
    "for _, row in filtered_variables.iterrows():\n",
    "    print(f\"Name: {row['variable_name']}, Description: {row['variable_description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary correctness: Matches data, format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: Ghana_nolan\n",
      "Variables in summary but not in data: set()\n",
      "Columns in data but not in summary: set()\n"
     ]
    }
   ],
   "source": [
    "print(f'country: {country}')\n",
    "\n",
    "# check that metadata and data match\n",
    "data_columns = set(data.columns)\n",
    "\n",
    "summary_variable_names = set(summary['variable_name'])\n",
    "missing_in_data = summary_variable_names - data_columns\n",
    "missing_in_summary = data_columns - summary_variable_names\n",
    "\n",
    "print(\"Variables in summary but not in data:\", missing_in_data)\n",
    "print(\"Columns in data but not in summary:\", missing_in_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: Ghana_nolan\n"
     ]
    }
   ],
   "source": [
    "print(f'country: {country}')\n",
    "# Check that \"summary\" fits the required format\n",
    "required_columns = {\n",
    "    \"variable_name\", \"data_type\", \"geographic_indicator\", \"geographic_indicator_coarser\"\n",
    "    }\n",
    "summary_columns = set(summary.columns)\n",
    "\n",
    "missing_columns = required_columns - summary_columns\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"Missing required columns in summary: {missing_columns}\")\n",
    "\n",
    "# Ensure \"data_type\" has only permitted values\n",
    "permitted_data_types = {\"numeric\", \"categorical\"}\n",
    "found_errors = False\n",
    "for _, row in summary.iterrows():\n",
    "    if row[\"data_type\"] not in permitted_data_types:\n",
    "        print(\n",
    "            f\"Invalid data_type '{row['data_type']}' for variable '{row['variable_name']}'. \"\n",
    "            f\"Description: {row['variable_description']}\"\n",
    "        )\n",
    "        found_errors = True\n",
    "\n",
    "# Ensure \"geographic_indicator_coarser\", \"geographic_indicator_finer\" is boolean or 0-1\n",
    "for _, row in summary.iterrows():\n",
    "    for c in [\"geographic_indicator\", \"geographic_indicator_coarser\", \"geographic_indicator_finer\"]:\n",
    "        if c not in row:\n",
    "            continue\n",
    "        if row[c] not in [0, 1, True, False, None]:\n",
    "            print(\n",
    "                f\"Invalid {c} '{row[c]}' for variable '{row['variable_name']}'. \"\n",
    "                f\"Description: {row['variable_description']}\"\n",
    "            )\n",
    "            found_errors = True\n",
    "if found_errors:\n",
    "    raise ValueError(\"Errors found in summary metadata. Please fix them before proceeding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: Ghana_nolan\n",
      "categorical in summary, numeric in data: 'region'; Region where the household is located.\n",
      "categorical in summary, numeric in data: 'hhid'; Unique identifier for the household.\n",
      "categorical in summary, numeric in data: 'urbrur'; Urban-rural classification indicating whether the household is in an urban or rural area.\n",
      "categorical in summary, numeric in data: 'locality_zone'; Specific zone or area within the locality where the household is located.\n",
      "categorical in summary, numeric in data: 'head_gender'; Gender of the head of the household.\n",
      "categorical in summary, numeric in data: 'head_marital_status'; Marital status of the head of the household.\n",
      "categorical in summary, numeric in data: 'head_religion'; Religion of the head of the household.\n",
      "categorical in summary, numeric in data: 'head_ethnic_group'; Ethnic group to which the head of the household belongs.\n",
      "categorical in summary, numeric in data: 'head_industry_or_trade'; Industry or trade in which the head of the household is employed.\n",
      "categorical in summary, numeric in data: 'isco_code'; International Standard Classification of Occupations code for the head of the households occupation.\n",
      "categorical in summary, numeric in data: 'head_education'; Level of education attained by the head of the household.\n",
      "categorical in summary, numeric in data: 'max_education'; Highest education level attained by any member of the household.\n",
      "categorical in summary, numeric in data: 'drinking_water_source'; Source of drinking water used by the household.\n",
      "categorical in summary, numeric in data: 'general_water_source'; General source of water used by the household.\n",
      "categorical in summary, numeric in data: 'main_cooking_fuel_source'; Main cooking fuel source used by the household.\n",
      "categorical in summary, numeric in data: 'trash_disposal'; Trash disposal method used by the household.\n",
      "categorical in summary, numeric in data: 'toilet_type'; Type of toilet used by the household.\n",
      "categorical in summary, numeric in data: 'wall_material'; Material used for the walls of the households dwelling.\n",
      "categorical in summary, numeric in data: 'floor_material'; Material used for the floors of the households dwelling.\n",
      "categorical in summary, numeric in data: 'roof_material'; Material used for the roof of the households dwelling.\n",
      "categorical in summary, numeric in data: 'dwelling_ownership_type'; Dwelling ownership type (rented, owned, etc.) of the household.\n",
      "categorical in summary, numeric in data: 'house_has_electricity'; Whether the household has electricity.\n",
      "categorical in summary, numeric in data: 'type_of_housing'; Type of housing the household lives in.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/tmp/ipykernel_882815/734161392.py:19: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  and not pd.api.types.is_categorical_dtype(data[col])\n"
     ]
    }
   ],
   "source": [
    "print(f'country: {country}')\n",
    "\n",
    "# Check that numeric columns in summary are actually numeric in data\n",
    "numeric_columns = summary[summary[\"data_type\"] == \"numeric\"][\"variable_name\"]\n",
    "found_error = False\n",
    "for col in numeric_columns:\n",
    "    if col in data.columns and not pd.api.types.is_numeric_dtype(data[col]):\n",
    "        description = summary.loc[summary[\"variable_name\"] == col, \"variable_description\"].values[0]\n",
    "        print(f\"BAD: numeric in summary, non-numeric in data: '{col}'; {description}\")\n",
    "        found_error = True\n",
    "if found_error:\n",
    "    raise ValueError('Found numeric columns in summary that are not numeric in data.')\n",
    "\n",
    "# Check that categorical columns in summary are actually categorical in data (less important)\n",
    "categorical_columns = summary[summary[\"data_type\"] == \"categorical\"][\"variable_name\"]\n",
    "for col in categorical_columns:\n",
    "    if (\n",
    "        col in data.columns \n",
    "        and not pd.api.types.is_categorical_dtype(data[col])\n",
    "        and not (col.endswith('_missing') or col.endswith('_m'))\n",
    "    ):\n",
    "        description = summary.loc[summary[\"variable_name\"] == col, \"variable_description\"].values[0]\n",
    "        print(f\"categorical in summary, numeric in data: '{col}'; {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: Ghana_nolan\n",
      "Constant columns:\n",
      "num_child_missing\n",
      "num_adult_missing\n",
      "num_elder_missing\n",
      "businesses_owned_missing\n",
      "hh_size_missing\n",
      "consumption_per_capita_per_day_missing\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('num_adult', 'num_elder', 'identical'),\n",
       " ('num_pincers_owned', 'num_pinch_bar_owned', 'identical'),\n",
       " ('num_pincers_owned',\n",
       "  'num_screw_driver_owned',\n",
       "  'numeric_categorical_equivalent'),\n",
       " ('num_pinch_bar_owned',\n",
       "  'num_screw_driver_owned',\n",
       "  'numeric_categorical_equivalent')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicate information. Don't do if there are too many columns.\n",
    "print(f'country: {country}')\n",
    "\n",
    "find_equivalent_columns(data, summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geography and stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: Ghana_nolan\n",
      "geographic indicators:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>variable_description</th>\n",
       "      <th>module_name</th>\n",
       "      <th>module_description</th>\n",
       "      <th>data_type</th>\n",
       "      <th>geographic_indicator</th>\n",
       "      <th>geographic_indicator_coarser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>region</td>\n",
       "      <td>Region where the household is located.</td>\n",
       "      <td>key_hhld_info_df</td>\n",
       "      <td>Key Household Information</td>\n",
       "      <td>categorical</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>district</td>\n",
       "      <td>District where the household is located.</td>\n",
       "      <td>key_hhld_info_df</td>\n",
       "      <td>Key Household Information</td>\n",
       "      <td>numeric</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ea_number</td>\n",
       "      <td>Enumeration area identifier for the household'...</td>\n",
       "      <td>key_hhld_info_df</td>\n",
       "      <td>Key Household Information</td>\n",
       "      <td>numeric</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>ghana_zone</td>\n",
       "      <td>Ghana zone where the household is located.</td>\n",
       "      <td>sec0_df</td>\n",
       "      <td>Checklist</td>\n",
       "      <td>numeric</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    variable_name                               variable_description  \\\n",
       "0          region             Region where the household is located.   \n",
       "1        district           District where the household is located.   \n",
       "2       ea_number  Enumeration area identifier for the household'...   \n",
       "163    ghana_zone         Ghana zone where the household is located.   \n",
       "\n",
       "          module_name         module_description    data_type  \\\n",
       "0    key_hhld_info_df  Key Household Information  categorical   \n",
       "1    key_hhld_info_df  Key Household Information      numeric   \n",
       "2    key_hhld_info_df  Key Household Information      numeric   \n",
       "163           sec0_df                  Checklist      numeric   \n",
       "\n",
       "     geographic_indicator  geographic_indicator_coarser  \n",
       "0                    True                          True  \n",
       "1                    True                         False  \n",
       "2                    True                         False  \n",
       "163                  True                         False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region\n",
      "10\n",
      "district\n",
      "115\n",
      "ea_number\n",
      "332\n",
      "ghana_zone\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(f'country: {country}')\n",
    "\n",
    "print('geographic indicators:')\n",
    "display(summary[summary.geographic_indicator])\n",
    "for _, row in summary[summary.geographic_indicator].iterrows():\n",
    "    print(row.variable_name)\n",
    "    print(data[row.variable_name].nunique())\n",
    "\n",
    "if False:\n",
    "    partially_represented = summary[\n",
    "        (summary.geographic_indicator_finer) & ~(summary.geographic_indicator_coarser)\n",
    "    ]\n",
    "    if len(partially_represented) == 0:\n",
    "        print('No partially represented geo level')\n",
    "    else:\n",
    "        assert len(partially_represented) == 1\n",
    "        print('partially represented:')\n",
    "        print(partially_represented.variable_name.values[0])\n",
    "        print('partially represented value counts:')\n",
    "        print(data[partially_represented.variable_name.values[0]].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: Ghana_nolan\n",
      "proposed stratifier: region\n",
      "count per unit\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6. Ashanti Region</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5. Eastern Region</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3. Greater Accra Region</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8. Northern Region</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7. Brong Ahafo Region</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4. Volta Region</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Western Region</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2. Central Region</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9. Upper East Region</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10. Upper West Region</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    region  count\n",
       "6        6. Ashanti Region    891\n",
       "5        5. Eastern Region    625\n",
       "3  3. Greater Accra Region    583\n",
       "8       8. Northern Region    566\n",
       "7    7. Brong Ahafo Region    508\n",
       "4          4. Volta Region    480\n",
       "0        1. Western Region    464\n",
       "2        2. Central Region    419\n",
       "9     9. Upper East Region    240\n",
       "1    10. Upper West Region    177"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights per unit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "region\n",
       "10. Upper West Region      12\n",
       "9. Upper East Region       16\n",
       "2. Central Region          28\n",
       "1. Western Region          31\n",
       "4. Volta Region            32\n",
       "7. Brong Ahafo Region      34\n",
       "3. Greater Accra Region    38\n",
       "8. Northern Region         38\n",
       "5. Eastern Region          42\n",
       "6. Ashanti Region          59\n",
       "Name: hh_wgt, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regions per weight class\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hh_wgt\n",
       "214.980820     1\n",
       "1528.199341    1\n",
       "1516.917603    1\n",
       "1514.871582    1\n",
       "1503.002930    1\n",
       "              ..\n",
       "878.241089     1\n",
       "874.731934     1\n",
       "874.081055     1\n",
       "864.869019     1\n",
       "4751.101562    1\n",
       "Name: region, Length: 330, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count per unit x weight\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hh_wgt</th>\n",
       "      <th>region</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1089.019043</td>\n",
       "      <td>6. Ashanti Region</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>4502.678711</td>\n",
       "      <td>3. Greater Accra Region</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>214.980820</td>\n",
       "      <td>8. Northern Region</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>1458.206665</td>\n",
       "      <td>2. Central Region</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>1533.486450</td>\n",
       "      <td>7. Brong Ahafo Region</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1395.010376</td>\n",
       "      <td>5. Eastern Region</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>1422.286011</td>\n",
       "      <td>6. Ashanti Region</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1060.170776</td>\n",
       "      <td>6. Ashanti Region</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1196.175293</td>\n",
       "      <td>8. Northern Region</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>1416.486328</td>\n",
       "      <td>6. Ashanti Region</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          hh_wgt                   region  count\n",
       "139  1089.019043        6. Ashanti Region     30\n",
       "326  4502.678711  3. Greater Accra Region     30\n",
       "0     214.980820       8. Northern Region     15\n",
       "216  1458.206665        2. Central Region     15\n",
       "224  1533.486450    7. Brong Ahafo Region     15\n",
       "..           ...                      ...    ...\n",
       "200  1395.010376        5. Eastern Region     14\n",
       "207  1422.286011        6. Ashanti Region     14\n",
       "136  1060.170776        6. Ashanti Region     13\n",
       "162  1196.175293       8. Northern Region     13\n",
       "205  1416.486328        6. Ashanti Region     13\n",
       "\n",
       "[330 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stratification\n",
    "print(f'country: {country}')\n",
    "print('proposed stratifier:', proposed_stratifier)\n",
    "print('count per unit')\n",
    "display(data.groupby(proposed_stratifier, observed=True).size().reset_index(name='count').sort_values('count', ascending=False))\n",
    "\n",
    "print('weights per unit')\n",
    "display(data.groupby(proposed_stratifier,  observed=True).hh_wgt.nunique().sort_values())\n",
    "\n",
    "print('regions per weight class')\n",
    "display(data.groupby('hh_wgt', observed=True)[proposed_stratifier].nunique().sort_values())\n",
    "\n",
    "print('count per unit x weight')\n",
    "display(\n",
    "    data.groupby(['hh_wgt', proposed_stratifier],  observed=True)\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    "    .sort_values('count', ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data, check with roshni's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Ghana_nolan, country data path: /data/eop/ghana_nolan/cleaned\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['bash', '/data/eop/ghana_nolan/cleaned/split.sh'], returncode=0)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Country: {country}, country data path: {country_data_path}')\n",
    "os.chdir(country_data_path)\n",
    "subprocess.run(['bash', str(country_data_path / 'split.sh')], check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Ghana_nolan, country data path: /data/eop/ghana_nolan/cleaned\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Country: {country}, country data path: {country_data_path}')\n",
    "\n",
    "train_path = country_data_path / 'train.parquet'\n",
    "test_path = country_data_path / 'test.parquet'\n",
    "summary_path = country_data_path / 'summary.parquet'\n",
    "# Assert that train.parquet and test.parquet are newer than any other parquet file under country_data_path\n",
    "all_parquet_files = list(country_data_path.glob('*.parquet'))\n",
    "for f in all_parquet_files:\n",
    "    if f not in [train_path, test_path]:\n",
    "        assert train_path.stat().st_mtime > f.stat().st_mtime, f\"{train_path.name} is not newer than {f.name}\"\n",
    "        assert test_path.stat().st_mtime > f.stat().st_mtime, f\"{test_path.name} is not newer than {f.name}\"\n",
    "\n",
    "train_dataset, validation_dataset, test_covariate_dataset, test_dataset = load_datasets(\n",
    "    trainpath = train_path,\n",
    "    testpath = test_path,\n",
    "    summarypath = summary_path,\n",
    "    geo_extrapolation = True,\n",
    "    outcome = 'consumption_per_capita_per_day',\n",
    "    weight = 'headcount_adjusted_hh_wgt'\n",
    ")\n",
    "X, y, r = train_dataset.get_data()\n",
    "X, X_mean, X_std = standardize(X)\n",
    "y, y_mean, y_std = standardize(y)\n",
    "\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(X, y, sample_weight=r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leo_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
