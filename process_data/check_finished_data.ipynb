{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def get_row_from_metadata(metadata, covariate_name):\n",
    "    \"\"\"\n",
    "    Extracts a specific row from the metadata DataFrame based on the covariate name.\n",
    "\n",
    "    :param metadata: DataFrame containing metadata.\n",
    "    :param covariate_name: Name of the covariate to extract.\n",
    "    :return: Row corresponding to the specified covariate name.\n",
    "    \"\"\"\n",
    "    return metadata.loc[metadata['variable_name'] == covariate_name].squeeze()\n",
    "\n",
    "def all_rows_from_metadata_containing(metadata, substring):\n",
    "    \"\"\"\n",
    "    Extracts all rows from the metadata DataFrame that contain a specific substring in the variable name.\n",
    "\n",
    "    :param metadata: DataFrame containing metadata.\n",
    "    :param substring: Substring to search for in the variable names.\n",
    "    :return: DataFrame containing all rows with variable names that contain the substring.\n",
    "    \"\"\"\n",
    "    return metadata[metadata['variable_name'].str.contains(substring, na=False)].reset_index(drop=True)\n",
    "\n",
    "def all_column_names_containing(df, substring):\n",
    "    \"\"\"\n",
    "    Extracts all column names from the DataFrame that contain a specific substring.\n",
    "\n",
    "    :param df: DataFrame to search for column names.\n",
    "    :param substring: Substring to search for in the column names.\n",
    "    :return: List of column names containing the specified substring.\n",
    "    \"\"\"\n",
    "    return [col for col in df.columns if substring in col]\n",
    "\n",
    "\n",
    "def find_equivalent_columns(data, summary, numeric_tolerance=1e-6, categorical_threshold=0.99):\n",
    "    \"\"\"\n",
    "    Find pairs of columns in a DataFrame that are informationally equivalent.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas DataFrame\n",
    "        The DataFrame to analyze\n",
    "    numeric_tolerance : float, default 1e-6\n",
    "        Tolerance for considering numeric columns equal or proportional\n",
    "    categorical_threshold : float, default 0.99\n",
    "        Threshold for considering categorical columns equivalent (percentage match)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list of tuples\n",
    "        Each tuple contains (col1, col2, relationship_type)\n",
    "        where relationship_type is one of: 'identical', 'proportional', 'categorical_equivalent'\n",
    "    \"\"\"\n",
    "    equivalent_pairs = []\n",
    "    columns = data.columns\n",
    "    \n",
    "    # Get column types\n",
    "    \n",
    "    numeric_cols = summary[summary.data_type == 'numeric'].variable_name.tolist()\n",
    "    categorical_cols = summary[summary.data_type == 'categorical'].variable_name.tolist()\n",
    "\n",
    "    # Identify constant columns\n",
    "    constant_cols = []\n",
    "    for col in columns:\n",
    "        unique_values = data[col].dropna().unique()\n",
    "        if len(unique_values) <= 1:\n",
    "            constant_cols.append(col)\n",
    "\n",
    "    # Print constant columns if verbose\n",
    "    if len(constant_cols) > 0:\n",
    "        print(\"Constant columns:\")\n",
    "        for col in constant_cols:\n",
    "            print(col)\n",
    "        print()\n",
    "    \n",
    "\n",
    "    # Remove constant columns from numeric and categorical lists\n",
    "    numeric_cols = [col for col in numeric_cols if col not in constant_cols]\n",
    "    categorical_cols = [col for col in categorical_cols if col not in constant_cols]\n",
    "\n",
    "    # remove missingness-indicator columns\n",
    "    missingness_cols = list(\n",
    "        set(all_column_names_containing(data, '_missing') + \n",
    "        all_column_names_containing(data, '_m'))\n",
    "    )\n",
    "    numeric_cols = [col for col in numeric_cols if col not in missingness_cols]\n",
    "    categorical_cols = [col for col in categorical_cols if col not in missingness_cols]\n",
    "    \n",
    "    # Check numeric columns for equality or proportionality\n",
    "    for col1, col2 in itertools.combinations(numeric_cols, 2):\n",
    "\n",
    "        # Check for identical values first\n",
    "        if data[col1].equals(data[col2]):\n",
    "            equivalent_pairs.append((col1, col2, 'identical'))\n",
    "            continue\n",
    "            \n",
    "        # Check for identical values where neither is zero\n",
    "        valid_mask = ~data[col1].isna() & ~data[col2].isna()\n",
    "        if np.allclose(data.loc[valid_mask, col1], data.loc[valid_mask, col2], \n",
    "                      rtol=numeric_tolerance, atol=numeric_tolerance):\n",
    "            equivalent_pairs.append((col1, col2, 'nearly_identical'))\n",
    "            continue\n",
    "        \n",
    "        # For rows with zeros, check if the columns are exactly equal\n",
    "        zero_mask = (data[col1] == 0) | (data[col2] == 0)\n",
    "        non_zero_mask = ~zero_mask & valid_mask\n",
    "        \n",
    "        # Check if the columns have the same values where zeros are present\n",
    "        if zero_mask.any():\n",
    "            zero_equality = (data.loc[zero_mask & valid_mask, col1] == \n",
    "                             data.loc[zero_mask & valid_mask, col2]).all()\n",
    "        else:\n",
    "            zero_equality = True\n",
    "            \n",
    "        # Check for proportional relationship in non-zero values\n",
    "        if non_zero_mask.sum() > 10:  # Require at least some non-zero values\n",
    "            ratios = data.loc[non_zero_mask, col2] / data.loc[non_zero_mask, col1]\n",
    "            ratio_std = ratios.std()\n",
    "            \n",
    "            # If standard deviation of ratios is very small, columns are proportional\n",
    "            if ratio_std < numeric_tolerance and zero_equality:\n",
    "                ratio = ratios.mean()\n",
    "                equivalent_pairs.append((col1, col2, f'proportional (factor: {ratio:.4f})'))\n",
    "    \n",
    "    # Create a list of all columns to check for categorical equivalence\n",
    "    # This includes both explicit categorical columns and numeric columns\n",
    "    all_potential_categorical_cols = categorical_cols + numeric_cols\n",
    "    \n",
    "    # Check all columns for equivalent categorical mappings\n",
    "    for col1, col2 in itertools.combinations(all_potential_categorical_cols, 2):\n",
    "        # Skip if identical columns or already identified as identical or proportional\n",
    "        if col1 == col2 or any((col1, col2, rel) in equivalent_pairs for rel in \n",
    "                               ['identical', 'nearly_identical', 'proportional']):\n",
    "            continue\n",
    "            \n",
    "        # Get unique values for both columns\n",
    "        unique_vals1 = data[col1].dropna().unique()\n",
    "        unique_vals2 = data[col2].dropna().unique()\n",
    "        \n",
    "        # Skip if columns have different number of unique values\n",
    "        if len(unique_vals1) != len(unique_vals2):\n",
    "            continue\n",
    "            \n",
    "        # Skip if too many unique values (likely not categorical)\n",
    "        if len(unique_vals1) > 100:  # Arbitrary threshold, adjust as needed\n",
    "            continue\n",
    "            \n",
    "        # Create a mapping table between values in both columns\n",
    "        mapping_df = data[[col1, col2]].dropna().drop_duplicates()\n",
    "        \n",
    "        # Check if mapping is one-to-one (each value in col1 maps to exactly one value in col2)\n",
    "        is_one_to_one = True\n",
    "        \n",
    "        # Check col1 -> col2 mapping\n",
    "        for val in unique_vals1:\n",
    "            corresponding_vals = data.loc[data[col1] == val, col2].dropna().unique()\n",
    "            if len(corresponding_vals) != 1:\n",
    "                is_one_to_one = False\n",
    "                break\n",
    "                \n",
    "        # Check col2 -> col1 mapping\n",
    "        if is_one_to_one:\n",
    "            for val in unique_vals2:\n",
    "                corresponding_vals = data.loc[data[col2] == val, col1].dropna().unique()\n",
    "                if len(corresponding_vals) != 1:\n",
    "                    is_one_to_one = False\n",
    "                    break\n",
    "        \n",
    "        if is_one_to_one:\n",
    "            # If we create a new column using the mapping, it should match the original\n",
    "            val_mapping = dict(zip(mapping_df[col1], mapping_df[col2]))\n",
    "            \n",
    "            # Apply mapping and handle NaN values\n",
    "            mapped_values = data[col1].map(val_mapping)\n",
    "            \n",
    "            # Count matches (ignoring NaN values)\n",
    "            valid_mask = ~data[col1].isna() & ~data[col2].isna()\n",
    "            if valid_mask.sum() > 0:\n",
    "                match_percentage = (mapped_values == data[col2])[valid_mask].mean()\n",
    "                \n",
    "                if match_percentage >= categorical_threshold:\n",
    "                    # Determine if both are numeric or mixed types\n",
    "                    if col1 in numeric_cols and col2 in numeric_cols:\n",
    "                        relationship = 'numeric_categorical_equivalent'\n",
    "                    else:\n",
    "                        relationship = 'categorical_equivalent'\n",
    "                    equivalent_pairs.append((col1, col2, relationship))\n",
    "    \n",
    "    return equivalent_pairs\n",
    "\n",
    "\"\"\"\n",
    "Done in this notebook\n",
    "- Ensure that missingness-indicator columns exist.\n",
    "    - You probably can't conclusively check that all are included, because the data you get will not necessarily reveal which columns had missingness, but check that there are some missingness columns, and none for categorical data.\n",
    "- Ensure there are no NaNs in the data.\n",
    "- Ensure column names:\n",
    "    - In data: \"hhid\" (if household ID is included), \"consumption_per_capita_per_day\", \"hh_wgt\".\n",
    "    - Consumption: Check mean and std for sanity. In a poor country, the mean should be low-mid single digits: e.g., in Uganda, the mean is $3.80/day.\n",
    "- Check for columns that indicate units:\n",
    "    - If they are present, the corresponding numeric field should be standardized, e.g., all area units adjusted to square meters.\n",
    "- Check that metadata and the dataset itself match:\n",
    "    - Every column in data is described in metadata and vice versa. It's also OK if `hhid` is not in the data at all.\n",
    "- In metadata:\n",
    "    - \"variable_name\".\n",
    "    - \"data_type\", with permitted values \"numeric\" and \"categorical\".\n",
    "    - \"geographic_indicator\".\n",
    "- Scan datatypes:\n",
    "    - In particular, make sure nothing is numeric which should be categorical.\n",
    "    - Ensure categorical-type columns have the appropriate type even if the categories are encoded as integers (if a column is binary, with no missing values, it can be numeric or categorical).\n",
    "    - IDs of all kinds are strings even if they appear numeric.\n",
    "- Check for duplication\n",
    "- Check feasibility of stratification\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in: Ethiopia\n"
     ]
    }
   ],
   "source": [
    "data_path = Path('/data/eop')\n",
    "\n",
    "data, summary, proposed_stratifier = None, None, None\n",
    "\n",
    "country = 'Nigeria'  # Change this to the desired country\n",
    "\n",
    "if country == 'Burkina Faso':\n",
    "    data = pd.read_parquet(\n",
    "        data_path / 'burkina_faso' / 'cleaned' / 'burkinafaso_final_data.parquet'\n",
    "    )\n",
    "    summary = pd.read_parquet(\n",
    "        data_path / 'burkina_faso' / 'cleaned' / 'summary.parquet'\n",
    "    )\n",
    "    proposed_stratifier = 'region'\n",
    "elif country == 'Cote dIvoire':\n",
    "    data = pd.read_parquet(\n",
    "        data_path / 'cote_divoire' / 'cleaned' / 'cotedivoire_cleaned_data.parquet'\n",
    "    )\n",
    "\n",
    "    summary = pd.read_parquet(\n",
    "        data_path / 'cote_divoire' / 'cleaned' / 'summary.parquet'\n",
    "    )\n",
    "    proposed_stratifier = 'region'\n",
    "elif country == 'Guinea-Bissau':\n",
    "    data = pd.read_parquet(\n",
    "        data_path / 'guinea-bissau' / 'cleaned' / 'final_gb_dataset.parquet'\n",
    "    )\n",
    "    summary = pd.read_parquet(\n",
    "        data_path / 'guinea-bissau' / 'cleaned' / 'summary.parquet'\n",
    "    )\n",
    "    proposed_stratifier = 'region'\n",
    "elif country == 'Mali':\n",
    "    data = pd.read_parquet(\n",
    "        data_path / 'mali' / 'cleaned' / 'final_mali_dataset.parquet'\n",
    "    )\n",
    "    summary = pd.read_parquet(\n",
    "        data_path / 'mali' / 'cleaned' / 'summary.parquet'\n",
    "    )\n",
    "    proposed_stratifier = 'region'\n",
    "elif country == 'Somalia':\n",
    "    data = pd.read_parquet(\n",
    "        data_path / 'somalia' / 'cleaned' / 'somalia_lsms_final.parquet'\n",
    "    )\n",
    "    summary = pd.read_parquet(\n",
    "        data_path / 'somalia' / 'cleaned' / 'summary.parquet'\n",
    "    )\n",
    "    proposed_stratifier = 'region'\n",
    "elif country == 'Albania': \n",
    "    data = pd.read_parquet(\n",
    "        data_path / 'albania' / 'cleaned' / 'albania_all.parquet'\n",
    "    )\n",
    "    summary = pd.read_parquet(\n",
    "        data_path / 'albania' / 'cleaned' / 'summary.parquet'\n",
    "    )\n",
    "elif country == 'Uganda':\n",
    "    data = pd.read_parquet(\n",
    "        data_path / 'uganda' / 'cleaned' / 'uganda_full.parquet'\n",
    "    )\n",
    "    summary = pd.read_parquet(\n",
    "        data_path / 'uganda' / 'cleaned' / 'summary.parquet'\n",
    "    )\n",
    "    proposed_stratifier='region'\n",
    "elif country == 'Malawi':\n",
    "    data = pd.read_parquet(data_path / 'malawi/cleaned/malawi_2019.parquet')\n",
    "    summary = pd.read_parquet(data_path / 'malawi/cleaned/summary.parquet')\n",
    "    summary.rename(columns={'description': 'variable_description'}, inplace=True)\n",
    "\n",
    "elif country == 'Togo':\n",
    "    data = pd.read_parquet('/data/eop/Togo 2018-19/clean/final_togo.parquet')\n",
    "    summary = pd.read_parquet('/data/eop/Togo 2018-19/clean/summary.parquet')\n",
    "    proposed_stratifier = 'cluster_id'\n",
    "elif country == 'Togo_only_cdr':\n",
    "    data = pd.read_parquet('/data/eop/Togo 2018-19/clean/cdr_features/togo.parquet')\n",
    "    summary = pd.read_parquet('/data/eop/Togo 2018-19/clean/cdr_features/summary.parquet')\n",
    "\n",
    "elif country == 'Togo_survey_and_cdr':\n",
    "    data = pd.read_parquet('/data/eop/Togo 2018-19/clean/cdr_features_and_survey_predictors/togo.parquet')\n",
    "    summary = pd.read_parquet('/data/eop/Togo 2018-19/clean/cdr_features_and_survey_predictors/summary.parquet')\n",
    "    proposed_stratifier = 'cluster_id'\n",
    "\n",
    "elif country == 'Ethiopia':\n",
    "    data = pd.read_parquet('/data/eop/Ethiopia 2018-19/clean/final_ethiopia.parquet')\n",
    "    summary = pd.read_parquet('/data/eop/Ethiopia 2018-19/clean/summary.parquet')\n",
    "    proposed_stratifier = 'region_zone'\n",
    "elif country == 'Nigeria':\n",
    "    data = pd.read_parquet('/data/eop/Nigeria 2018-19/clean/final_nigeria.parquet')\n",
    "    summary = pd.read_parquet('/data/eop/Nigeria 2018-19/clean/summary.parquet')\n",
    "    proposed_stratifier = 'ea_id'\n",
    "\n",
    "elif country == 'Kenya':\n",
    "    data = pd.read_parquet('/data/eop/kenya/cleaned/kenya.parquet')\n",
    "    summary = pd.read_parquet('/data/eop/kenya/cleaned/summary.parquet')\n",
    "elif country == 'Tanzania':\n",
    "    data = pd.read_parquet('/data/eop/Tanzania_2020-21/cleaned/tanzania_data.parquet')\n",
    "    summary = pd.read_parquet('/data/eop/Tanzania_2020-21/cleaned/summary.parquet')\n",
    "    proposed_stratifier = 'region'\n",
    "elif country == 'Madagascar':\n",
    "    data = pd.read_parquet('/data/eop/Madagascar 2010-11/cleaned/madagascar_data.parquet')\n",
    "    summary = pd.read_parquet('/data/eop/Madagascar 2010-11/cleaned/summary.parquet')\n",
    "    proposed_stratifier = 'REGION'\n",
    "else:\n",
    "    raise ValueError('Invalid country name')\n",
    "\n",
    "\n",
    "if 'variable_description' not in summary.columns:\n",
    "    summary['variable_description'] = summary['variable_name']\n",
    "\n",
    "print(f'Read in: {country}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: Ethiopia\n",
      "nullity: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hhid                       0.0\n",
       "distance_to_bus_station    0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty string\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hhid                       0.0\n",
       "distance_to_bus_station    0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:\n",
      "6770\n"
     ]
    }
   ],
   "source": [
    "print(f'country: {country}')\n",
    "print('nullity: ')\n",
    "display(data.isna().mean().sort_values(ascending=False).head(2))\n",
    "# Empty string may or may not be a problem.\n",
    "\n",
    "print('empty string')\n",
    "display(data.isin(['']).mean().sort_values(ascending=False).head(2))\n",
    "print('Number of samples:')\n",
    "print(data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missingness columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: Ethiopia\n",
      "categorical columns with missingness indicators:\n",
      "data_type\n",
      "numeric    25\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>data_type</th>\n",
       "      <th>geographic_indicator_coarser</th>\n",
       "      <th>geographic_indicator_finer</th>\n",
       "      <th>geographic_indicator</th>\n",
       "      <th>variable_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [variable_name, data_type, geographic_indicator_coarser, geographic_indicator_finer, geographic_indicator, variable_description]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical columns with no missingness indicators:\n",
      "3                              hh_wgt\n",
      "9                             hh_size\n",
      "10                       num_children\n",
      "11                 num_young_children\n",
      "12                         num_elders\n",
      "13                num_children_school\n",
      "14                    num_adult_males\n",
      "15                  num_adule_females\n",
      "19                           head_age\n",
      "31                          num_rooms\n",
      "52           num_owned_Kerosene_stove\n",
      "53                  num_owned_CD_Deck\n",
      "54           num_owned_Satellite_Dish\n",
      "55                 num_owned_Sofa_set\n",
      "56                  num_owned_Bicycle\n",
      "57               num_owned_Motorcycle\n",
      "58                num_owned_Cart_hand\n",
      "59              num_owned_Cart_animal\n",
      "60           num_owned_Sewing_machine\n",
      "61        num_owned_Weaving_equipment\n",
      "62           num_owned_Mitad_Electric\n",
      "63       num_owned_Cylinder_gas_stove\n",
      "64      num_owned_Energy_saving_stove\n",
      "65             num_owned_Refrigerator\n",
      "66              num_owned_Private_car\n",
      "67                     num_owned_Gold\n",
      "68                   num_owned_Silver\n",
      "69                 num_owned_Wardrobe\n",
      "70                    num_owned_Shelf\n",
      "71             num_owned_Biogas_stove\n",
      "72        num_owned_Water_storage_pit\n",
      "73                   num_owned_Sickle\n",
      "74           num_owned_Electric_stove\n",
      "75                      num_owned_Axe\n",
      "76                 num_owned_Pick_Axe\n",
      "77                        num_owned32\n",
      "78                        num_owned33\n",
      "79                        num_owned34\n",
      "80                        num_owned35\n",
      "81                  num_owned_Blanket\n",
      "82          num_owned_Mattress_ot_Bed\n",
      "83              num_owned_Wrist_watch\n",
      "84     num_owned_Fixed_line_telephone\n",
      "85        num_owned_Radio_or_recorder\n",
      "86               num_owned_Television\n",
      "87                    num_owned_Bulls\n",
      "88                     num_owned_Oxen\n",
      "89                     num_owned_Cows\n",
      "90                   num_owned_Steers\n",
      "91                  num_owned_Heifers\n",
      "92                   num_owned_Calves\n",
      "93                    num_owned_Goats\n",
      "94                    num_owned_Sheep\n",
      "95                   num_owned_Camels\n",
      "96                   num_owned_Horses\n",
      "97                    num_owned_Mules\n",
      "98                  num_owned_Donkeys\n",
      "99                  num_owned_Chicken\n",
      "138    consumption_per_capita_per_day\n",
      "Name: variable_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Missingness columns (assumes _missing suffix)\n",
    "print(f'country: {country}')\n",
    "\n",
    "missingness_columns_missing = [\n",
    "    c for c in data.columns if ('missing' in c) \n",
    "]\n",
    "missingness_columns_m = [\n",
    "    c for c in data.columns if ('_m' in c) \n",
    "]\n",
    "with_missingness = [\n",
    "    c[:-8] for c in missingness_columns_missing\n",
    "] + [\n",
    "    c[:-2] for c in missingness_columns_m\n",
    "]\n",
    "missingness_columns = missingness_columns_missing + missingness_columns_m\n",
    "for c in missingness_columns:\n",
    "    if not (c in summary.variable_name.values):\n",
    "        print(f\"Missingness column {c} not in summary\")\n",
    "    \n",
    "relevant_summary = summary[summary.variable_name.isin(with_missingness)]\n",
    "print('categorical columns with missingness indicators:')\n",
    "\n",
    "print(relevant_summary.data_type.value_counts())\n",
    "display(relevant_summary[relevant_summary.data_type == 'categorical'])\n",
    "\n",
    "# print numerical columns with no missingness indicators\n",
    "print('numerical columns with no missingness indicators:')\n",
    "print(summary[\n",
    "    (summary.data_type == 'numeric') \n",
    "    & (~summary.variable_name.isin(with_missingness))\n",
    "    & (~summary.variable_name.str.endswith('_missing'))\n",
    "    & (~summary.variable_name.str.endswith('_m'))\n",
    "].variable_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consumption, weights, hh size, poverty rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: Ethiopia\n",
      "mean: 4.681175409246381\n",
      "std: 4.812618484963736\n",
      "rate: 0.4560640131118927\n"
     ]
    }
   ],
   "source": [
    "print(f'country: {country}')\n",
    "assert 'consumption_per_capita_per_day' in data.columns\n",
    "assert 'headcount_adjusted_hh_wgt' in data.columns\n",
    "assert pd.api.types.is_numeric_dtype(data['consumption_per_capita_per_day']), \"'consumption_per_capita_per_day' is not numeric\"\n",
    "assert pd.api.types.is_numeric_dtype(data['headcount_adjusted_hh_wgt']), \"'headcount_adjusted_hh_wgt' is not numeric\"\n",
    "if not 'hh_size' in data.columns:\n",
    "    print('Warning: Missing hh_size')\n",
    "else:\n",
    "    assert np.isclose(data.hh_size * data.hh_wgt, data.headcount_adjusted_hh_wgt).all()\n",
    "    assert pd.api.types.is_numeric_dtype(data['hh_size']), \"'hh_size' is not numeric\"\n",
    "\n",
    "for col in ['headcount_adjusted_hh_wgt_missing', 'consumption_per_capita_per_day_missing', 'hh_wgt_missing']:\n",
    "    if col in data.columns:\n",
    "        assert data[col].sum() == 0, f\"{col} has missing values\"\n",
    "\n",
    "print('mean:', data.consumption_per_capita_per_day.mean())\n",
    "print('std:', data.consumption_per_capita_per_day.std())\n",
    "\n",
    "count_poor = (\n",
    "    data[data.consumption_per_capita_per_day < 2.15].headcount_adjusted_hh_wgt\n",
    ").sum()\n",
    "\n",
    "total = (\n",
    "    data.headcount_adjusted_hh_wgt\n",
    ").sum()\n",
    "rate = count_poor / total\n",
    "\n",
    "print('rate:',rate)\n",
    "# To crosscheck: https://docs.google.com/spreadsheets/d/11wGVZadIZMvR2oXoDtSfjJVvixyv3ievuUOF4k_1HNY/edit?gid=0#gid=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suspiciously named columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: Ethiopia\n",
      "containing the word \"unit\":\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>data_type</th>\n",
       "      <th>geographic_indicator_coarser</th>\n",
       "      <th>geographic_indicator_finer</th>\n",
       "      <th>geographic_indicator</th>\n",
       "      <th>variable_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [variable_name, data_type, geographic_indicator_coarser, geographic_indicator_finer, geographic_indicator, variable_description]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "containing the word \"consumption\":\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>data_type</th>\n",
       "      <th>geographic_indicator_coarser</th>\n",
       "      <th>geographic_indicator_finer</th>\n",
       "      <th>geographic_indicator</th>\n",
       "      <th>variable_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>consumption_per_capita_per_day</td>\n",
       "      <td>numeric</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>consumption_per_capita_per_day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      variable_name data_type  geographic_indicator_coarser  \\\n",
       "138  consumption_per_capita_per_day   numeric                         False   \n",
       "\n",
       "     geographic_indicator_finer  geographic_indicator  \\\n",
       "138                       False                 False   \n",
       "\n",
       "               variable_description  \n",
       "138  consumption_per_capita_per_day  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables with \"id\" or \"code\" and listed numeric:\n"
     ]
    }
   ],
   "source": [
    "print(f'country: {country}')\n",
    "\n",
    "# Suspicious data\n",
    "print('containing the word \"unit\":')\n",
    "display(\n",
    "    summary[\n",
    "        (\n",
    "            summary.variable_name.str.contains('unit')\n",
    "            | summary.variable_description.str.contains('unit')\n",
    "        ) & (\n",
    "            ~summary.variable_name.str.contains('community')\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "print('containing the word \"consumption\":')\n",
    "display(\n",
    "    summary[\n",
    "        summary.variable_name.str.contains('consumption')\n",
    "        | summary.variable_description.str.contains('consumption')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print variables whose name contains \"id\" or \"code\" and are listed as numeric in the summary\n",
    "print('variables with \"id\" or \"code\" and listed numeric:')\n",
    "\n",
    "filtered_variables = summary[\n",
    "    (summary[\"variable_name\"].str.contains(\"id|code\", case=False, na=False)) &\n",
    "    (summary[\"data_type\"] == \"numeric\")\n",
    "]\n",
    "\n",
    "# Print the name and description of the filtered variables\n",
    "for _, row in filtered_variables.iterrows():\n",
    "    print(f\"Name: {row['variable_name']}, Description: {row['variable_description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary correctness: Matches data, format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: Ethiopia\n",
      "Variables in summary but not in data: set()\n",
      "Columns in data but not in summary: {'headcount_adjusted_hh_wgt'}\n"
     ]
    }
   ],
   "source": [
    "print(f'country: {country}')\n",
    "\n",
    "# check that metadata and data match\n",
    "data_columns = set(data.columns)\n",
    "\n",
    "summary_variable_names = set(summary['variable_name'])\n",
    "missing_in_data = summary_variable_names - data_columns\n",
    "missing_in_summary = data_columns - summary_variable_names\n",
    "\n",
    "print(\"Variables in summary but not in data:\", missing_in_data)\n",
    "print(\"Columns in data but not in summary:\", missing_in_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: Ethiopia\n"
     ]
    }
   ],
   "source": [
    "print(f'country: {country}')\n",
    "# Check that \"summary\" fits the required format\n",
    "required_columns = {\n",
    "    \"variable_name\", \"data_type\", \"geographic_indicator\", \"geographic_indicator_coarser\"\n",
    "    }\n",
    "summary_columns = set(summary.columns)\n",
    "\n",
    "missing_columns = required_columns - summary_columns\n",
    "if missing_columns:\n",
    "    print(f\"Missing required columns in summary: {missing_columns}\")\n",
    "\n",
    "# Ensure \"data_type\" has only permitted values\n",
    "permitted_data_types = {\"numeric\", \"categorical\"}\n",
    "for _, row in summary.iterrows():\n",
    "    if row[\"data_type\"] not in permitted_data_types:\n",
    "        print(\n",
    "            f\"Invalid data_type '{row['data_type']}' for variable '{row['variable_name']}'. \"\n",
    "            f\"Description: {row['variable_description']}\"\n",
    "        )\n",
    "\n",
    "# Ensure \"geographic_indicator_coarser\", \"geographic_indicator_finer\" is boolean or 0-1\n",
    "for _, row in summary.iterrows():\n",
    "    for c in [\"geographic_indicator\", \"geographic_indicator_coarser\", \"geographic_indicator_finer\"]:\n",
    "        if c not in row:\n",
    "            continue\n",
    "        if row[c] not in [0, 1, True, False, None]:\n",
    "            print(\n",
    "                f\"Invalid {c} '{row[c]}' for variable '{row['variable_name']}'. \"\n",
    "                f\"Description: {row['variable_description']}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: Ethiopia\n",
      "categorical in summary, numeric in data: 'hhid'; hhid\n",
      "categorical in summary, numeric in data: 'ea_id'; ea_id\n",
      "categorical in summary, numeric in data: 'rural_urban'; rural_urban\n",
      "categorical in summary, numeric in data: 'region_code'; region_code\n",
      "categorical in summary, numeric in data: 'woreda_code'; woreda_code\n",
      "categorical in summary, numeric in data: 'city_code'; city_code\n",
      "categorical in summary, numeric in data: 'subcity_code'; subcity_code\n",
      "categorical in summary, numeric in data: 'kebele_code'; kebele_code\n",
      "categorical in summary, numeric in data: 'max_edu_adult'; max_edu_adult\n",
      "categorical in summary, numeric in data: 'max_edu_adult_female'; max_edu_adult_female\n",
      "categorical in summary, numeric in data: 'head_gender'; head_gender\n",
      "categorical in summary, numeric in data: 'religion'; religion\n",
      "categorical in summary, numeric in data: 'head_marital_status'; head_marital_status\n",
      "categorical in summary, numeric in data: 'head_agri_7d'; head_agri_7d\n",
      "categorical in summary, numeric in data: 'head_self_emp_7d'; head_self_emp_7d\n",
      "categorical in summary, numeric in data: 'head_casual_7d'; head_casual_7d\n",
      "categorical in summary, numeric in data: 'head_workpay_7d'; head_workpay_7d\n",
      "categorical in summary, numeric in data: 'head_wage_job'; head_wage_job\n",
      "categorical in summary, numeric in data: 'head_workpay_12m'; head_workpay_12m\n",
      "categorical in summary, numeric in data: 'head_education'; head_education\n",
      "categorical in summary, numeric in data: 'occupancy_basis'; occupancy_basis\n",
      "categorical in summary, numeric in data: 'wall_material'; wall_material\n",
      "categorical in summary, numeric in data: 'roof_material'; roof_material\n",
      "categorical in summary, numeric in data: 'floor_material'; floor_material\n",
      "categorical in summary, numeric in data: 'kitchen_type'; kitchen_type\n",
      "categorical in summary, numeric in data: 'primary_oven_type'; primary_oven_type\n",
      "categorical in summary, numeric in data: 'toilet_type'; toilet_type\n",
      "categorical in summary, numeric in data: 'toilet_shared'; toilet_shared\n",
      "categorical in summary, numeric in data: 'toilet_location'; toilet_location\n",
      "categorical in summary, numeric in data: 'has_handwash_place'; has_handwash_place\n",
      "categorical in summary, numeric in data: 'has_handwash_water'; has_handwash_water\n",
      "categorical in summary, numeric in data: 'has_handwash_soap'; has_handwash_soap\n",
      "categorical in summary, numeric in data: 'solidwaste_disposal_type'; solidwaste_disposal_type\n",
      "categorical in summary, numeric in data: 'drinking_water_source'; drinking_water_source\n",
      "categorical in summary, numeric in data: 'drinking_source_location'; drinking_source_location\n",
      "categorical in summary, numeric in data: 'dry_season_source_different'; dry_season_source_different\n",
      "categorical in summary, numeric in data: 'dry_season_main_source'; dry_season_main_source\n",
      "categorical in summary, numeric in data: 'dry_source_location'; dry_source_location\n",
      "categorical in summary, numeric in data: 'main_lighting_source'; main_lighting_source\n",
      "categorical in summary, numeric in data: 'main_cooking_fuel'; main_cooking_fuel\n",
      "categorical in summary, numeric in data: 'household_othr_buildings'; household_othr_buildings\n",
      "categorical in summary, numeric in data: 'business'; business\n",
      "categorical in summary, numeric in data: 'in_woreda_town'; in_woreda_town\n",
      "categorical in summary, numeric in data: 'in_major_urban_centre'; in_major_urban_centre\n",
      "categorical in summary, numeric in data: 'large_weekly_market'; large_weekly_market\n",
      "categorical in summary, numeric in data: 'health_post_present'; health_post_present\n",
      "categorical in summary, numeric in data: 'health_center_present'; health_center_present\n",
      "categorical in summary, numeric in data: 'doctor_in_health_center'; doctor_in_health_center\n",
      "categorical in summary, numeric in data: 'doctor_lives_in_community'; doctor_lives_in_community\n",
      "categorical in summary, numeric in data: 'commercial_bank_present'; commercial_bank_present\n",
      "categorical in summary, numeric in data: 'microfinance_present'; microfinance_present\n",
      "categorical in summary, numeric in data: 'water_service_present'; water_service_present\n",
      "categorical in summary, numeric in data: 'atm_present'; atm_present\n",
      "categorical in summary, numeric in data: 'sacco_present'; sacco_present\n",
      "categorical in summary, numeric in data: 'insurance_branch_present'; insurance_branch_present\n",
      "categorical in summary, numeric in data: 'land_dwelling_area_m'; land_dwelling_area_m\n",
      "categorical in summary, numeric in data: 'land_area_m2_m'; land_area_m2_m\n",
      "categorical in summary, numeric in data: 'nbd_population_m'; nbd_population_m\n",
      "categorical in summary, numeric in data: 'distance_to_tar_road_m'; distance_to_tar_road_m\n",
      "categorical in summary, numeric in data: 'distance_to_bus_station_m'; distance_to_bus_station_m\n",
      "categorical in summary, numeric in data: 'distance_to_woreda_town_m'; distance_to_woreda_town_m\n",
      "categorical in summary, numeric in data: 'distance_to_major_urban_centre_m'; distance_to_major_urban_centre_m\n",
      "categorical in summary, numeric in data: 'distance_to_weekly_market_m'; distance_to_weekly_market_m\n",
      "categorical in summary, numeric in data: 'distance_govt_primary_school_m'; distance_govt_primary_school_m\n",
      "categorical in summary, numeric in data: 'distance_to_govt_sec_school_m'; distance_to_govt_sec_school_m\n",
      "categorical in summary, numeric in data: 'num_rel_primary_schools_m'; num_rel_primary_schools_m\n",
      "categorical in summary, numeric in data: 'num_rel_secondary_schools_m'; num_rel_secondary_schools_m\n",
      "categorical in summary, numeric in data: 'num_private_primary_schools_m'; num_private_primary_schools_m\n",
      "categorical in summary, numeric in data: 'num_private_secondary_schools_m'; num_private_secondary_schools_m\n",
      "categorical in summary, numeric in data: 'distance_to_health_post_m'; distance_to_health_post_m\n",
      "categorical in summary, numeric in data: 'distance_to_hospital_m'; distance_to_hospital_m\n",
      "categorical in summary, numeric in data: 'distance_to_commercial_bank_m'; distance_to_commercial_bank_m\n",
      "categorical in summary, numeric in data: 'distance_to_microfinance_m'; distance_to_microfinance_m\n",
      "categorical in summary, numeric in data: 'distance_to_atm_m'; distance_to_atm_m\n",
      "categorical in summary, numeric in data: 'distance_to_sacco_m'; distance_to_sacco_m\n",
      "categorical in summary, numeric in data: 'distance_to_insurance_branch_m'; distance_to_insurance_branch_m\n",
      "categorical in summary, numeric in data: 'elevation_m'; elevation_m\n",
      "categorical in summary, numeric in data: 'popdensity_m'; popdensity_m\n",
      "categorical in summary, numeric in data: 'latitude_m'; latitude_m\n",
      "categorical in summary, numeric in data: 'longitude_m'; longitude_m\n",
      "categorical in summary, numeric in data: 'region_zone'; region_zone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/tmp/ipykernel_2041397/1395230008.py:13: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if col in data.columns and not pd.api.types.is_categorical_dtype(data[col]):\n"
     ]
    }
   ],
   "source": [
    "print(f'country: {country}')\n",
    "\n",
    "# Check that numeric columns in summary are actually numeric in data\n",
    "numeric_columns = summary[summary[\"data_type\"] == \"numeric\"][\"variable_name\"]\n",
    "for col in numeric_columns:\n",
    "    if col in data.columns and not pd.api.types.is_numeric_dtype(data[col]):\n",
    "        description = summary.loc[summary[\"variable_name\"] == col, \"variable_description\"].values[0]\n",
    "        print(f\"BAD: numeric in summary, non-numeric in data: '{col}'; {description}\")\n",
    "\n",
    "# Check that categorical columns in summary are actually categorical in data (less important)\n",
    "categorical_columns = summary[summary[\"data_type\"] == \"categorical\"][\"variable_name\"]\n",
    "for col in categorical_columns:\n",
    "    if col in data.columns and not pd.api.types.is_categorical_dtype(data[col]):\n",
    "        description = summary.loc[summary[\"variable_name\"] == col, \"variable_description\"].values[0]\n",
    "        print(f\"categorical in summary, numeric in data: '{col}'; {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: Ethiopia\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicate information. Don't do if there are too many columns.\n",
    "print(f'country: {country}')\n",
    "\n",
    "find_equivalent_columns(data, summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geography and stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: Ethiopia\n",
      "geographic indicators:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>data_type</th>\n",
       "      <th>geographic_indicator_coarser</th>\n",
       "      <th>geographic_indicator_finer</th>\n",
       "      <th>geographic_indicator</th>\n",
       "      <th>variable_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ea_id</td>\n",
       "      <td>categorical</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ea_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>region_code</td>\n",
       "      <td>categorical</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>region_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>woreda_code</td>\n",
       "      <td>categorical</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>woreda_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>city_code</td>\n",
       "      <td>categorical</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>city_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>subcity_code</td>\n",
       "      <td>categorical</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>subcity_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kebele_code</td>\n",
       "      <td>categorical</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>kebele_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>region_zone</td>\n",
       "      <td>categorical</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>region_zone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    variable_name    data_type  geographic_indicator_coarser  \\\n",
       "1           ea_id  categorical                         False   \n",
       "4     region_code  categorical                          True   \n",
       "5     woreda_code  categorical                         False   \n",
       "6       city_code  categorical                         False   \n",
       "7    subcity_code  categorical                         False   \n",
       "8     kebele_code  categorical                         False   \n",
       "164   region_zone  categorical                         False   \n",
       "\n",
       "     geographic_indicator_finer  geographic_indicator variable_description  \n",
       "1                         False                  True                ea_id  \n",
       "4                          True                  True          region_code  \n",
       "5                         False                  True          woreda_code  \n",
       "6                         False                  True            city_code  \n",
       "7                         False                  True         subcity_code  \n",
       "8                         False                  True          kebele_code  \n",
       "164                        True                  True          region_zone  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ea_id\n",
      "535\n",
      "region_code\n",
      "11\n",
      "woreda_code\n",
      "27\n",
      "city_code\n",
      "5\n",
      "subcity_code\n",
      "11\n",
      "kebele_code\n",
      "41\n",
      "region_zone\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "print(f'country: {country}')\n",
    "\n",
    "print('geographic indicators:')\n",
    "display(summary[summary.geographic_indicator])\n",
    "for _, row in summary[summary.geographic_indicator].iterrows():\n",
    "    print(row.variable_name)\n",
    "    print(data[row.variable_name].nunique())\n",
    "\n",
    "if False:\n",
    "    partially_represented = summary[\n",
    "        (summary.geographic_indicator_finer) & ~(summary.geographic_indicator_coarser)\n",
    "    ]\n",
    "    if len(partially_represented) == 0:\n",
    "        print('No partially represented geo level')\n",
    "    else:\n",
    "        assert len(partially_represented) == 1\n",
    "        print('partially represented:')\n",
    "        print(partially_represented.variable_name.values[0])\n",
    "        print('partially represented value counts:')\n",
    "        print(data[partially_represented.variable_name.values[0]].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: Ethiopia\n",
      "proposed stratifier: region_zone\n",
      "count per unit\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_zone</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>DIRE DAWA_1</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>HARAR_1</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>GAMBELA_1</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>BENISHANGUL GUMUZ_2</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BENISHANGUL GUMUZ_1</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>OROMIA_24</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>OROMIA_28</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>OROMIA_30</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>OROMIA_35</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>BENISHANGUL GUMUZ_4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            region_zone  count\n",
       "36          DIRE DAWA_1    579\n",
       "41              HARAR_1    550\n",
       "37            GAMBELA_1    248\n",
       "33  BENISHANGUL GUMUZ_2    164\n",
       "32  BENISHANGUL GUMUZ_1    160\n",
       "..                  ...    ...\n",
       "57            OROMIA_24     15\n",
       "58            OROMIA_28     15\n",
       "60            OROMIA_30     15\n",
       "62            OROMIA_35     15\n",
       "35  BENISHANGUL GUMUZ_4     10\n",
       "\n",
       "[105 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights per unit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "region_zone\n",
       "OROMIA_1                1\n",
       "OROMIA_23               1\n",
       "OROMIA_24               1\n",
       "BENISHANGUL GUMUZ_4     1\n",
       "OROMIA_28               1\n",
       "                       ..\n",
       "TIGRAY_2               18\n",
       "AFAR_2                 19\n",
       "GAMBELA_1              22\n",
       "HARAR_1                50\n",
       "DIRE DAWA_1            50\n",
       "Name: hh_wgt, Length: 105, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regions per weight class\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hh_wgt\n",
       "7.594256       1\n",
       "2482.531727    1\n",
       "2483.181945    1\n",
       "2514.627852    1\n",
       "2538.286831    1\n",
       "              ..\n",
       "802.221053     2\n",
       "1231.423933    2\n",
       "8256.395349    2\n",
       "1858.280556    3\n",
       "6905.952500    4\n",
       "Name: region_zone, Length: 660, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count per unit x weight\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hh_wgt</th>\n",
       "      <th>region_zone</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>151.035714</td>\n",
       "      <td>DIRE DAWA_1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>1220.930769</td>\n",
       "      <td>ADDIS ABABA_2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>278.439990</td>\n",
       "      <td>DIRE DAWA_1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>802.221053</td>\n",
       "      <td>BENISHANGUL GUMUZ_2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>138.328128</td>\n",
       "      <td>HARAR_1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>511.552037</td>\n",
       "      <td>SNNP_10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1127.846219</td>\n",
       "      <td>OROMIA_6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1107.151793</td>\n",
       "      <td>OROMIA_4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>57.886410</td>\n",
       "      <td>AFAR_4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1771.077508</td>\n",
       "      <td>DIRE DAWA_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>672 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          hh_wgt          region_zone  count\n",
       "97    151.035714          DIRE DAWA_1     60\n",
       "320  1220.930769        ADDIS ABABA_2     30\n",
       "183   278.439990          DIRE DAWA_1     30\n",
       "262   802.221053  BENISHANGUL GUMUZ_2     20\n",
       "88    138.328128              HARAR_1     20\n",
       "..           ...                  ...    ...\n",
       "226   511.552037              SNNP_10      1\n",
       "298  1127.846219             OROMIA_6      1\n",
       "296  1107.151793             OROMIA_4      1\n",
       "30     57.886410               AFAR_4      1\n",
       "394  1771.077508          DIRE DAWA_1      1\n",
       "\n",
       "[672 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stratification\n",
    "print(f'country: {country}')\n",
    "print('proposed stratifier:', proposed_stratifier)\n",
    "print('count per unit')\n",
    "display(data.groupby(proposed_stratifier, observed=True).size().reset_index(name='count').sort_values('count', ascending=False))\n",
    "\n",
    "print('weights per unit')\n",
    "display(data.groupby(proposed_stratifier,  observed=True).hh_wgt.nunique().sort_values())\n",
    "\n",
    "print('regions per weight class')\n",
    "display(data.groupby('hh_wgt', observed=True)[proposed_stratifier].nunique().sort_values())\n",
    "\n",
    "print('count per unit x weight')\n",
    "display(\n",
    "    data.groupby(['hh_wgt', proposed_stratifier],  observed=True)\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    "    .sort_values('count', ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leo_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
