{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "\n",
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "def normalize_text(text):\n",
    "    decomposed = unicodedata.normalize('NFKD', str(text))\n",
    "    # Keep only non-combining characters\n",
    "    stripped = ''.join(c for c in decomposed if not unicodedata.combining(c))\n",
    "    return stripped.strip().lower()\n",
    "\n",
    "def gather_survey_year_pip_data(\n",
    "    country_list: pd.DataFrame, \n",
    "    pip_data: pd.DataFrame,\n",
    "    poverty_line\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add poverty rates to country_list using pip_data with interpolation logic.\n",
    "    \n",
    "    Args:\n",
    "        country_list: DataFrame with columns 'Country', 'Year', 'Country Code'\n",
    "        pip_data: DataFrame with PIP poverty data (non-interpolated)\n",
    "        poverty_line: Poverty line to use (default 2.15)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with added 'poverty_rate' and 'estimate_type' columns\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter pip_data for the specified poverty line\n",
    "    \n",
    "    # Create a copy of country_list to avoid modifying the original\n",
    "    result = country_list[['country_code', 'survey_year']].copy()\n",
    "    result['wb_poverty_rate_survey_year'] = np.nan\n",
    "    result['interpolation_method_rate_survey_year'] = ''\n",
    "    \n",
    "    # Group pip data by country for efficient lookup\n",
    "    pip_by_country = pip_data.groupby('country_code')\n",
    "    \n",
    "    for idx, row in result.iterrows():\n",
    "\n",
    "        country_code = row['country_code']\n",
    "        target_year = int(row['survey_year'])  # Ensure target_year is an integer\n",
    "        \n",
    "        # Get pip data for this country\n",
    "        if country_code not in pip_by_country.groups:\n",
    "            result.loc[idx, 'interpolation_method_rate_survey_year'] = 'no data available'\n",
    "            continue\n",
    "            \n",
    "        country_data = pip_by_country.get_group(country_code).copy()\n",
    "        country_data = country_data.sort_values('reporting_year')\n",
    "        \n",
    "        # Check for exact year match\n",
    "        exact_match = country_data[country_data['reporting_year'] == target_year]\n",
    "        if not exact_match.empty:\n",
    "            poverty_rate = exact_match.iloc[0]['headcount']\n",
    "            poverty_gap = exact_match.iloc[0]['poverty_gap']\n",
    "            estimate_type = 'exact year'\n",
    "        else:            \n",
    "            # No exact match - need to interpolate or use nearest\n",
    "            poverty_rate, poverty_gap, estimate_type = (\n",
    "                get_interpolated_poverty_estimate(country_data, target_year)\n",
    "            )\n",
    "\n",
    "        result.loc[idx, 'wb_poverty_rate_survey_year'] = poverty_rate\n",
    "        result.loc[idx, 'wb_poverty_gap_index_survey_year'] = poverty_gap\n",
    "        result.loc[idx, 'interpolation_method_rate_survey_year'] = estimate_type\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_interpolated_poverty_estimate(country_data: pd.DataFrame, target_year: int) -> Tuple[Optional[float], str]:\n",
    "    \"\"\"\n",
    "    Get poverty estimate for a target year using interpolation or nearest year logic.\n",
    "    \n",
    "    Args:\n",
    "        country_data: PIP data for a single country, sorted by year\n",
    "        target_year: Year for which to estimate poverty rate\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (poverty_rate, poverty_gap, estimate_type)\n",
    "    \"\"\"\n",
    "    country_data.dropna(subset=['reporting_year', 'headcount'], inplace=True)\n",
    "    if country_data.empty:\n",
    "        return None, None, 'no data available'\n",
    "    \n",
    "    # Ensure target_year is an integer and years are integers\n",
    "    target_year = int(target_year)\n",
    "    years = country_data['reporting_year'].astype(int).values\n",
    "    rates = country_data['headcount'].values\n",
    "    gaps = country_data['poverty_gap'].values\n",
    "\n",
    "    # Find years before and after target year\n",
    "    years_before = years[years < target_year]\n",
    "    years_after = years[years > target_year]\n",
    "    \n",
    "    # Case 1: Can interpolate (have years both before and after)\n",
    "    if len(years_before) > 0 and len(years_after) > 0:\n",
    "        # Get closest years before and after\n",
    "        year_before = years_before.max()\n",
    "        year_after = years_after.min()\n",
    "        \n",
    "        # Get corresponding poverty rates\n",
    "        try:\n",
    "            rate_before = country_data[country_data['reporting_year'] == year_before]['headcount'].iloc[0]\n",
    "            rate_after = country_data[country_data['reporting_year'] == year_after]['headcount'].iloc[0]\n",
    "\n",
    "            gap_before = country_data[country_data['reporting_year'] == year_before]['poverty_gap'].iloc[0]\n",
    "            gap_after = country_data[country_data['reporting_year'] == year_after]['poverty_gap'].iloc[0]\n",
    "        except:\n",
    "            from IPython import embed; embed()\n",
    "        \n",
    "        # Linear interpolation\n",
    "        weight = (target_year - year_before) / (year_after - year_before)\n",
    "        interpolated_rate = rate_before + weight * (rate_after - rate_before)\n",
    "        interpolated_gap = gap_before + weight * (gap_after - gap_before)\n",
    "        \n",
    "        estimate_type = f'interpolated using {year_before} and {year_after}'\n",
    "        return interpolated_rate, interpolated_gap, estimate_type\n",
    "    \n",
    "    # Case 2: Only extrapolation possible - use nearest year instead\n",
    "    else:\n",
    "        # Find nearest year\n",
    "        year_distances = np.abs(years - target_year)\n",
    "        nearest_idx = np.argmin(year_distances)\n",
    "        nearest_year = years[nearest_idx]\n",
    "        nearest_rate = rates[nearest_idx]\n",
    "        nearest_gap = gaps[nearest_idx]\n",
    "        \n",
    "        estimate_type = f'from nearest year: {nearest_year}'\n",
    "        return nearest_rate, nearest_gap, estimate_type\n",
    "\n",
    "survey_directory_to_country_name_map = { # E: don't need it in this code\n",
    "    'burkina_faso': 'burkina faso',\n",
    "    'cote_divoire': \"coÌ‚te d'ivoire\",\n",
    "    'south_africa': 'south africa',\n",
    "    'south_sudan': 'south sudan',\n",
    "    'yemen': 'yemen, rep.'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_data_povertyline_2017 = pd.read_csv(\n",
    "    'data/eop/compiled_country_data/pip_2017_20251024.csv',\n",
    "    dtype={'reporting_year': int}\n",
    ")\n",
    "\n",
    "pip_data_povertyline_2021 = pd.read_csv(\n",
    "    'data/eop/compiled_country_data/pip_2021_20251024.csv',\n",
    "    dtype={'reporting_year': int}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_value_with_year(df, value_col):\n",
    "    def latest_func(group):\n",
    "        if group[value_col].notna().any():\n",
    "            idx = group['reporting_year'].idxmax()\n",
    "            return pd.Series({\n",
    "                f'latest_{value_col}': group.loc[idx, value_col],\n",
    "                'year': group.loc[idx, 'reporting_year']\n",
    "            })\n",
    "        else:\n",
    "            return pd.Series({\n",
    "                f'latest_{value_col}': np.nan,\n",
    "                'year': np.nan\n",
    "            })\n",
    "    return df.groupby('country_code').apply(latest_func).reset_index()\n",
    "\n",
    "latest_poverty_rate_povertyline_2017 = get_latest_value_with_year(pip_data_povertyline_2017, 'headcount')\n",
    "latest_poverty_gap_index_povertyline_2017 = get_latest_value_with_year(pip_data_povertyline_2017, 'poverty_gap')\n",
    "\n",
    "latest_poverty_rate_povertyline_2021 = get_latest_value_with_year(pip_data_povertyline_2021, 'headcount')\n",
    "latest_poverty_gap_index_povertyline_2021 = get_latest_value_with_year(pip_data_povertyline_2021, 'poverty_gap')\n",
    "superset = latest_poverty_rate_povertyline_2017\n",
    "superset = superset.merge(\n",
    "    pip_data_povertyline_2017[['country_code', 'country_name']].drop_duplicates(\n",
    "        subset='country_code'\n",
    "    ),\n",
    "    on='country_code', how='left'\n",
    ").rename(\n",
    "    columns={'country_name': 'country'}\n",
    ")\n",
    "superset.country = superset.country.apply(normalize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "latest_poverty_rate_povertyline_2017.rename(columns={\n",
    "    'latest_headcount': 'wb_poverty_rate_povertyline_2017_most_recent',\n",
    "    'year': 'wb_poverty_rate_povertyline_2017_most_recent_year'\n",
    "}, inplace=True)\n",
    "latest_poverty_gap_index_povertyline_2017.rename(columns={\n",
    "    'latest_poverty_gap': 'wb_poverty_gap_index_povertyline_2017_most_recent',\n",
    "    'year': 'wb_poverty_gap_index_povertyline_2017_most_recent_year'\n",
    "}, inplace=True)\n",
    "\n",
    "latest_poverty_rate_povertyline_2021.rename(columns={\n",
    "    'latest_headcount': 'wb_poverty_rate_povertyline_2021_most_recent',\n",
    "    'year': 'wb_poverty_rate_povertyline_2021_most_recent_year'\n",
    "}, inplace=True)\n",
    "latest_poverty_gap_index_povertyline_2021.rename(columns={\n",
    "    'latest_poverty_gap': 'wb_poverty_gap_index_povertyline_2021_most_recent',\n",
    "    'year': 'wb_poverty_gap_index_povertyline_2021_most_recent_year'\n",
    "}, inplace=True)\n",
    "\n",
    "superset = superset[['country_code', 'country']].merge(\n",
    "    latest_poverty_rate_povertyline_2017, on='country_code', how='left'\n",
    ")\n",
    "\n",
    "superset = superset.merge(\n",
    "    latest_poverty_gap_index_povertyline_2017, on='country_code', how='left'\n",
    ")\n",
    "\n",
    "superset = superset.merge(\n",
    "    latest_poverty_rate_povertyline_2021, on='country_code', how='left'\n",
    ")\n",
    "\n",
    "superset = superset.merge(\n",
    "    latest_poverty_gap_index_povertyline_2021, on='country_code', how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_data = pd.read_csv(\n",
    "    'data/eop/compiled_country_data/world_bank_data_download_20250708/API_SP.POP.TOTL_DS2_en_csv_v2_38144.csv',\n",
    "    skiprows=4\n",
    ")\n",
    "\n",
    "population_data.rename(columns={\n",
    "    'Country Code': 'country_code', '2023': 'total_population_2023'\n",
    "}, inplace=True)\n",
    "\n",
    "superset = superset.merge(\n",
    "    population_data[['country_code', 'total_population_2023']], \n",
    "    on='country_code', how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for survey countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_countries = pd.read_csv(\n",
    "    'data/eop/compiled_country_data/survey_countries.csv',\n",
    "    dtype=str\n",
    ").drop(columns='country')\n",
    "survey_countries = survey_countries[survey_countries.using == 'True'].drop(columns='using')\n",
    "accumulated_data = superset.copy()  # checkpoint\n",
    "accumulated_data = accumulated_data.merge(survey_countries, on='country_code', how='left') # E: somalia is not in PIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add poverty rates and gaps\n",
    "survey_year_poverty_data_povertyline_2017 = gather_survey_year_pip_data(\n",
    "    accumulated_data[accumulated_data.survey_year.notna()], pip_data_povertyline_2017, 2.15\n",
    ").drop(columns='survey_year')\n",
    "\n",
    "survey_year_poverty_data_povertyline_2017.rename(columns={\n",
    "    'wb_poverty_rate_survey_year': 'wb_poverty_rate_povertyline_2017_survey_year', \n",
    "    'wb_poverty_gap_index_survey_year': 'wb_poverty_gap_index_povertyline_2017_survey_year',\n",
    "    'interpolation_method_rate_survey_year': 'interpolation_method_rate_povertyline_2017_survey_year',\n",
    "}, inplace=True)\n",
    "\n",
    "survey_year_poverty_data_povertyline_2021 = gather_survey_year_pip_data(\n",
    "    accumulated_data[accumulated_data.survey_year.notna()], pip_data_povertyline_2021, 3.0\n",
    ").drop(columns='survey_year')\n",
    "survey_year_poverty_data_povertyline_2021.rename(columns={\n",
    "    'wb_poverty_rate_survey_year': 'wb_poverty_rate_povertyline_2021_survey_year', \n",
    "    'wb_poverty_gap_index_survey_year': 'wb_poverty_gap_index_povertyline_2021_survey_year',\n",
    "    'interpolation_method_rate_survey_year': 'interpolation_method_rate_povertyline_2021_survey_year'\n",
    "}, inplace=True)\n",
    "\n",
    "accumulated_data = accumulated_data.merge(\n",
    "    survey_year_poverty_data_povertyline_2017, on='country_code', how='left'\n",
    ")\n",
    "accumulated_data = accumulated_data.merge(\n",
    "    survey_year_poverty_data_povertyline_2021, on='country_code', how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_data = pd.read_csv(\n",
    "    'data/eop/compiled_country_data/world_bank_data_download_20250708/API_SP.POP.TOTL_DS2_en_csv_v2_38144.csv',\n",
    "    skiprows=4\n",
    ").dropna(axis=1, how='all') # E: drop columns that are all NaN\n",
    "\n",
    "population_data.rename(columns={\n",
    "    'Country Code': 'country_code'\n",
    "}, inplace=True)\n",
    "population_data = population_data.merge(\n",
    "    accumulated_data[['country_code', 'survey_year']], on='country_code', how='inner' # E: Taiwan is lost here\n",
    ")\n",
    "\n",
    "\n",
    "population_list = []\n",
    "for _, row in population_data.iterrows():\n",
    "\n",
    "    if pd.isna(row.survey_year):\n",
    "        continue\n",
    "    result = {'country_code': row.country_code}\n",
    "    result['total_population_survey_year'] = row[row.survey_year]\n",
    "    population_list.append(result)\n",
    "population = pd.DataFrame(population_list)\n",
    "\n",
    "accumulated_data = accumulated_data.merge(\n",
    "    population, on='country_code', how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_wb_data = pd.read_csv(\n",
    "    'data/eop/compiled_country_data/world_bank_data_download_20250627/ba42da22-4cc7-4d46-86ef-7fc5dcd2ac5e_Data.csv'\n",
    ")\n",
    "\n",
    "\n",
    "def rename_year_columns(col):\n",
    "    match = re.match(r'^(\\d{4}) \\[YR\\d{4}\\]$', col)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return col\n",
    "\n",
    "composite_wb_data.columns = [rename_year_columns(c) for c in composite_wb_data.columns]\n",
    "composite_wb_data = composite_wb_data.rename(columns={\n",
    "    'Country Name': 'country',\n",
    "    'Country Code': 'country_code',\n",
    "    'Series Code': 'series_code'\n",
    "}).drop(columns='Series Name')\n",
    "\n",
    "\n",
    "year_cols = [col for col in composite_wb_data.columns if re.match(r'^\\d{4}$', col)]\n",
    "year_cols.sort()\n",
    "composite_wb_data[year_cols] = composite_wb_data[year_cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oda_raw = composite_wb_data[composite_wb_data['series_code'] == 'DT.ODA.ALLD.KD'].copy()\n",
    "\n",
    "cpi = pd.read_csv(\n",
    "    'data/eop/compiled_country_data/world_bank_data_download_20251117/API_FP.CPI.TOTL_DS2_en_csv_v2_216045.csv',\n",
    "    skiprows=4,\n",
    ")\n",
    "us_cpi_2021 = cpi.loc[cpi['Country Code'] == 'USA', '2021'].values[0]\n",
    "us_cpi_2023 = cpi.loc[cpi['Country Code'] == 'USA', '2023'].values[0]\n",
    "\n",
    "oda_raw[year_cols] = oda_raw[year_cols] * (us_cpi_2023 / us_cpi_2021)\n",
    "\n",
    "oda_list = []\n",
    "for _, row in oda_raw.iterrows():\n",
    "    result = {'country_code': row.country_code}\n",
    "    result['ODA_most_recent_year'] = None\n",
    "    result['ODA_most_recent'] = np.nan\n",
    "    for year in year_cols:\n",
    "        if pd.notna(row[year]):\n",
    "            result['ODA_most_recent_year'] = year\n",
    "            result['ODA_most_recent'] = row[year] / 1e9  # Units of billions of USD\n",
    "    oda_list.append(result)\n",
    "oda = pd.DataFrame(oda_list)\n",
    "accumulated_data = accumulated_data.merge(\n",
    "    oda, on='country_code', how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_raw = pd.read_csv(\n",
    "    'data/eop/compiled_country_data/world_bank_data_download_20250628/API_NY.GDP.MKTP.KD_DS2_en_csv_v2_127117.csv',\n",
    "    skiprows=4,\n",
    ")\n",
    "gdp_raw = gdp_raw.rename(columns={'Country Code': 'country_code'})\n",
    "\n",
    "cpi = pd.read_csv(\n",
    "    'data/eop/compiled_country_data/world_bank_data_download_20251117/API_FP.CPI.TOTL_DS2_en_csv_v2_216045.csv',\n",
    "    skiprows=4,\n",
    ")\n",
    "us_cpi_2015 = cpi.loc[cpi['Country Code'] == 'USA', '2015'].values[0]\n",
    "us_cpi_2023 = cpi.loc[cpi['Country Code'] == 'USA', '2023'].values[0]\n",
    "\n",
    "gdp_raw = accumulated_data.loc[\n",
    "    accumulated_data.survey_year.notna(), ['country_code', 'survey_year']\n",
    "].merge(gdp_raw, on='country_code', how='left')\n",
    "\n",
    "gdp_list = []\n",
    "for _, row in gdp_raw.iterrows():\n",
    "    result = {\n",
    "        'country_code': row.country_code,\n",
    "        'GDP_survey_year': row[row.survey_year] * (us_cpi_2023 / us_cpi_2015) / 1e9\n",
    "    }\n",
    "    gdp_list.append(result)\n",
    "gdp = pd.DataFrame(gdp_list)\n",
    "accumulated_data = accumulated_data.merge(gdp, on='country_code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_data_raw = pd.read_csv(\n",
    "    'data/eop/compiled_country_data/imf_data_download_20250714/imf-dm-export-20250714.csv'\n",
    ")\n",
    "revenue_data_raw.rename(columns={'Revenue (% of GDP)': 'country'}, inplace=True)\n",
    "revenue_data_raw.country = revenue_data_raw.country.str.lower()\n",
    "\n",
    "revenue_data_raw.dropna(subset='country', inplace=True)\n",
    "revenue_data_raw.country.replace({\n",
    "    'congo, dem. rep. of the': 'congo, dem. rep.',\n",
    "    'south sudan, republic of': 'south sudan',\n",
    "    'yemen': 'yemen, rep.'\n",
    "}, inplace=True)\n",
    "revenue_data_raw.country = revenue_data_raw.country.apply(normalize_text)\n",
    "\n",
    "revenue_data_raw = accumulated_data.loc[\n",
    "    accumulated_data.survey_year.notna(), ['country', 'survey_year']\n",
    "].merge(revenue_data_raw, on='country', how='left')\n",
    "revenue_list = []\n",
    "for _, row in revenue_data_raw.iterrows():\n",
    "    result = {\n",
    "        'country': row.country,\n",
    "        'government_revenue_percentage_survey_year': row[row.survey_year]\n",
    "    }\n",
    "    revenue_list.append(result)\n",
    "revenue = pd.DataFrame(revenue_list)\n",
    "\n",
    "accumulated_data = accumulated_data.merge(revenue, on='country', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_poverty_shares = False # E: if true, it will not work due to 'wb_poverty_rate_most_recent', 'wb_poverty_rate_most_recent_year' not being in accumulated_data\n",
    "if include_poverty_shares:\n",
    "    poverty_rate_data_from_data_portal = pd.read_csv(\n",
    "        '/data/eop/compiled_country_data/world_bank_data_download_20250714/API_SI.POV.DDAY_DS2_en_csv_v2_38376.csv',\n",
    "        skiprows=4\n",
    "    )\n",
    "\n",
    "\n",
    "    poverty_rate_data_from_data_portal.loc[poverty_rate_data_from_data_portal['Country Name'] == 'World', '2019'] = (\n",
    "        poverty_rate_data_from_data_portal.loc[poverty_rate_data_from_data_portal['Country Name'] == 'World', '2018']\n",
    "        + poverty_rate_data_from_data_portal.loc[poverty_rate_data_from_data_portal['Country Name'] == 'World', '2020']\n",
    "    ) / 2\n",
    "\n",
    "\n",
    "\n",
    "    poverty_rate_data_from_data_portal.loc[poverty_rate_data_from_data_portal['Country Name'] == 'World', '2024'] = (\n",
    "        2 * poverty_rate_data_from_data_portal.loc[poverty_rate_data_from_data_portal['Country Name'] == 'World', '2023']\n",
    "        - poverty_rate_data_from_data_portal.loc[poverty_rate_data_from_data_portal['Country Name'] == 'World', '2022']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_poverty_shares:\n",
    "    population_data = pd.read_csv(\n",
    "        'data/eop/compiled_country_data/world_bank_data_download_20250708/API_SP.POP.TOTL_DS2_en_csv_v2_38144.csv',\n",
    "        skiprows=4\n",
    "    )\n",
    "\n",
    "    # Find the intersection of year columns in both dataframes\n",
    "    year_columns = [\n",
    "        col for col in poverty_rate_data_from_data_portal.columns if col in population_data.columns and col.isdigit()\n",
    "    ]\n",
    "\n",
    "    # Calculate world poverty count for each year\n",
    "    world_poverty_count = []\n",
    "    for year in year_columns:\n",
    "        rate = poverty_rate_data_from_data_portal.loc[poverty_rate_data_from_data_portal['Country Name'] == 'World', year].values[0]\n",
    "        pop = population_data.loc[population_data['Country Name'] == 'World', year].values[0]\n",
    "        poverty_count = rate * pop / 100 if pd.notna(rate) and pd.notna(pop) else np.nan\n",
    "        world_poverty_count.append({'year': int(year), 'world_poverty_count': poverty_count})\n",
    "\n",
    "    world_poverty_count_df = pd.DataFrame(world_poverty_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_poverty_shares:\n",
    "    population_raw = pd.read_csv(\n",
    "        'data/eop/compiled_country_data/world_bank_data_download_20250708/API_SP.POP.TOTL_DS2_en_csv_v2_38144.csv',\n",
    "        skiprows=4\n",
    "    )\n",
    "    population_raw = population_raw.rename(columns={'Country Code': 'country_code'})\n",
    "\n",
    "    # first, using pip poverty rates\n",
    "    population_data = (\n",
    "        accumulated_data[['country_code', 'survey_year', 'wb_poverty_rate_most_recent', 'wb_poverty_rate_most_recent_year']]\n",
    "        .merge(population_raw, on='country_code', how='left')\n",
    "    )\n",
    "    population_list = []\n",
    "    for _, row in population_data.iterrows():\n",
    "        result = {\n",
    "            'country_code': row.country_code,\n",
    "            'share_of_worlds_poor_most_recent_year': str(int(row.wb_poverty_rate_most_recent_year)),\n",
    "            'poverty_headcount': (\n",
    "                row.wb_poverty_rate_most_recent * row[str(int(row.wb_poverty_rate_most_recent_year))]\n",
    "            ),\n",
    "        }\n",
    "        population_list.append(result)\n",
    "    share_of_worlds_poor_pip = pd.DataFrame(population_list)\n",
    "\n",
    "    def compute_share_of_world_poor(row):\n",
    "        year = row.share_of_worlds_poor_most_recent_year\n",
    "        world_poverty_headcount = world_poverty_count_df.loc[\n",
    "            world_poverty_count_df.year.astype(str) == year, 'world_poverty_count'\n",
    "        ].values[0]\n",
    "        return row.poverty_headcount / world_poverty_headcount\n",
    "\n",
    "    share_of_worlds_poor_pip['share_of_worlds_poor_most_recent'] = share_of_worlds_poor_pip.apply(compute_share_of_world_poor, axis=1)\n",
    "\n",
    "\n",
    "    # now using dev indicators poverty rates\n",
    "    year_cols = [col for col in poverty_rate_data_from_data_portal.columns if re.match(r'^\\d{4}$', col)]\n",
    "    year_cols.sort()\n",
    "    poverty_rate_data_from_data_portal[year_cols] = poverty_rate_data_from_data_portal[year_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    l = []\n",
    "    for _, row in poverty_rate_data_from_data_portal.iterrows():\n",
    "        result = {\n",
    "            'country_code': row['Country Code'],\n",
    "            'country_dev_indicators': row['Country Name']\n",
    "        }\n",
    "        result['poverty_rate_most_recent_dev_indicators_year'] = None\n",
    "        result['poverty_rate_most_recent_dev_indicators'] = np.nan\n",
    "        for year in year_cols:\n",
    "            if pd.notna(row[year]):\n",
    "                result['poverty_rate_most_recent_dev_indicators_year'] = int(year)\n",
    "                result['poverty_rate_most_recent_dev_indicators'] = row[year] / 100\n",
    "        l.append(result)\n",
    "\n",
    "    poverty_rates_dev_indicators = (\n",
    "        pd.DataFrame(l)\n",
    "    )\n",
    "    population_with_dev_indicators = (\n",
    "        poverty_rates_dev_indicators[[\n",
    "            'country_code', 'country_dev_indicators', 'poverty_rate_most_recent_dev_indicators', 'poverty_rate_most_recent_dev_indicators_year'\n",
    "        ]]\n",
    "        .merge(population_raw, on='country_code', how='inner')\n",
    "    )\n",
    "    population_list = []\n",
    "    for _, row in population_with_dev_indicators.iterrows():\n",
    "        result = {\n",
    "            'country_code': row.country_code,\n",
    "            'country': row.country_dev_indicators,\n",
    "        }\n",
    "        if not np.isnan(row.poverty_rate_most_recent_dev_indicators_year):\n",
    "            result.update({\n",
    "                'share_of_worlds_poor_most_recent_year': str(int(row.poverty_rate_most_recent_dev_indicators_year)),\n",
    "                'poverty_headcount': (\n",
    "                    row.poverty_rate_most_recent_dev_indicators * row[str(int(row.poverty_rate_most_recent_dev_indicators_year))]\n",
    "                )\n",
    "            })\n",
    "        else:\n",
    "            result.update({\n",
    "                'share_of_worlds_poor_most_recent_year': None,\n",
    "                'poverty_headcount': np.nan\n",
    "            })\n",
    "        population_list.append(result)\n",
    "    share_of_worlds_poor_dev_indicators = pd.DataFrame(population_list)\n",
    "\n",
    "    def compute_share_of_world_poor(row):\n",
    "        year = row.share_of_worlds_poor_most_recent_year\n",
    "        if year is None:\n",
    "            return np.nan\n",
    "        world_poverty_headcount = world_poverty_count_df.loc[\n",
    "            world_poverty_count_df.year.astype(str) == year, 'world_poverty_count'\n",
    "        ].values[0]\n",
    "        return row.poverty_headcount / world_poverty_headcount\n",
    "\n",
    "    share_of_worlds_poor_dev_indicators['share_of_worlds_poor_most_recent'] = (\n",
    "        share_of_worlds_poor_dev_indicators.apply(compute_share_of_world_poor, axis=1)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_poverty_shares:\n",
    "    accumulated_data = accumulated_data.merge(\n",
    "        share_of_worlds_poor_pip[['country_code', 'share_of_worlds_poor_most_recent', 'share_of_worlds_poor_most_recent_year']], \n",
    "        on='country_code', how='left'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exchange rates and PPP conversions: start with WB values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_exchange_rates = pd.read_csv(\n",
    "    'data/eop/compiled_country_data/world_bank_data_download_20250715/API_PA.NUS.FCRF_DS2_en_csv_v2_22859.csv',\n",
    "    skiprows=4,\n",
    ")\n",
    "wb_exchange_rates.rename(\n",
    "    columns={\n",
    "        'Country Code': 'country_code', 'Country Name': 'country', '2021': 'market_exchange_rate_2021', \n",
    "        '2017': 'market_exchange_rate_2017'\n",
    "    }, inplace=True\n",
    ")\n",
    "wb_ppp_conversions = pd.read_csv(\n",
    "    'data/eop/compiled_country_data/world_bank_data_download_20250715/API_PA.NUS.PRVT.PP_DS2_en_csv_v2_22915.csv',\n",
    "    skiprows=4,\n",
    ")\n",
    "wb_ppp_conversions.rename(\n",
    "    columns={\n",
    "        'Country Code': 'country_code', 'Country Name': 'country', \n",
    "        '2021': 'PPP_conversion_factor_2021', '2017': 'PPP_conversion_factor_2017'\n",
    "    }, inplace=True\n",
    ")\n",
    "\n",
    "wb_exchange_rates['country']= (\n",
    "    wb_exchange_rates['country']\n",
    "    .str.normalize('NFD')\n",
    "    .str.encode('ascii', errors='ignore')\n",
    "    .str.decode('ascii').str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "    .str.replace(' ', '_')\n",
    "    .str.lower()\n",
    "    .replace({'venezuela_rb': 'venezuela, rb'})\n",
    "    .replace({'yemen_republic_of': 'yemen, rep.'})\n",
    "\n",
    ")\n",
    "\n",
    "wb_ppp_conversions['country']= (\n",
    "    wb_ppp_conversions['country']\n",
    "    .str.normalize('NFD')\n",
    "    .str.encode('ascii', errors='ignore')\n",
    "    .str.decode('ascii').str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "    .str.replace(' ', '_')\n",
    "    .str.lower()\n",
    "    .replace({'venezuela_rb': 'venezuela, rb'})\n",
    "    .replace({'yemen_republic_of': 'yemen, rep.'})\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "accumulated_data = accumulated_data.merge(\n",
    "    wb_exchange_rates[['country_code', 'market_exchange_rate_2017', 'market_exchange_rate_2021']],\n",
    "    on='country_code', how='left'\n",
    ")\n",
    "accumulated_data = accumulated_data.merge(\n",
    "    wb_ppp_conversions[['country_code', 'PPP_conversion_factor_2021', 'PPP_conversion_factor_2017']],\n",
    "    on='country_code', how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now impute with IMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imf_exchange_rates = pd.read_csv( \n",
    "    (\n",
    "        'data/eop/compiled_country_data/imf_data_download_20250903/'\n",
    "        'imf_exchange_rates_dataset_2025-09-03T16_58_04.844661537Z_DEFAULT_INTEGRATION_IMF.STA_ER_4.0.1.csv'\n",
    "    )\n",
    ")\n",
    "\n",
    "imf_exchange_rates.rename(columns={'COUNTRY': 'country'}, inplace=True)\n",
    "\n",
    "imf_exchange_rates = imf_exchange_rates[\n",
    "    (imf_exchange_rates.INDICATOR == 'US Dollar per domestic currency')\n",
    "    & (imf_exchange_rates.TYPE_OF_TRANSFORMATION == 'Period average')\n",
    "    & (imf_exchange_rates.FREQUENCY == 'Annual')\n",
    "]\n",
    "\n",
    "imf_exchange_rates['country'] = (\n",
    "    imf_exchange_rates['country']\n",
    "    .str.normalize('NFD')\n",
    "    .str.encode('ascii', errors='ignore')\n",
    "    .str.decode('ascii').str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "    .str.replace(' ', '_')\n",
    "    .str.lower()\n",
    "    .replace({'taiwan_province_of_china': 'taiwan, china'})\n",
    "    .replace({'venezuela_republica_bolivariana_de': 'venezuela, rb'})\n",
    ")\n",
    "imf_exchange_rates.country = imf_exchange_rates.country.apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_imf_exchange_rates = accumulated_data.merge(imf_exchange_rates, how='left', on='country') \n",
    "\n",
    "imputing_2017_exchange_rate = []\n",
    "imputing_2021_exchange_rate = []\n",
    "for _, row in with_imf_exchange_rates.iterrows():\n",
    "    if pd.isna(row.market_exchange_rate_2017):\n",
    "        if pd.notna(row['2017']):\n",
    "            imputing_2017_exchange_rate.append(row.country)\n",
    "            accumulated_data.loc[\n",
    "                accumulated_data.country_code == row.country_code, 'market_exchange_rate_2017'\n",
    "            ] = row['2017']\n",
    "\n",
    "    if pd.isna(row.market_exchange_rate_2021):\n",
    "        if pd.notna(row['2021']):\n",
    "            imputing_2021_exchange_rate.append(row.country)\n",
    "            accumulated_data.loc[\n",
    "                accumulated_data.country_code == row.country_code, 'market_exchange_rate_2021'\n",
    "            ] = row['2021'] # market exchange rate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imf_ppp_rates = pd.read_csv( \n",
    "    (\n",
    "        'data/eop/compiled_country_data/imf_data_download_20250903/'\n",
    "        'imf_ppp_dataset_2025-09-03T18_24_12.655968722Z_DEFAULT_INTEGRATION_IMF.RES_WEO_6.0.0.csv'\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "imf_ppp_rates = imf_ppp_rates[\n",
    "    (imf_ppp_rates.FREQUENCY == 'Annual')\n",
    "]\n",
    "\n",
    "imf_ppp_rates.rename(columns={'COUNTRY': 'country'}, inplace=True)\n",
    "\n",
    "\n",
    "imf_ppp_rates['country']= (\n",
    "    imf_ppp_rates['country']\n",
    "    .str.normalize('NFD')\n",
    "    .str.encode('ascii', errors='ignore')\n",
    "    .str.decode('ascii').str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "    .str.replace(' ', '_')\n",
    "    .str.lower()\n",
    "    .replace({'taiwan_province_of_china': 'taiwan, china'})\n",
    "    .replace({'venezuela_republica_bolivariana_de': 'venezuela, rb'})\n",
    "    .replace({'yemen_republic_of': 'yemen, rep.'})\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "with_imf_ppp = accumulated_data.merge(imf_ppp_rates, how='left', on='country')\n",
    "\n",
    "imputing_2017_ppp = []\n",
    "imputing_2021_ppp = []\n",
    "for _, row in with_imf_ppp.iterrows():\n",
    "    if pd.isna(row.PPP_conversion_factor_2017):\n",
    "        if pd.notna(row['2017']):\n",
    "            imputing_2017_ppp.append(row.country)\n",
    "            accumulated_data.loc[\n",
    "                accumulated_data.country_code == row.country_code, \n",
    "                'PPP_conversion_factor_2017'\n",
    "            ] = row['2017']\n",
    "\n",
    "    if pd.isna(row.PPP_conversion_factor_2021):\n",
    "        if pd.notna(row['2021']):\n",
    "            imputing_2021_ppp.append(row.country)\n",
    "            accumulated_data.loc[\n",
    "                accumulated_data.country_code == row.country_code, \n",
    "                'PPP_conversion_factor_2021'\n",
    "            ] = row['2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('imputing 2017 exchange rate', imputing_2017_exchange_rate)\n",
    "print('imputing 2021 exchange rate', imputing_2021_exchange_rate)\n",
    "print('imputing 2017 ppp', imputing_2017_ppp)\n",
    "print('imputing 2021 ppp', imputing_2021_ppp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrapolate for still-missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any_missing_data = accumulated_data[\n",
    "    (accumulated_data.PPP_conversion_factor_2017.isna())\n",
    "    | (accumulated_data.PPP_conversion_factor_2021.isna())\n",
    "    | (accumulated_data.market_exchange_rate_2017.isna())\n",
    "    | (accumulated_data.market_exchange_rate_2021.isna())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change back for merging + extrapolation\n",
    "wb_exchange_rates.rename(\n",
    "    columns={\n",
    "        'market_exchange_rate_2021': '2021',\n",
    "        'market_exchange_rate_2017': '2017'\n",
    "    }, inplace=True\n",
    ")\n",
    "wb_ppp_conversions.rename(\n",
    "    columns={\n",
    "        'PPP_conversion_factor_2021': '2021',\n",
    "        'PPP_conversion_factor_2017': '2017'\n",
    "    }, inplace=True\n",
    ")\n",
    "\n",
    "wb_exchange_rates = wb_exchange_rates[wb_exchange_rates.country_code.isin(any_missing_data.country_code)]\n",
    "wb_ppp_conversions = wb_ppp_conversions[wb_ppp_conversions.country_code.isin(any_missing_data.country_code)]\n",
    "\n",
    "imf_exchange_rates = imf_exchange_rates[imf_exchange_rates.country.isin(any_missing_data.country)]\n",
    "imf_ppp_rates = imf_ppp_rates[imf_ppp_rates.country.isin(any_missing_data.country)]\n",
    "\n",
    "exchange_rates_merged = pd.merge(\n",
    "    wb_exchange_rates, imf_exchange_rates, suffixes=('', '_imf'), on='country', how='outer'\n",
    ")\n",
    "ppp_conversions_merged = pd.merge(\n",
    "    wb_ppp_conversions, imf_ppp_rates, suffixes=('', '_imf'), on='country', how='outer'\n",
    ")\n",
    "\n",
    "# Add missing PPP (just venezuela)\n",
    "numeric_cols = [col for col in ppp_conversions_merged.columns if col.isdigit()]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if f'{col}_imf' in ppp_conversions_merged.columns:\n",
    "        ppp_conversions_merged.loc[ppp_conversions_merged.country_code == 'VEN', col] = ppp_conversions_merged[f'{col}_imf']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_rates_merged = exchange_rates_merged[\n",
    "    ['country', 'country_code'] + sorted([c for c in exchange_rates_merged.columns if c.isdigit()])\n",
    "]\n",
    "ppp_conversions_merged = ppp_conversions_merged[\n",
    "    ['country', 'country_code'] + sorted([c for c in ppp_conversions_merged.columns if c.isdigit()])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guinea: Impute 2021 market exchange rate using 2020 ratio and 2021 PPP\n",
    "accumulated_data.loc[\n",
    "    accumulated_data.country == 'guinea', 'market_exchange_rate_2021'\n",
    "] = (\n",
    "    (\n",
    "        exchange_rates_merged.loc[exchange_rates_merged.country == 'guinea', '2020']\n",
    "        / ppp_conversions_merged.loc[ppp_conversions_merged.country == 'guinea', '2020']\n",
    "    ) * ppp_conversions_merged.loc[ppp_conversions_merged.country == 'guinea', '2021']\n",
    ").values[0]\n",
    "\n",
    "# Myanmar: Impute 2021 market exchange rate using 2020 ratio and 2021 PPP\n",
    "accumulated_data.loc[\n",
    "    accumulated_data.country == 'myanmar', 'market_exchange_rate_2021'\n",
    "] = (\n",
    "        (\n",
    "        exchange_rates_merged.loc[exchange_rates_merged.country == 'myanmar', '2020']\n",
    "        / ppp_conversions_merged.loc[ppp_conversions_merged.country == 'myanmar', '2020']\n",
    "    ) * ppp_conversions_merged.loc[ppp_conversions_merged.country == 'myanmar', '2021']\n",
    ").values[0]\n",
    "\n",
    "# West bank and gaza: use Israel market exchange rate numbers\n",
    "accumulated_data.loc[\n",
    "    accumulated_data.country_code == 'PSE', 'market_exchange_rate_2017'\n",
    "] = accumulated_data.loc[\n",
    "    accumulated_data.country_code == 'ISR', 'market_exchange_rate_2017'\n",
    "].values[0]\n",
    "accumulated_data.loc[\n",
    "    accumulated_data.country_code == 'PSE', 'market_exchange_rate_2021'\n",
    "] = accumulated_data.loc[\n",
    "    accumulated_data.country_code == 'ISR', 'market_exchange_rate_2021'\n",
    "].values[0]\n",
    "\n",
    "# Turkmenistan: Can't usefully extrapolate. Omitting.\n",
    "\n",
    "# Venezuela\n",
    "# PPP 2017: Extrapolate using ratio from 2011\n",
    "accumulated_data.loc[\n",
    "    accumulated_data.country_code == 'VEN', 'PPP_conversion_factor_2017'\n",
    "] = (\n",
    "        (\n",
    "        ppp_conversions_merged.loc[ppp_conversions_merged.country_code == 'VEN', '2011']\n",
    "        / exchange_rates_merged.loc[exchange_rates_merged.country_code == 'VEN', '2011']\n",
    "    ) * exchange_rates_merged.loc[exchange_rates_merged.country_code == 'VEN', '2017']\n",
    ").values[0]\n",
    "\n",
    "\n",
    "# Exchange rate: Extrapolate using ratio from 2011\n",
    "accumulated_data.loc[\n",
    "    accumulated_data.country_code == 'VEN', 'market_exchange_rate_2021'\n",
    "] = (\n",
    "        (\n",
    "        exchange_rates_merged.loc[exchange_rates_merged.country_code == 'VEN', '2011']\n",
    "        / ppp_conversions_merged.loc[ppp_conversions_merged.country_code == 'VEN', '2011']\n",
    "    ) * ppp_conversions_merged.loc[ppp_conversions_merged.country_code == 'VEN', '2021']\n",
    ").values[0]\n",
    "\n",
    "# Zimbabwe: impute 2017 market exchange rate using 2020 ratio and 2017 PPP\n",
    "accumulated_data.loc[\n",
    "    accumulated_data.country == 'zimbabwe', 'market_exchange_rate_2017'\n",
    "] = (\n",
    "        (\n",
    "        exchange_rates_merged.loc[exchange_rates_merged.country == 'zimbabwe', '2020']\n",
    "        / ppp_conversions_merged.loc[ppp_conversions_merged.country == 'zimbabwe', '2020']\n",
    "    ) * ppp_conversions_merged.loc[ppp_conversions_merged.country == 'zimbabwe', '2017']\n",
    ").values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print diagnostics\n",
    "if False:\n",
    "    display(\n",
    "            accumulated_data[accumulated_data.country.str.contains('turkmen')][[\n",
    "            'market_exchange_rate_2017', 'market_exchange_rate_2021', 'PPP_conversion_factor_2017', \n",
    "            'PPP_conversion_factor_2021'\n",
    "        ]]\n",
    "    )\n",
    "\n",
    "if False:\n",
    "    wb_exchange_rates = pd.read_csv(\n",
    "        '/data/eop/compiled_country_data/world_bank_data_download_20250715/API_PA.NUS.FCRF_DS2_en_csv_v2_22859.csv',\n",
    "        skiprows=4,\n",
    "    )\n",
    "    wb_exchange_rates.rename(\n",
    "        columns={\n",
    "            'Country Code': 'country_code', 'Country Name': 'country',\n",
    "        }, inplace=True\n",
    "    )\n",
    "    wb_ppp_conversions = pd.read_csv(\n",
    "        '/data/eop/compiled_country_data/world_bank_data_download_20250715/API_PA.NUS.PRVT.PP_DS2_en_csv_v2_22915.csv',\n",
    "        skiprows=4,\n",
    "    )\n",
    "    wb_ppp_conversions.rename(\n",
    "        columns={\n",
    "            'Country Code': 'country_code', 'Country Name': 'country', \n",
    "        }, inplace=True\n",
    "    )\n",
    "    with pd.option_context('display.max_columns', 100):\n",
    "        print('market exchange rate')\n",
    "        display(exchange_rates_merged[exchange_rates_merged.country.str.contains('west')])\n",
    "        display(wb_exchange_rates[wb_exchange_rates.country.str.contains('rael')])\n",
    "\n",
    "\n",
    "\n",
    "        print('ppp')\n",
    "        display(ppp_conversions_merged[ppp_conversions_merged.country.str.contains('west')])\n",
    "        display(wb_ppp_conversions[wb_ppp_conversions.country.str.contains('rael')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi = pd.read_csv(\n",
    "    'data/eop/compiled_country_data/world_bank_data_download_20251117/API_FP.CPI.TOTL_DS2_en_csv_v2_216045.csv',\n",
    "    skiprows=4,\n",
    ").rename(columns={'Country Code': 'country_code'})\n",
    "temp_merged = accumulated_data.merge(cpi, on='country_code', how='left')\n",
    "\n",
    "def get_cpi_value(row, year):\n",
    "    year = float(year)\n",
    "    if year == int(year):\n",
    "        if str(int(year)) in row:\n",
    "            return row[str(int(year))]\n",
    "        else:\n",
    "            print(f'CPI {int(year)} not available for {row.country}')\n",
    "            if int(year) == 2024:\n",
    "                print('Using 2023 instead; confirm overwrite by curated data')\n",
    "                return row['2023']\n",
    "    print(f'fractional base year {row.country}')\n",
    "    lower_year = int(year)\n",
    "    upper_year = lower_year + 1\n",
    "    print(lower_year, upper_year)\n",
    "    weight = year - lower_year \n",
    "\n",
    "    lower_value = row[str(upper_year)]\n",
    "    upper_value = row[str(lower_year)]\n",
    "    overall = lower_value * (1 - weight) + upper_value * weight\n",
    "    print(\n",
    "        f'upper: {lower_value}, lower: {upper_value}, '\n",
    "        f'overall: {overall}'\n",
    "    )\n",
    "    return overall\n",
    "\n",
    "def assemble(row):\n",
    "    base_year = row['currency_base_year']\n",
    "    base_cpi = get_cpi_value(row, base_year)\n",
    "    local_currency_conversion_2017 = row['2017'] / base_cpi\n",
    "    local_currency_conversion_2021 = row['2021'] / base_cpi\n",
    "    ppp_conversion_2017 = row['PPP_conversion_factor_2017']\n",
    "    ppp_conversion_2021 = row['PPP_conversion_factor_2021']\n",
    "    overall_conversion_2017 = local_currency_conversion_2017 / ppp_conversion_2017\n",
    "    overall_conversion_2021 = local_currency_conversion_2021 / ppp_conversion_2021\n",
    "\n",
    "    return pd.Series({\n",
    "        'country_code': row['country_code'],\n",
    "        '2017_cpi': row['2017'],\n",
    "        '2021_cpi': row['2021'],\n",
    "        'overall_currency_conversion_to_2017_ppp': overall_conversion_2017,\n",
    "        'overall_currency_conversion_to_2021_ppp': overall_conversion_2021,\n",
    "        'overall_conversion_factor_ratio_from_2021_to_2017': overall_conversion_2017 / overall_conversion_2021\n",
    "    })\n",
    "assembled = temp_merged[temp_merged.survey_year.notna()].apply(assemble, axis=1)\n",
    "accumulated_data = accumulated_data.merge(\n",
    "    assembled[['country_code', 'overall_conversion_factor_ratio_from_2021_to_2017', 'overall_currency_conversion_to_2017_ppp', 'overall_currency_conversion_to_2021_ppp']],\n",
    "    on='country_code', how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Override with manually curated data\n",
    "\n",
    "We override survey currency conversion factors, not by-year PPP or CPI or exchange rates, since these conversions are survey-specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_factor_overrides = pd.read_csv('data/eop/compiled_country_data/cpi_ppp_exec_portal_accessed_20251019.csv')\n",
    "additional_conversion_factor_overrides = pd.read_csv('data/eop/compiled_country_data/cpi_ppp_exec_portal_ad_hoc.csv')\n",
    "conversion_factor_overrides = pd.concat([conversion_factor_overrides, additional_conversion_factor_overrides], ignore_index=True)\n",
    "matching = accumulated_data.merge(conversion_factor_overrides, left_on='country_code', right_on='code', how='inner')\n",
    "matching = matching[matching.pip_using == 'True']\n",
    "matching = matching[matching.survey_year.astype(float) ==  matching.year]\n",
    "# Ensure duplicate country_code rows have matching CPI/ICP values, then drop duplicates\n",
    "dup_mask = matching.duplicated(subset='country_code', keep=False)\n",
    "dup_codes = matching.loc[dup_mask, 'country_code'].unique().tolist()\n",
    "\n",
    "for cc in dup_codes:\n",
    "    rows = matching[matching['country_code'] == cc]\n",
    "    for col in ['cpi2017', 'cpi2021', 'icp2017', 'icp2021']:\n",
    "        if col not in matching.columns:\n",
    "            continue\n",
    "        vals = rows[col].dropna().unique()\n",
    "        if len(vals) > 1:\n",
    "            raise AssertionError(f\"Mismatch for {col} in country_code {cc}: {vals}\")\n",
    "\n",
    "matching = matching.drop_duplicates(subset='country_code', keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, country_row in matching.iterrows():\n",
    "    accumulated_data.loc[\n",
    "        accumulated_data.country_code == country_row.country_code, 'overall_currency_conversion_to_2017_ppp'\n",
    "    ] = 1/(country_row['cpi2017'] * country_row['icp2017'])\n",
    "    accumulated_data.loc[\n",
    "        accumulated_data.country_code == country_row.country_code, 'overall_currency_conversion_to_2021_ppp'\n",
    "    ] = 1/(country_row['cpi2021'] * country_row['icp2021'])\n",
    "    accumulated_data.loc[\n",
    "        accumulated_data.country_code == country_row.country_code, 'overall_conversion_factor_ratio_from_2021_to_2017'\n",
    "    ] = (\n",
    "        accumulated_data['overall_currency_conversion_to_2017_ppp'] \n",
    "        / accumulated_data['overall_currency_conversion_to_2021_ppp']\n",
    "    )\n",
    "accumulated_data.drop(columns=['pip_using'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elizabeth Foster's overrides for the eight WAMU countries\n",
    "ehcvm_overrides = pd.read_csv('data/eop/compiled_country_data/cpi_icp_from_elizabeth_202510.csv')\n",
    "for _, row in accumulated_data.iterrows():\n",
    "    if row.country_code in ehcvm_overrides.code.values:\n",
    "        country_row = ehcvm_overrides[\n",
    "            (ehcvm_overrides.code == row.country_code)\n",
    "            & (ehcvm_overrides.year == 2018)\n",
    "        ]\n",
    "        assert len(country_row) == 1\n",
    "\n",
    "\n",
    "        accumulated_data.loc[\n",
    "            accumulated_data.country_code == row.country_code, 'overall_currency_conversion_to_2017_ppp'\n",
    "        ] = 1/(country_row['cpi2017'].values[0] * country_row['icp2017'].values[0])\n",
    "        accumulated_data.loc[\n",
    "            accumulated_data.country_code == row.country_code, 'overall_currency_conversion_to_2021_ppp'\n",
    "        ] = 1/(country_row['cpi2021'].values[0] * country_row['icp2021'].values[0])\n",
    "        accumulated_data.loc[\n",
    "            accumulated_data.country_code == row.country_code, 'overall_conversion_factor_ratio_from_2021_to_2017'\n",
    "        ] = (\n",
    "            accumulated_data['overall_currency_conversion_to_2017_ppp'] \n",
    "            / accumulated_data['overall_currency_conversion_to_2021_ppp']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data_path = Path('data/eop/country_data')\n",
    "\n",
    "survey_metrics = []\n",
    "\n",
    "name_map = {\n",
    "    'burkina_faso': 'burkina faso',\n",
    "    'cote_divoire': \"coÌ‚te d'ivoire\",\n",
    "    'south_africa': 'south africa',\n",
    "    'south_sudan': 'south sudan'\n",
    "}\n",
    "for dir in survey_data_path.iterdir():\n",
    "    country_code = dir.name\n",
    "    try:\n",
    "        if (dir / 'cleaned').exists():\n",
    "            cleaned_dir = dir / 'cleaned'\n",
    "        elif (dir / 'clean').exists():\n",
    "            print(f'found \"clean\" instead of \"cleaned\": {country_code}')\n",
    "            cleaned_dir = dir / 'clean'\n",
    "        else:\n",
    "            print(f'No cleaned data directory found for {country_code}')\n",
    "\n",
    "        # Assert that train.parquet and test.parquet are newer than any other parquet file under country_data_path\n",
    "        all_parquet_files = list(cleaned_dir.glob('*.parquet'))\n",
    "        train_path = cleaned_dir / 'train.parquet'\n",
    "        test_path = cleaned_dir / 'test.parquet'\n",
    "        for f in all_parquet_files:\n",
    "            if f not in [train_path, test_path]:\n",
    "                assert train_path.stat().st_mtime > f.stat().st_mtime, f\"{train_path.name} is not newer than {f.name}\"\n",
    "                assert test_path.stat().st_mtime > f.stat().st_mtime, f\"{test_path.name} is not newer than {f.name}\"\n",
    "        train = pd.read_parquet(cleaned_dir / 'train.parquet')\n",
    "        test = pd.read_parquet(cleaned_dir / 'test.parquet')\n",
    "\n",
    "        data = pd.concat((train, test), ignore_index=True)\n",
    "\n",
    "        conversion_factor = accumulated_data.loc[\n",
    "            accumulated_data.country_code == country_code, 'overall_conversion_factor_ratio_from_2021_to_2017'\n",
    "        ].values[0]\n",
    "        data['consumption_per_capita_per_day_povertyline_2017'] = (\n",
    "            data.consumption_per_capita_per_day * conversion_factor\n",
    "        )\n",
    "\n",
    "        data['consumption_per_capita_per_day_povertyline_2021'] = data.consumption_per_capita_per_day\n",
    "\n",
    "        count_poor_povertyline_2017 = (\n",
    "            data[data.consumption_per_capita_per_day_povertyline_2017 < 2.15].headcount_adjusted_hh_wgt\n",
    "        ).sum()\n",
    "        count_poor_povertyline_2021 = (\n",
    "            data[data.consumption_per_capita_per_day_povertyline_2021 < 3.0].headcount_adjusted_hh_wgt\n",
    "        ).sum()\n",
    "\n",
    "        total = (\n",
    "            data.headcount_adjusted_hh_wgt\n",
    "        ).sum()\n",
    "\n",
    "        rate_povertyline_2017 = count_poor_povertyline_2017 / total\n",
    "        rate_povertyline_2021 = count_poor_povertyline_2021 / total\n",
    "\n",
    "        poverty_gap_index_povertyline_2017 = (\n",
    "            (\n",
    "                (2.15 - data['consumption_per_capita_per_day_povertyline_2017'])\n",
    "                .clip(lower=0) * data['headcount_adjusted_hh_wgt']\n",
    "            )\n",
    "        ).sum() / (total * 2.15)\n",
    "\n",
    "        poverty_gap_index_povertyline_2021 = (\n",
    "            (\n",
    "                (3.0 - data['consumption_per_capita_per_day_povertyline_2021'])\n",
    "                .clip(lower=0) * data['headcount_adjusted_hh_wgt']\n",
    "            )\n",
    "        ).sum() / (total * 3.0)\n",
    "\n",
    "        survey_metrics.append(\n",
    "            {\n",
    "                'country_code': country_code, \n",
    "                'survey_poverty_rate_povertyline_2017': rate_povertyline_2017, \n",
    "                'survey_poverty_rate_povertyline_2021': rate_povertyline_2021,\n",
    "                'survey_poverty_gap_index_povertyline_2017': poverty_gap_index_povertyline_2017,\n",
    "                'survey_poverty_gap_index_povertyline_2021': poverty_gap_index_povertyline_2021,\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'Error encountered with {dir.name}; skipping')\n",
    "        print(e)\n",
    "\n",
    "survey_metrics_df = pd.DataFrame(survey_metrics)\n",
    "\n",
    "\n",
    "survey_metrics_df = accumulated_data.loc[\n",
    "    accumulated_data.survey_year.notna(), ['country_code']\n",
    "].merge(survey_metrics_df, on='country_code', how='left')\n",
    "\n",
    "accumulated_data = accumulated_data.merge(survey_metrics_df, on='country_code', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_str = datetime.today().strftime('%Y%m%d')\n",
    "accumulated_data.to_csv(\n",
    "    f'data/eop/compiled_country_data/auxiliary_data/auxiliary_data_{today_str}.csv', index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E: Comparing two most recent auxiliary data files\n",
    "auxiliary_data_20251124 = pd.read_csv(\n",
    "    'data/eop/compiled_country_data/auxiliary_data/auxiliary_data_20251124.csv'\n",
    ")\n",
    "auxiliary_data_20251201 = pd.read_csv(\n",
    "    'data/eop/compiled_country_data/auxiliary_data/auxiliary_data_20251201.csv'\n",
    ")   \n",
    "\n",
    "# compare auxiliary_data_20251124 and auxiliary_data_20251201 for differences\n",
    "print(auxiliary_data_20251124.compare(auxiliary_data_20251201))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Currency conversion table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_files = glob('data/eop/compiled_country_data/auxiliary_data/auxiliary_data_*.csv')\n",
    "latest_file = max(aux_files, key=lambda x: x.split('_')[-1].split('.')[0])\n",
    "aux_data = pd.read_csv(latest_file)\n",
    "print(f'Latest file: {latest_file}')\n",
    "\n",
    "previous_conversion_factors_table = pd.read_csv('data/eop/compiled_country_data/currency_conversion.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_conversion_factors_table = aux_data.loc[aux_data.survey_year.notna(), ['country', 'country_code', 'overall_currency_conversion_to_2021_ppp']]\n",
    "\n",
    "new_conversion_factors_table.rename(columns={'overall_currency_conversion_to_2021_ppp': 'Conversion Factor'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: # Report changes\n",
    "    merged = new_conversion_factors_table.merge(\n",
    "        previous_conversion_factors_table[['country_code', 'Conversion Factor']], \n",
    "        how='outer',\n",
    "        suffixes=('_new', '_old'),\n",
    "        on='country_code'\n",
    "    )\n",
    "\n",
    "    mismatched = merged[\n",
    "        ~np.isclose(merged['Conversion Factor_new'], merged['Conversion Factor_old'], equal_nan=True)\n",
    "    ]\n",
    "    display(mismatched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_conversion_factors_table.to_csv('/data/eop/compiled_country_data/currency_conversion.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secondary aux data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_accumulated_data = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_raw = pd.read_csv(\n",
    "    'data/eop/compiled_country_data/world_bank_data_download_20250628/API_NY.GDP.MKTP.KD_DS2_en_csv_v2_127117.csv',\n",
    "    skiprows=4,\n",
    ")\n",
    "gdp_raw = gdp_raw.rename(columns={'Country Code': 'country_code'})\n",
    "\n",
    "cpi = pd.read_csv(\n",
    "    'data/eop/compiled_country_data/world_bank_data_download_20251117/API_FP.CPI.TOTL_DS2_en_csv_v2_216045.csv',\n",
    "    skiprows=4,\n",
    ")\n",
    "us_cpi_2015 = cpi.loc[cpi['Country Code'] == 'USA', '2015'].values[0]\n",
    "us_cpi_2023 = cpi.loc[cpi['Country Code'] == 'USA', '2023'].values[0]\n",
    "aux_accumulated_data['china_GDP_2023'] = (\n",
    "    gdp_raw.loc[gdp_raw['country_code'] == 'CHN', '2023'].values[0] * (us_cpi_2023 / us_cpi_2015) / 1e9\n",
    ")\n",
    "aux_accumulated_data['OECD_GDP_2023'] = (\n",
    "    gdp_raw.loc[gdp_raw['country_code'] == 'OED', '2023'].values[0] * (us_cpi_2023 / us_cpi_2015) / 1e9\n",
    ")\n",
    "aux_accumulated_data['global_GDP_2023'] = (\n",
    "    gdp_raw.loc[gdp_raw['country_code'] == 'WLD', '2023'].values[0] * (us_cpi_2023 / us_cpi_2015) / 1e9\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_data_raw = pd.read_csv(\n",
    "    'data/eop/compiled_country_data/imf_data_download_20250714/imf-dm-export-20250714.csv'\n",
    ")\n",
    "revenue_data_raw.rename(columns={'Revenue (% of GDP)': 'country'}, inplace=True)\n",
    "revenue_data_raw.dropna(subset='country', inplace=True)\n",
    "\n",
    "aux_accumulated_data['china_govt_revenue_percentage_2023'] = (\n",
    "    revenue_data_raw.loc[revenue_data_raw.country == \"China, People's Republic of\", '2023'].values[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to use WB (excluding grants) for OECD\n",
    "wb_revenue_data = pd.read_csv(\n",
    "    'data/eop/compiled_country_data/world_bank_data_download_20250904/API_GC.REV.XGRT.GD.ZS_DS2_en_csv_v2_557920.csv',\n",
    "    skiprows=4\n",
    ")\n",
    "aux_accumulated_data['OECD_govt_revenue_percentage_2023'] = (\n",
    "    wb_revenue_data.loc[wb_revenue_data['Country Code'] == 'OED', '2023'].values[0]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cpi_usa = cpi.loc[cpi['Country Code'] == 'USA']\n",
    "earliest_survey_year = accumulated_data.survey_year.astype('Int64').min()\n",
    "years = range(earliest_survey_year, 2025)\n",
    "cpi_usa = cpi_usa[[str(y) for y in years]].melt(var_name='year', value_name='cpi_usa')\n",
    "cpi_usa.cpi_usa = cpi_usa.cpi_usa / cpi_usa.loc[cpi_usa.year == '2023', 'cpi_usa'].values[0]\n",
    "\n",
    "cpi_usa.rename(columns={'year': 'indicator', 'cpi_usa': 'value'}, inplace=True)\n",
    "cpi_usa.indicator = cpi_usa.indicator.apply(lambda y: f'conversion_factor_nominal_USD_{y}_to_2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_dataframe = (\n",
    "    pd.DataFrame.from_dict(aux_accumulated_data, columns=['value'], orient='index')\n",
    "    .reset_index(names='indicator')\n",
    ")\n",
    "aux_dataframe = pd.concat((aux_dataframe, cpi_usa), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_str = datetime.today().strftime('%Y%m%d')\n",
    "aux_dataframe.to_csv(f'data/eop/compiled_country_data/auxiliary_data/secondary_auxiliary_data_{today_str}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human-readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_files = glob('data/eop/compiled_country_data/auxiliary_data/auxiliary_data_*.csv')\n",
    "latest_file = max(aux_files, key=lambda x: x.split('_')[-1].split('.')[0])\n",
    "aux_data = pd.read_csv(latest_file)\n",
    "print(f'Latest file: {latest_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WB country classification allows us to get the full list of countries and codes\n",
    "country_income_classifications = pd.read_csv(\n",
    "    '/data/eop/compiled_country_data/world_bank_helpdesk_download_20250628/world_bank_income_classification_20250628.csv'\n",
    ")\n",
    "\n",
    "# There's a split after the countries+territories and before the aggregates; use this to drop the aggregates\n",
    "all_nan_mask = country_income_classifications.isnull().all(axis=1)\n",
    "split_index = country_income_classifications[all_nan_mask].index.values[0]\n",
    "\n",
    "all_countries_and_territories = country_income_classifications.loc[:split_index-1, ['Economy', 'Code']].rename(\n",
    "    columns={'Economy': 'country', 'Code': 'country_code'}\n",
    ")\n",
    "\n",
    "# Manually constructed\n",
    "not_countries = [\n",
    "    'ASM', 'ABW', 'BMU', 'VGB', 'CYM', 'PYF', 'GIB', 'GRL', \n",
    "    'GUM', 'HKG', 'MAC', 'MAF', 'NCL', 'MNP', 'PRI','SXM', 'VIR'\n",
    "]\n",
    "\n",
    "all_countries = all_countries_and_territories[\n",
    "     ~all_countries_and_territories.country_code.isin(not_countries)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpc = pd.read_csv(\n",
    "    '/data/eop/country_inventory/wpc_extended.csv',\n",
    "    usecols = [\n",
    "        'Country (color codes: inputs, intermediates, final outputs, error checks)',\n",
    "        \"Share of country's population that is in extreme poverty (WPC)\",\n",
    "    ]\n",
    ")\n",
    "wpc.columns = ['country',  'poverty_rate_wpc']\n",
    "wpc['poverty_rate_wpc'] = wpc['poverty_rate_wpc'].str.rstrip('%').astype(float) / 100\n",
    "\n",
    "wpc.dropna(subset='country', inplace=True)\n",
    "# Typos \n",
    "wpc.loc[wpc.country.str.contains('Niger '), ['country']] = 'Niger'\n",
    "wpc.loc[wpc.country.str.contains('Combodia'), ['country']] = 'Cambodia'\n",
    "\n",
    "\n",
    "# Lining up names\n",
    "for current, wb in [\n",
    "    ('East Eimor', 'Timor-Leste'),\n",
    "    ('Ivory Coast', 'CÃ´te dâ€™Ivoire'),\n",
    "    ('Bosnia', 'Bosnia and Herzegovina'),\n",
    "    ('Sao Tome and Principe', 'SÃ£o TomÃ© and PrÃ­ncipe'),\n",
    "    ('Taiwan', 'Taiwan, China'),\n",
    "    ('Turkiye', 'TÃ¼rkiye'),\n",
    "    ('Viet Nam', 'Vietnam'),\n",
    "    ('Palestine', 'West Bank and Gaza')\n",
    "]:\n",
    "    wpc.loc[wpc.country.str.contains(current), ['country']] = wb\n",
    "\n",
    "wpc.loc[wpc.country.str.contains('East Timor'), ['country']] = 'Timor-Leste'\n",
    "wpc.loc[wpc.country.str.contains('Ivory Coast'), ['country']] = 'CÃ´te dâ€™Ivoire'\n",
    "wpc.loc[wpc.country.str.contains('Bosnia'), ['country']] = 'Bosnia and Herzegovina'\n",
    "wpc.drop(wpc[wpc.country == 'Puerto Rico'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_world_in_data = pd.read_csv(\n",
    "    '/data/eop/compiled_country_data/our_world_in_data_20250918/pip_dataset.csv'\n",
    ")\n",
    "our_world_in_data = our_world_in_data[\n",
    "    (our_world_in_data.ppp_version == 2017)\n",
    "    & (our_world_in_data.reporting_level == 'national')\n",
    "]\n",
    "our_world_in_data.country.replace(\n",
    "    {\n",
    "        'Cape Verde': 'Cabo Verde', 'Democratic Republic of Congo': 'Congo, Dem. Rep.', \n",
    "        \"Cote d'Ivoire\": \"CÃ´te dâ€™Ivoire\", 'Congo': 'Congo, Rep.', 'Egypt': 'Egypt, Arab Rep.',\n",
    "        'Gambia': 'Gambia, The', 'Iran': 'Iran, Islamic Rep.', 'South Korea': 'Korea, Rep.',\n",
    "        'Kyrgyzstan': 'Kyrgyz Republic','Laos': 'Lao PDR', 'Micronesia (country)': 'Micronesia, Fed. Sts.',\n",
    "        'Palestine': 'West Bank and Gaza', 'Russia': 'Russian Federation', 'Slovakia': 'Slovak Republic',\n",
    "        'Saint Lucia': 'St. Lucia', 'Syria': 'Syrian Arab Republic', 'Sao Tome and Principe': 'SÃ£o TomÃ© and PrÃ­ncipe',\n",
    "        'Taiwan': 'Taiwan, China', 'Timor': 'Timor-Leste', 'Turkey': 'TÃ¼rkiye','Venezuela': 'Venezuela, RB',\n",
    "        'Yemen': 'Yemen, Rep.'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "def get_latest_value_with_year(df, value_col):\n",
    "    def latest_func(group):\n",
    "        if group[value_col].notna().any():\n",
    "            idx = group['reporting_year'].idxmax()\n",
    "            return pd.Series({\n",
    "                f'latest_{value_col}': group.loc[idx, value_col],\n",
    "                'year': group.loc[idx, 'reporting_year']\n",
    "            })\n",
    "        else:\n",
    "            return pd.Series({\n",
    "                f'latest_{value_col}': np.nan,\n",
    "                'year': np.nan\n",
    "            })\n",
    "    return df.groupby('country_code').apply(latest_func).reset_index()\n",
    "\n",
    "our_world_in_data_with_codes = our_world_in_data.merge(all_countries[['country', 'country_code']], on='country', how='left')\n",
    "our_world_in_data_with_codes.rename(columns={\n",
    "        'year': 'reporting_year', 'headcount_ratio_international_povline': 'headcount', \n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "our_world_in_data_with_codes.headcount /= 100\n",
    "\n",
    "# avg_shortfall_international_povline is the average gap among people below the poverty line; we need to adjust\n",
    "# it to be the average among the whole population.\n",
    "def produce_poverty_gap(row):\n",
    "    if row.headcount == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return row.avg_shortfall_international_povline * row.headcount\n",
    "    \n",
    "our_world_in_data_with_codes['poverty_gap'] = our_world_in_data_with_codes.apply(produce_poverty_gap, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_our_world_in_data_rates = get_latest_value_with_year(our_world_in_data_with_codes, 'headcount')\n",
    "latest_our_world_in_data_rates.columns = ['country_code', 'owid_poverty_rate_most_recent', 'owid_poverty_rate_most_recent_year']\n",
    "latest_our_world_in_data_gaps = get_latest_value_with_year(our_world_in_data_with_codes, 'poverty_gap')\n",
    "latest_our_world_in_data_gaps.columns = ['country_code', 'owid_poverty_gap_index_most_recent', 'owid_poverty_gap_index_most_recent_year']\n",
    "latest_our_world_in_data_gaps.owid_poverty_gap_index_most_recent /= 2.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_code, survey_year, headcount, poverty_gap\n",
    "\n",
    "our_world_in_data_survey_year = gather_survey_year_pip_data(\n",
    "    aux_data[aux_data.survey_year.notna()], our_world_in_data_with_codes, 2.15\n",
    ")\n",
    "our_world_in_data_survey_year.columns = [\n",
    "    'country_code', 'survey_year', 'owid_poverty_rate_survey_year', \n",
    "    'interpolation_method_rate_survey_year', 'owid_poverty_gap_index_survey_year'\n",
    "]\n",
    "our_world_in_data_survey_year.drop(columns='interpolation_method_rate_survey_year', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owid_merged = pd.merge(latest_our_world_in_data_rates, latest_our_world_in_data_gaps, how='inner')\n",
    "owid_merged = owid_merged.merge(our_world_in_data_survey_year, on='country_code', how='left')\n",
    "owid_merged.drop(columns='survey_year', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_readable = all_countries.merge(wpc, on='country', how='outer')\n",
    "human_readable = human_readable.merge(owid_merged, on='country_code', how='outer')\n",
    "merged = pd.merge(human_readable, aux_data.drop(columns='country'), on='country_code', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_readable_columns = [\n",
    "    'country', 'survey_year',\n",
    "    'wb_poverty_rate_povertyline_2017_most_recent_year', 'wb_poverty_rate_povertyline_2017_most_recent', \n",
    "    'wb_poverty_rate_povertyline_2017_survey_year',\n",
    "    'poverty_rate_wpc', 'survey_poverty_rate_povertyline_2017',\n",
    "    'wb_poverty_gap_index_povertyline_2017_most_recent_year', 'wb_poverty_gap_index_povertyline_2017_most_recent',\n",
    "    'wb_poverty_gap_index_povertyline_2017_survey_year', 'survey_poverty_gap_index_povertyline_2017'\n",
    "]\n",
    "human_readable_columns = human_readable_columns + [\n",
    "    c for c in owid_merged.columns if c not in human_readable_columns\n",
    "]\n",
    "human_readable = merged[human_readable_columns]\n",
    "# Confirm latest years match so I can drop one of them\n",
    "print(\n",
    "    (\n",
    "        (\n",
    "            human_readable.wb_poverty_rate_povertyline_2017_most_recent_year \n",
    "            == human_readable.wb_poverty_gap_index_povertyline_2017_most_recent_year\n",
    "        ) | (\n",
    "            (human_readable.wb_poverty_rate_povertyline_2017_most_recent_year.isna())\n",
    "            & (human_readable.wb_poverty_gap_index_povertyline_2017_most_recent_year.isna())\n",
    "        )\n",
    "    ).mean()\n",
    ")\n",
    "print(\n",
    "    (\n",
    "        (\n",
    "            human_readable.owid_poverty_rate_most_recent_year \n",
    "            == human_readable.owid_poverty_gap_index_most_recent_year\n",
    "        ) | (\n",
    "            (human_readable.owid_poverty_rate_most_recent_year.isna())\n",
    "            & (human_readable.owid_poverty_gap_index_most_recent_year.isna())\n",
    "        )\n",
    "    ).mean()\n",
    ")\n",
    "\n",
    "human_readable = (\n",
    "    human_readable\n",
    "    .rename(columns={\n",
    "        'wb_poverty_rate_povertyline_2017_most_recent_year': 'wb_most_recent_year',\n",
    "        'wb_poverty_rate_povertyline_2017_most_recent': 'wb_poverty_rate_most_recent',\n",
    "        'wb_poverty_rate_povertyline_2017_survey_year': 'wb_poverty_rate_survey_year',\n",
    "        'poverty_rate_wpc': 'wpc_poverty_rate',\n",
    "        'survey_poverty_rate_povertyline_2017': 'survey_poverty_rate',\n",
    "        'wb_poverty_gap_index_povertyline_2017_most_recent': 'wb_poverty_gap_index_most_recent',\n",
    "        'wb_poverty_gap_index_povertyline_2017_survey_year': 'wb_poverty_gap_index_survey_year',\n",
    "        'survey_poverty_gap_index_povertyline_2017': 'survey_poverty_gap_index',\n",
    "        'owid_poverty_rate_most_recent_year': 'owid_most_recent_year'\n",
    "    })\n",
    "    .drop(columns=['wb_poverty_gap_index_povertyline_2017_most_recent_year', 'owid_poverty_gap_index_most_recent_year'])\n",
    ")\n",
    "cols = list(human_readable.columns)\n",
    "# Find the index of 'wb_most_recent_year'\n",
    "idx = cols.index('wb_most_recent_year')\n",
    "# Insert 'wpc_year' right after 'wb_most_recent_year'\n",
    "cols.insert(idx + 1, 'wpc_year')\n",
    "human_readable['wpc_year'] = 2022\n",
    "human_readable = human_readable[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_readable.loc[\n",
    "    human_readable.survey_year.notna(), \n",
    "    ['country',  'survey_poverty_rate', 'wb_poverty_rate_survey_year', 'wb_poverty_rate_most_recent', 'wpc_poverty_rate', 'owid_poverty_rate_most_recent', \n",
    "     'wb_most_recent_year', 'wpc_year', 'owid_most_recent_year'\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_str = datetime.today().strftime('%Y%m%d')\n",
    "human_readable.to_csv(\n",
    "    f'/data/eop/compiled_country_data/auxiliary_data/human_readable_{today_str}.csv', index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
